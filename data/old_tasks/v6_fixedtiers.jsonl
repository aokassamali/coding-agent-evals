{"task_id": "tier1_return_none_01", "prompt": "Fix this function so it returns True when x is positive and False otherwise.", "signature": "def is_positive(x: int) -> bool:", "starter_code": "def is_positive(x: int) -> bool:\n    if x > 0:\n        return True\n    # missing return for non-positive case\n", "tests": "def test_is_positive():\n    assert is_positive(5) == True\n    assert is_positive(-1) == False\n    assert is_positive(0) == False\n", "category": "bugfix", "topic": "return_value", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_off_by_one_01", "prompt": "Fix this function that should return the sum of numbers from 1 to n (inclusive).", "signature": "def sum_to_n(n: int) -> int:", "starter_code": "def sum_to_n(n: int) -> int:\n    total = 0\n    for i in range(n):\n        total += i\n    return total\n", "tests": "def test_sum_to_n():\n    assert sum_to_n(5) == 15\n    assert sum_to_n(1) == 1\n    assert sum_to_n(10) == 55\n", "category": "bugfix", "topic": "off_by_one", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_wrong_operator_01", "prompt": "Fix this function that should check if a number is even.", "signature": "def is_even(n: int) -> bool:", "starter_code": "def is_even(n: int) -> bool:\n    return n % 2 == 1\n", "tests": "def test_is_even():\n    assert is_even(4) == True\n    assert is_even(7) == False\n    assert is_even(0) == True\n", "category": "bugfix", "topic": "logic_error", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_wrong_comparison_01", "prompt": "Fix this function that should return the maximum of two numbers.", "signature": "def max_of_two(a: int, b: int) -> int:", "starter_code": "def max_of_two(a: int, b: int) -> int:\n    if a < b:\n        return a\n    return b\n", "tests": "def test_max_of_two():\n    assert max_of_two(3, 5) == 5\n    assert max_of_two(10, 2) == 10\n    assert max_of_two(4, 4) == 4\n", "category": "bugfix", "topic": "comparison", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_string_method_01", "prompt": "Fix this function that should return True if the string starts with a vowel (case-insensitive).", "signature": "def starts_with_vowel(s: str) -> bool:", "starter_code": "def starts_with_vowel(s: str) -> bool:\n    if not s:\n        return False\n    return s[0] in 'aeiou'\n", "tests": "def test_starts_with_vowel():\n    assert starts_with_vowel('apple') == True\n    assert starts_with_vowel('Apple') == True\n    assert starts_with_vowel('banana') == False\n    assert starts_with_vowel('') == False\n", "category": "bugfix", "topic": "string_handling", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_list_append_01", "prompt": "Fix this function that should return a list with the element added to the end.", "signature": "def append_element(lst: list, elem) -> list:", "starter_code": "def append_element(lst: list, elem) -> list:\n    lst.append(elem)\n    return elem\n", "tests": "def test_append_element():\n    assert append_element([1, 2], 3) == [1, 2, 3]\n    assert append_element([], 'a') == ['a']\n", "category": "bugfix", "topic": "return_value", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_boolean_logic_01", "prompt": "Fix this function that should return True if both conditions are met: n is positive AND n is less than 100.", "signature": "def in_range(n: int) -> bool:", "starter_code": "def in_range(n: int) -> bool:\n    return n > 0 or n < 100\n", "tests": "def test_in_range():\n    assert in_range(50) == True\n    assert in_range(-5) == False\n    assert in_range(100) == False\n    assert in_range(0) == False\n", "category": "bugfix", "topic": "boolean_logic", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_index_error_01", "prompt": "Fix this function that should return the last element of a list.", "signature": "def get_last(lst: list):", "starter_code": "def get_last(lst: list):\n    return lst[len(lst)]\n", "tests": "def test_get_last():\n    assert get_last([1, 2, 3]) == 3\n    assert get_last(['a']) == 'a'\n    assert get_last([True, False]) == False\n", "category": "bugfix", "topic": "indexing", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_string_concat_01", "prompt": "Fix this function that should greet a person by name.", "signature": "def greet(name: str) -> str:", "starter_code": "def greet(name: str) -> str:\n    return 'Hello, ' + 'name' + '!'\n", "tests": "def test_greet():\n    assert greet('Alice') == 'Hello, Alice!'\n    assert greet('Bob') == 'Hello, Bob!'\n", "category": "bugfix", "topic": "string_handling", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_division_01", "prompt": "Fix this function that should return the integer division result.", "signature": "def integer_divide(a: int, b: int) -> int:", "starter_code": "def integer_divide(a: int, b: int) -> int:\n    return a / b\n", "tests": "def test_integer_divide():\n    assert integer_divide(7, 2) == 3\n    assert integer_divide(10, 3) == 3\n    assert integer_divide(8, 4) == 2\n", "category": "bugfix", "topic": "arithmetic", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_counter_01", "prompt": "Fix this function that should count occurrences of a value in a list.", "signature": "def count_value(lst: list, val) -> int:", "starter_code": "def count_value(lst: list, val) -> int:\n    count = 0\n    for item in lst:\n        if item == val:\n            count = 1\n    return count\n", "tests": "def test_count_value():\n    assert count_value([1, 2, 1, 3, 1], 1) == 3\n    assert count_value([1, 2, 3], 4) == 0\n    assert count_value([], 1) == 0\n", "category": "bugfix", "topic": "accumulator", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_abs_value_01", "prompt": "Fix this function that should return the absolute value.", "signature": "def absolute(n: int) -> int:", "starter_code": "def absolute(n: int) -> int:\n    if n < 0:\n        return n\n    return n\n", "tests": "def test_absolute():\n    assert absolute(-5) == 5\n    assert absolute(5) == 5\n    assert absolute(0) == 0\n", "category": "bugfix", "topic": "logic_error", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_reverse_01", "prompt": "Fix this function that should return a reversed copy of the list without modifying the original.", "signature": "def reverse_list(lst: list) -> list:", "starter_code": "def reverse_list(lst: list) -> list:\n    lst.reverse()\n    return lst\n", "tests": "def test_reverse_list():\n    original = [1, 2, 3]\n    result = reverse_list(original)\n    assert result == [3, 2, 1]\n    assert original == [1, 2, 3]\n", "category": "bugfix", "topic": "mutation", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_power_01", "prompt": "Fix this function that should return x raised to the power of n.", "signature": "def power(x: int, n: int) -> int:", "starter_code": "def power(x: int, n: int) -> int:\n    return x * n\n", "tests": "def test_power():\n    assert power(2, 3) == 8\n    assert power(5, 2) == 25\n    assert power(3, 0) == 1\n", "category": "bugfix", "topic": "arithmetic", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_factorial_01", "prompt": "Fix this function that should return the factorial of n.", "signature": "def factorial(n: int) -> int:", "starter_code": "def factorial(n: int) -> int:\n    if n == 0:\n        return 0\n    return n * factorial(n - 1)\n", "tests": "def test_factorial():\n    assert factorial(0) == 1\n    assert factorial(1) == 1\n    assert factorial(5) == 120\n", "category": "bugfix", "topic": "base_case", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_min_list_01", "prompt": "Fix this function that should return the minimum value in a list.", "signature": "def find_min(lst: list) -> int:", "starter_code": "def find_min(lst: list) -> int:\n    minimum = 0\n    for num in lst:\n        if num < minimum:\n            minimum = num\n    return minimum\n", "tests": "def test_find_min():\n    assert find_min([3, 1, 4, 1, 5]) == 1\n    assert find_min([5, 4, 3, 2, 1]) == 1\n    assert find_min([42]) == 42\n    assert find_min([10, 20, 30]) == 10\n", "category": "bugfix", "topic": "initialization", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_join_strings_01", "prompt": "Fix this function that should join a list of strings with a separator.", "signature": "def join_with(strings: list, sep: str) -> str:", "starter_code": "def join_with(strings: list, sep: str) -> str:\n    return strings.join(sep)\n", "tests": "def test_join_with():\n    assert join_with(['a', 'b', 'c'], '-') == 'a-b-c'\n    assert join_with(['hello', 'world'], ' ') == 'hello world'\n    assert join_with(['x'], ',') == 'x'\n", "category": "bugfix", "topic": "method_call", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_contains_01", "prompt": "Fix this function that should check if a list contains a value.", "signature": "def contains(lst: list, val) -> bool:", "starter_code": "def contains(lst: list, val) -> bool:\n    for item in lst:\n        if item == val:\n            return True\n        else:\n            return False\n    return False\n", "tests": "def test_contains():\n    assert contains([1, 2, 3], 2) == True\n    assert contains([1, 2, 3], 4) == False\n    assert contains([], 1) == False\n", "category": "bugfix", "topic": "control_flow", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_capitalize_01", "prompt": "Fix this function that should capitalize the first letter of each word.", "signature": "def capitalize_words(s: str) -> str:", "starter_code": "def capitalize_words(s: str) -> str:\n    return s.upper()\n", "tests": "def test_capitalize_words():\n    assert capitalize_words('hello world') == 'Hello World'\n    assert capitalize_words('HELLO') == 'Hello'\n    assert capitalize_words('a b c') == 'A B C'\n", "category": "bugfix", "topic": "string_method", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_clamp_01", "prompt": "Fix this function that should clamp a value between min and max bounds.", "signature": "def clamp(val: int, min_val: int, max_val: int) -> int:", "starter_code": "def clamp(val: int, min_val: int, max_val: int) -> int:\n    if val < min_val:\n        return min_val\n    if val < max_val:\n        return max_val\n    return val\n", "tests": "def test_clamp():\n    assert clamp(5, 0, 10) == 5\n    assert clamp(-5, 0, 10) == 0\n    assert clamp(15, 0, 10) == 10\n", "category": "bugfix", "topic": "comparison", "tier": 1, "starter_check": "fail"}
{"task_id": "tier2_empty_list_edge_01", "prompt": "Fix this function that should return the average of a list of numbers, returning 0 for empty lists.", "signature": "def average(nums: list) -> float:", "starter_code": "def average(nums: list) -> float:\n    return sum(nums) / len(nums)\n", "tests": "def test_average():\n    assert average([1, 2, 3, 4, 5]) == 3.0\n    assert average([10]) == 10.0\n    assert average([]) == 0\n    assert average([2, 4]) == 3.0\n", "category": "bugfix", "topic": "edge_case", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_whitespace_edge_01", "prompt": "Fix this function that should return the first word of a string, handling leading whitespace and empty strings.", "signature": "def first_word(s: str) -> str:", "starter_code": "def first_word(s: str) -> str:\n    return s.split()[0]\n", "tests": "def test_first_word():\n    assert first_word('hello world') == 'hello'\n    assert first_word('  hello world') == 'hello'\n    assert first_word('single') == 'single'\n    assert first_word('') == ''\n    assert first_word('   ') == ''\n", "category": "bugfix", "topic": "edge_case", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_negative_index_01", "prompt": "Fix this function that should return the nth element from the end of a list (1-indexed), returning None for invalid indices.", "signature": "def nth_from_end(lst: list, n: int):", "starter_code": "def nth_from_end(lst: list, n: int):\n    return lst[-n]\n", "tests": "def test_nth_from_end():\n    assert nth_from_end([1, 2, 3, 4, 5], 1) == 5\n    assert nth_from_end([1, 2, 3, 4, 5], 3) == 3\n    assert nth_from_end([1, 2, 3], 0) == None\n    assert nth_from_end([1, 2], 5) == None\n", "category": "bugfix", "topic": "bounds_check", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_type_coercion_01", "prompt": "Fix this function that should check if two values are equal, treating numeric types as equal if their values match.", "signature": "def values_equal(a, b) -> bool:", "starter_code": "def values_equal(a, b) -> bool:\n    return a is b\n", "tests": "def test_values_equal():\n    assert values_equal(1, 1) == True\n    assert values_equal(1, 1.0) == True\n    assert values_equal('a', 'a') == True\n    assert values_equal(1, 2) == False\n    assert values_equal([], []) == True\n", "category": "bugfix", "topic": "identity_vs_equality", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_dict_key_error_01", "prompt": "Fix this function that should safely get a nested dictionary value, returning default if keys don't exist.", "signature": "def get_nested(d: dict, key1: str, key2: str, default=None):", "starter_code": "def get_nested(d: dict, key1: str, key2: str, default=None):\n    return d[key1][key2]\n", "tests": "def test_get_nested():\n    data = {'a': {'b': 1, 'c': 2}}\n    assert get_nested(data, 'a', 'b') == 1\n    assert get_nested(data, 'a', 'x') == None\n    assert get_nested(data, 'x', 'y') == None\n    assert get_nested(data, 'x', 'y', 'default') == 'default'\n", "category": "bugfix", "topic": "dict_access", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_float_comparison_01", "prompt": "Fix this function that should check if two floats are approximately equal.", "signature": "def approx_equal(a: float, b: float, tolerance: float = 1e-9) -> bool:", "starter_code": "def approx_equal(a: float, b: float, tolerance: float = 1e-9) -> bool:\n    return a == b\n", "tests": "def test_approx_equal():\n    assert approx_equal(0.1 + 0.2, 0.3) == True\n    assert approx_equal(1.0, 1.0) == True\n    assert approx_equal(1.0, 1.1) == False\n    assert approx_equal(1.0, 1.0001, 0.001) == True\n", "category": "bugfix", "topic": "float_precision", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_string_find_01", "prompt": "Fix this function that should return the index of the first occurrence of a substring, or -1 if not found.", "signature": "def find_substring(s: str, sub: str) -> int:", "starter_code": "def find_substring(s: str, sub: str) -> int:\n    return s.index(sub)\n", "tests": "def test_find_substring():\n    assert find_substring('hello world', 'world') == 6\n    assert find_substring('hello', 'xyz') == -1\n    assert find_substring('hello', '') == 0\n    assert find_substring('', 'a') == -1\n", "category": "bugfix", "topic": "exception_handling", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_boolean_none_01", "prompt": "Fix this function that should return True only if the value is explicitly True (not just truthy).", "signature": "def is_true(val) -> bool:", "starter_code": "def is_true(val) -> bool:\n    return bool(val)\n", "tests": "def test_is_true():\n    assert is_true(True) == True\n    assert is_true(False) == False\n    assert is_true(1) == False\n    assert is_true('yes') == False\n    assert is_true(None) == False\n", "category": "bugfix", "topic": "boolean_semantics", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_list_multiply_01", "prompt": "Fix this function that should create a matrix (list of lists) with given dimensions, where modifying one row doesn't affect others.", "signature": "def create_matrix(rows: int, cols: int, fill=0) -> list:", "starter_code": "def create_matrix(rows: int, cols: int, fill=0) -> list:\n    return [[fill] * cols] * rows\n", "tests": "def test_create_matrix():\n    m = create_matrix(2, 3, 0)\n    assert m == [[0, 0, 0], [0, 0, 0]]\n    m[0][0] = 1\n    assert m == [[1, 0, 0], [0, 0, 0]]\n", "category": "bugfix", "topic": "reference_vs_copy", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_strip_chars_01", "prompt": "Fix this function that should remove specific characters from both ends of a string only (not from the middle).", "signature": "def strip_chars(s: str, chars: str) -> str:", "starter_code": "def strip_chars(s: str, chars: str) -> str:\n    result = s\n    for c in chars:\n        result = result.replace(c, '')\n    return result\n", "tests": "def test_strip_chars():\n    assert strip_chars('xxhelloxx', 'x') == 'hello'\n    assert strip_chars('abchelloabc', 'abc') == 'hello'\n    assert strip_chars('hello', 'x') == 'hello'\n    assert strip_chars('xhellox', 'x') == 'hello'\n    # Bug: replace() removes from middle too\n    assert strip_chars('xhxexlxlxox', 'x') == 'hxexlxlxo', 'Should only strip from ends'\n", "category": "bugfix", "topic": "string_methods", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_sort_key_none_01", "prompt": "Fix this function that should sort a list of dictionaries by a key, putting None values at the end.", "signature": "def sort_by_key(items: list, key: str) -> list:", "starter_code": "def sort_by_key(items: list, key: str) -> list:\n    return sorted(items, key=lambda x: x[key])\n", "tests": "def test_sort_by_key():\n    items = [{'name': 'b', 'val': 2}, {'name': 'a', 'val': 1}, {'name': 'c', 'val': None}]\n    result = sort_by_key(items, 'val')\n    assert result[0]['name'] == 'a'\n    assert result[1]['name'] == 'b'\n    assert result[2]['name'] == 'c'\n", "category": "bugfix", "topic": "sorting", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_unique_preserve_order_01", "prompt": "Fix this function that should return unique elements while preserving their original order.", "signature": "def unique_ordered(lst: list) -> list:", "starter_code": "def unique_ordered(lst: list) -> list:\n    return list(set(lst))\n", "tests": "def test_unique_ordered():\n    assert unique_ordered([3, 1, 2, 1, 3, 2]) == [3, 1, 2]\n    assert unique_ordered([1, 1, 1]) == [1]\n    assert unique_ordered([]) == []\n    assert unique_ordered(['a', 'b', 'a']) == ['a', 'b']\n", "category": "bugfix", "topic": "order_preservation", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_zip_unequal_01", "prompt": "Fix this function that should zip two lists, padding the shorter one with a fill value.", "signature": "def zip_longest(lst1: list, lst2: list, fillvalue=None) -> list:", "starter_code": "def zip_longest(lst1: list, lst2: list, fillvalue=None) -> list:\n    return list(zip(lst1, lst2))\n", "tests": "def test_zip_longest():\n    assert zip_longest([1, 2, 3], ['a', 'b']) == [(1, 'a'), (2, 'b'), (3, None)]\n    assert zip_longest([1], [2, 3, 4]) == [(1, 2), (None, 3), (None, 4)]\n    assert zip_longest([1, 2], [3, 4]) == [(1, 3), (2, 4)]\n", "category": "bugfix", "topic": "iteration", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_recursive_default_01", "prompt": "Fix this function that recursively flattens a nested list. The bug causes state to leak between calls.", "signature": "def flatten(lst: list) -> list:", "starter_code": "def flatten(lst: list, result=[]) -> list:\n    for item in lst:\n        if isinstance(item, list):\n            flatten(item, result)\n        else:\n            result.append(item)\n    return result\n", "tests": "def test_flatten():\n    assert flatten([1, [2, 3], [4, [5, 6]]]) == [1, 2, 3, 4, 5, 6]\n    assert flatten([[1], [2], [3]]) == [1, 2, 3]\n    assert flatten([1, 2, 3]) == [1, 2, 3]\n    assert flatten([7, 8]) == [7, 8]\n", "category": "bugfix", "topic": "mutable_default", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_int_parse_01", "prompt": "Fix this function that should safely parse a string to an integer, clamping to bounds and returning 0 for invalid input.", "signature": "def safe_int(s: str, min_val: int = -2147483648, max_val: int = 2147483647) -> int:", "starter_code": "def safe_int(s: str, min_val: int = -2147483648, max_val: int = 2147483647) -> int:\n    num = int(s)\n    return num\n", "tests": "def test_safe_int():\n    assert safe_int('42') == 42\n    assert safe_int('-100') == -100\n    assert safe_int('99999999999', max_val=100) == 100\n    assert safe_int('-99999999999', min_val=-100) == -100\n    assert safe_int('not_a_number') == 0\n", "category": "bugfix", "topic": "parsing", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_case_insensitive_01", "prompt": "Fix this function that should count occurrences of a word case-insensitively.", "signature": "def count_word(text: str, word: str) -> int:", "starter_code": "def count_word(text: str, word: str) -> int:\n    return text.count(word)\n", "tests": "def test_count_word():\n    assert count_word('Hello hello HELLO', 'hello') == 3\n    assert count_word('The the THE', 'the') == 3\n    assert count_word('ABC abc', 'xyz') == 0\n", "category": "bugfix", "topic": "case_sensitivity", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_palindrome_01", "prompt": "Fix this function that should check if a string is a palindrome, ignoring case and non-alphanumeric characters.", "signature": "def is_palindrome(s: str) -> bool:", "starter_code": "def is_palindrome(s: str) -> bool:\n    return s == s[::-1]\n", "tests": "def test_is_palindrome():\n    assert is_palindrome('racecar') == True\n    assert is_palindrome('A man a plan a canal Panama') == True\n    assert is_palindrome('hello') == False\n    assert is_palindrome('Was it a car or a cat I saw?') == True\n", "category": "bugfix", "topic": "string_processing", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_second_largest_01", "prompt": "Fix this function that should return the second largest unique value in a list, or None if it doesn't exist.", "signature": "def second_largest(nums: list) -> int:", "starter_code": "def second_largest(nums: list) -> int:\n    if len(nums) < 2:\n        return None\n    nums.sort(reverse=True)\n    return nums[1]\n", "tests": "def test_second_largest():\n    assert second_largest([1, 2, 3, 4, 5]) == 4\n    assert second_largest([5, 5, 5, 4]) == 4\n    assert second_largest([1]) == None\n    assert second_largest([]) == None\n    assert second_largest([3, 3, 3]) == None\n", "category": "bugfix", "topic": "edge_case", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_deep_copy_dict_01", "prompt": "Fix this function that should create a deep copy of a nested dictionary.", "signature": "def deep_copy_dict(d: dict) -> dict:", "starter_code": "def deep_copy_dict(d: dict) -> dict:\n    return d.copy()\n", "tests": "def test_deep_copy_dict():\n    original = {'a': 1, 'b': {'c': 2, 'd': [3, 4]}}\n    copy = deep_copy_dict(original)\n    copy['b']['c'] = 99\n    copy['b']['d'].append(5)\n    assert original['b']['c'] == 2\n    assert original['b']['d'] == [3, 4]\n", "category": "bugfix", "topic": "deep_copy", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_none_vs_false_01", "prompt": "Fix this function that should return a default value only when the input is None (not for other falsy values).", "signature": "def with_default(val, default):", "starter_code": "def with_default(val, default):\n    return val or default\n", "tests": "def test_with_default():\n    assert with_default(None, 'default') == 'default'\n    assert with_default(0, 'default') == 0\n    assert with_default('', 'default') == ''\n    assert with_default(False, 'default') == False\n    assert with_default([], 'default') == []\n    assert with_default('value', 'default') == 'value'\n", "category": "bugfix", "topic": "none_handling", "tier": 2, "starter_check": "fail"}
{"task_id": "tier3_two_stage_parse_01", "prompt": "Fix this CSV parser that should handle quoted fields containing commas.", "signature": "def parse_csv_line(line: str) -> list:", "starter_code": "def parse_csv_line(line: str) -> list:\n    fields = line.split(',')\n    return [f.strip() for f in fields]\n", "tests": "def test_parse_csv_line():\n    assert parse_csv_line('a,b,c') == ['a', 'b', 'c']\n    assert parse_csv_line('\"hello, world\",b,c') == ['hello, world', 'b', 'c']\n    assert parse_csv_line('a,\"b,c\",d') == ['a', 'b,c', 'd']\n    assert parse_csv_line('') == ['']\n", "category": "bugfix", "topic": "parsing", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_accumulator_reset_01", "prompt": "Fix this function that groups consecutive equal elements. The last group is being lost.", "signature": "def group_consecutive(lst: list) -> list:", "starter_code": "def group_consecutive(lst: list) -> list:\n    if not lst:\n        return []\n    groups = []\n    current_group = [lst[0]]\n    for item in lst[1:]:\n        if item == current_group[0]:\n            current_group.append(item)\n        else:\n            groups.append(current_group)\n            current_group = [item]\n    return groups\n", "tests": "def test_group_consecutive():\n    assert group_consecutive([1, 1, 2, 2, 2, 1]) == [[1, 1], [2, 2, 2], [1]]\n    assert group_consecutive([1, 2, 3]) == [[1], [2], [3]]\n    assert group_consecutive([1, 1, 1]) == [[1, 1, 1]]\n    assert group_consecutive([]) == []\n    assert group_consecutive([1]) == [[1]]\n", "category": "bugfix", "topic": "loop_boundary", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_dict_merge_01", "prompt": "Fix this function that deep merges two dictionaries. It should not mutate the originals.", "signature": "def deep_merge(dict1: dict, dict2: dict) -> dict:", "starter_code": "def deep_merge(dict1: dict, dict2: dict) -> dict:\n    result = dict1.copy()\n    for key, value in dict2.items():\n        if key in result and isinstance(result[key], dict) and isinstance(value, dict):\n            result[key] = deep_merge(result[key], value)\n        else:\n            result[key] = value\n    return result\n", "tests": "def test_deep_merge():\n    d1 = {'a': 1, 'b': {'c': 2, 'd': 3, 'nested': {'x': 1}}}\n    d2 = {'b': {'c': 4, 'e': 5}, 'f': 6}\n    result = deep_merge(d1, d2)\n    assert result == {'a': 1, 'b': {'c': 4, 'd': 3, 'e': 5, 'nested': {'x': 1}}, 'f': 6}\n    assert d1 == {'a': 1, 'b': {'c': 2, 'd': 3, 'nested': {'x': 1}}}\n    result['b']['nested']['x'] = 999\n    assert d1['b']['nested']['x'] == 1, 'Original nested dict was mutated'\n", "category": "bugfix", "topic": "deep_copy", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_iterator_exhaustion_01", "prompt": "Fix this function that should allow iterating over filtered data multiple times.", "signature": "def create_repeatable_filter(data: list, predicate) -> object:", "starter_code": "def create_repeatable_filter(data: list, predicate) -> object:\n    return filter(predicate, data)\n", "tests": "def test_create_repeatable_filter():\n    data = [1, 2, 3, 4, 5]\n    filtered = create_repeatable_filter(data, lambda x: x > 2)\n    first_pass = list(filtered)\n    second_pass = list(filtered)\n    assert first_pass == [3, 4, 5]\n    assert second_pass == [3, 4, 5]\n", "category": "bugfix", "topic": "iterator", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_boundary_split_01", "prompt": "Fix this function that splits a list into chunks of size n. There's an off-by-one error in the slice.", "signature": "def chunk_list(lst: list, n: int) -> list:", "starter_code": "def chunk_list(lst: list, n: int) -> list:\n    if n <= 0:\n        return []\n    chunks = []\n    for i in range(0, len(lst), n):\n        chunks.append(lst[i:i+n-1])\n    return chunks\n", "tests": "def test_chunk_list():\n    assert chunk_list([1, 2, 3, 4, 5], 2) == [[1, 2], [3, 4], [5]]\n    assert chunk_list([1, 2, 3, 4], 2) == [[1, 2], [3, 4]]\n    assert chunk_list([1, 2, 3], 5) == [[1, 2, 3]]\n    assert chunk_list([], 3) == []\n    assert chunk_list([1, 2, 3], 0) == []\n", "category": "bugfix", "topic": "slice_boundary", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_recursive_depth_01", "prompt": "Fix this function that finds all paths in a nested dict to leaf values. Paths are being corrupted due to mutation.", "signature": "def find_paths(d: dict, target) -> list:", "starter_code": "def find_paths(d: dict, target) -> list:\n    paths = []\n    def search(current, path):\n        if isinstance(current, dict):\n            for key, value in current.items():\n                path.append(key)\n                search(value, path)\n        elif current == target:\n            paths.append(path)\n    search(d, [])\n    return paths\n", "tests": "def test_find_paths():\n    data = {'a': {'b': 1, 'c': 2}, 'd': {'e': 1}}\n    result = find_paths(data, 1)\n    assert ['a', 'b'] in result\n    assert ['d', 'e'] in result\n    assert len(result) == 2\n    assert result[0] != result[1]\n", "category": "bugfix", "topic": "recursion_mutation", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_lazy_eval_01", "prompt": "Fix this function that creates a list of multiplier functions. All functions currently return the same value due to late binding.", "signature": "def create_multipliers(n: int) -> list:", "starter_code": "def create_multipliers(n: int) -> list:\n    multipliers = []\n    for i in range(n):\n        multipliers.append(lambda x: x * i)\n    return multipliers\n", "tests": "def test_create_multipliers():\n    mults = create_multipliers(4)\n    assert mults[0](10) == 0\n    assert mults[1](10) == 10\n    assert mults[2](10) == 20\n    assert mults[3](10) == 30\n", "category": "bugfix", "topic": "closure", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_graph_visited_01", "prompt": "Fix this function that finds all paths between two nodes. The shared visited set is blocking valid alternate paths.", "signature": "def find_all_paths(graph: dict, start, end) -> list:", "starter_code": "def find_all_paths(graph: dict, start, end) -> list:\n    return []  # Bug: returns empty instead of finding paths\n", "tests": "def test_find_all_paths():\n    # Graph: A->B->D and A->C->D - both paths should be found\n    graph = {'A': ['B', 'C'], 'B': ['D'], 'C': ['D'], 'D': []}\n    paths = find_all_paths(graph, 'A', 'D')\n    # Bug: after finding A->B->D, 'D' is in visited, so A->C->D won't find D\n    # Actually the bug is that we add to visited but never remove\n    # So after going A->B->D, when we backtrack and try A->C, C is not visited\n    # but when we try C->D, D is already visited from first path\n    assert len(paths) >= 2, f\"Expected at least 2 paths, got {len(paths)}: {paths}\"\n", "category": "bugfix", "topic": "graph_traversal", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_regex_groups_01", "prompt": "Fix this function that parses assignment expressions. It doesn't handle compound operators like += and -=.", "signature": "def parse_expression(expr: str) -> dict:", "starter_code": "import re\n\ndef parse_expression(expr: str) -> dict:\n    match = re.match(r'(\\w+)\\s*=\\s*(.+)', expr)\n    if match:\n        return {'var': match.group(1), 'op': '=', 'value': match.group(2)}\n    return None\n", "tests": "def test_parse_expression():\n    assert parse_expression('x = 5') == {'var': 'x', 'op': '=', 'value': '5'}\n    assert parse_expression('x += 5') == {'var': 'x', 'op': '+=', 'value': '5'}\n    assert parse_expression('x -= 5') == {'var': 'x', 'op': '-=', 'value': '5'}\n    assert parse_expression('count = hello world') == {'var': 'count', 'op': '=', 'value': 'hello world'}\n    assert parse_expression('invalid') == None\n", "category": "bugfix", "topic": "regex", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_concurrent_counter_01", "prompt": "Fix this thread-safe counter class that has race conditions.", "signature": "class ThreadSafeCounter:", "starter_code": "import threading\n\nclass ThreadSafeCounter:\n    def __init__(self):\n        self.value = 0\n    \n    def increment(self):\n        self.value += 1\n    \n    def get(self):\n        return self.value\n", "tests": "def test_thread_safe_counter():\n    import threading\n    # Test that a lock attribute exists (required for thread safety)\n    counter = ThreadSafeCounter()\n    assert hasattr(counter, '_lock') or hasattr(counter, 'lock'), \"Missing lock for thread safety\"\n", "category": "bugfix", "topic": "threading", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_generator_send_01", "prompt": "Fix this accumulator coroutine that crashes on the first send() call.", "signature": "def accumulator():", "starter_code": "def accumulator():\n    total = 0\n    while True:\n        yield total  # Bug: doesn't use sent value at all\n", "tests": "def test_accumulator():\n    gen = accumulator()\n    assert next(gen) == 0\n    result = gen.send(5)\n    assert result == 5, f\"Expected 5 after send(5), got {result}\"\n", "category": "bugfix", "topic": "generator", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_binary_search_bounds_01", "prompt": "Fix this binary search that finds the insertion point. It has an infinite loop bug.", "signature": "def find_insert_position(arr: list, target) -> int:", "starter_code": "def find_insert_position(arr: list, target) -> int:\n    if not arr:\n        return 0\n    left, right = 0, len(arr)\n    count = 0\n    while left < right:\n        count += 1\n        if count > len(arr) + 5:\n            raise RuntimeError('Infinite loop detected')\n        mid = (left + right) // 2\n        if arr[mid] < target:\n            left = mid  # Bug: should be mid + 1\n        else:\n            right = mid\n    return left\n", "tests": "def test_find_insert_position():\n    arr = [1, 3, 5, 7, 9]\n    try:\n        result = find_insert_position(arr, 6)\n        assert result == 3, f'Expected 3, got {result}'\n    except RuntimeError as e:\n        raise AssertionError(f'Infinite loop: {e}')\n    assert find_insert_position(arr, 0) == 0\n    assert find_insert_position(arr, 5) == 2\n    assert find_insert_position(arr, 10) == 5\n", "category": "bugfix", "topic": "binary_search", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_json_circular_01", "prompt": "Fix this function that serializes objects to JSON, handling circular references by replacing them with '[Circular]'.", "signature": "def safe_json_dumps(obj) -> str:", "starter_code": "import json\n\ndef safe_json_dumps(obj) -> str:\n    return json.dumps(obj)\n", "tests": "def test_safe_json_dumps():\n    import json\n    assert json.loads(safe_json_dumps({'a': 1})) == {'a': 1}\n    obj = {'a': 1}\n    obj['self'] = obj\n    result = safe_json_dumps(obj)\n    parsed = json.loads(result)\n    assert parsed['a'] == 1\n    assert parsed['self'] == '[Circular]'\n", "category": "bugfix", "topic": "serialization", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_event_ordering_01", "prompt": "Fix this function that processes events sorted by timestamp, then by priority. It modifies the original list.", "signature": "def process_events(events: list) -> list:", "starter_code": "def process_events(events: list) -> list:\n    events.sort(key=lambda e: e['timestamp'])\n    return [e['name'] for e in events]\n", "tests": "def test_process_events():\n    events = [\n        {'timestamp': 1, 'priority': 2, 'name': 'b'},\n        {'timestamp': 1, 'priority': 1, 'name': 'a'},\n        {'timestamp': 2, 'priority': 1, 'name': 'c'},\n    ]\n    original = [e.copy() for e in events]\n    result = process_events(events)\n    assert result == ['a', 'b', 'c']\n    assert events[0]['name'] == original[0]['name']\n", "category": "bugfix", "topic": "multi_key_sort", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_tokenizer_escape_01", "prompt": "Fix this tokenizer that should handle escaped quotes within quoted strings.", "signature": "def tokenize_string(s: str) -> list:", "starter_code": "def tokenize_string(s: str) -> list:\n    tokens = []\n    i = 0\n    while i < len(s):\n        if s[i] == '\"':\n            j = i + 1\n            while j < len(s) and s[j] != '\"':\n                j += 1\n            tokens.append(s[i+1:j])\n            i = j + 1\n        elif s[i].isspace():\n            i += 1\n        else:\n            j = i\n            while j < len(s) and not s[j].isspace() and s[j] != '\"':\n                j += 1\n            tokens.append(s[i:j])\n            i = j\n    return tokens\n", "tests": "def test_tokenize_string():\n    assert tokenize_string('hello world') == ['hello', 'world']\n    assert tokenize_string('\"hello world\"') == ['hello world']\n    assert tokenize_string('a \"b c\" d') == ['a', 'b c', 'd']\n    assert tokenize_string('\"hello \\\\\"world\\\\\"\"') == ['hello \"world\"']\n    assert tokenize_string('') == []\n", "category": "bugfix", "topic": "state_machine", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_cache_mutable_key_01", "prompt": "Fix this memoization decorator that crashes when arguments include unhashable types like lists.", "signature": "def memoize(func):", "starter_code": "def memoize(func):\n    cache = {}\n    def wrapper(*args):\n        if args in cache:\n            return cache[args]\n        result = func(*args)\n        cache[args] = result\n        return result\n    return wrapper\n", "tests": "def test_memoize():\n    call_count = 0\n    @memoize\n    def add_elements(lst):\n        nonlocal call_count\n        call_count += 1\n        return sum(lst)\n    assert add_elements([1, 2, 3]) == 6\n    assert add_elements([1, 2, 3]) == 6\n    assert call_count == 2\n    @memoize\n    def add(a, b):\n        return a + b\n    assert add(1, 2) == 3\n    assert add(1, 2) == 3\n", "category": "bugfix", "topic": "memoization", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_merge_intervals_01", "prompt": "Fix this function that merges overlapping intervals. Adjacent intervals like [1,2] and [2,3] should merge.", "signature": "def merge_intervals(intervals: list) -> list:", "starter_code": "def merge_intervals(intervals: list) -> list:\n    return intervals  # Bug: doesn't merge at all\n", "tests": "def test_merge_intervals():\n    result = merge_intervals([[1,2],[2,3]])\n    assert result == [[1,3]], f\"Adjacent intervals should merge: {result}\"\n", "category": "bugfix", "topic": "interval_logic", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_lru_eviction_01", "prompt": "Fix this LRU cache that should evict the least recently used item when capacity is exceeded.", "signature": "class LRUCache:", "starter_code": "class LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n    \n    def get(self, key):\n        return self.cache.get(key)\n    \n    def put(self, key, value):\n        self.cache[key] = value\n        if len(self.cache) > self.capacity:\n            oldest_key = next(iter(self.cache))\n            del self.cache[oldest_key]\n", "tests": "def test_lru_cache():\n    cache = LRUCache(2)\n    cache.put('a', 1)\n    cache.put('b', 2)\n    assert cache.get('a') == 1\n    cache.put('c', 3)\n    assert cache.get('b') == None\n    assert cache.get('a') == 1\n    assert cache.get('c') == 3\n", "category": "bugfix", "topic": "data_structure", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_retry_exponential_01", "prompt": "Fix this retry decorator that should use exponential backoff and properly re-raise the last exception.", "signature": "def retry(max_attempts: int, base_delay: float = 1.0):", "starter_code": "import time\n\ndef retry(max_attempts: int, base_delay: float = 1.0):\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            for attempt in range(max_attempts):\n                try:\n                    return func(*args, **kwargs)\n                except Exception:\n                    time.sleep(base_delay)\n            return None\n        return wrapper\n    return decorator\n", "tests": "def test_retry():\n    attempts = [0]\n    @retry(max_attempts=3, base_delay=0.01)\n    def failing_func():\n        attempts[0] += 1\n        if attempts[0] < 3:\n            raise ValueError('Not yet')\n        return 'success'\n    assert failing_func() == 'success'\n    assert attempts[0] == 3\n    attempts[0] = 0\n    @retry(max_attempts=2, base_delay=0.01)\n    def always_fails():\n        attempts[0] += 1\n        raise RuntimeError('Always fails')\n    try:\n        always_fails()\n        assert False, 'Should have raised'\n    except RuntimeError as e:\n        assert 'Always fails' in str(e)\n    assert attempts[0] == 2\n", "category": "bugfix", "topic": "decorator", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_topological_sort_01", "prompt": "Fix this topological sort that doesn't detect cycles properly.", "signature": "def topological_sort(graph: dict) -> list:", "starter_code": "def topological_sort(graph: dict) -> list:\n    visited = set()\n    result = []\n    def dfs(node):\n        if node in visited:\n            return\n        visited.add(node)\n        for neighbor in graph.get(node, []):\n            dfs(neighbor)\n        result.append(node)\n    for node in graph:\n        dfs(node)\n    return result[::-1]\n", "tests": "def test_topological_sort():\n    graph = {'a': ['b', 'c'], 'b': ['d'], 'c': ['d'], 'd': []}\n    result = topological_sort(graph)\n    assert result.index('a') < result.index('b')\n    assert result.index('a') < result.index('c')\n    assert result.index('b') < result.index('d')\n    cyclic = {'a': ['b'], 'b': ['c'], 'c': ['a']}\n    try:\n        topological_sort(cyclic)\n        assert False, 'Should detect cycle'\n    except ValueError as e:\n        assert 'cycle' in str(e).lower()\n", "category": "bugfix", "topic": "graph_algorithm", "tier": 3, "starter_check": "fail"}
{"task_id": "tier4_datetime_timezone_01", "prompt": "Fix this function that calculates time differences across timezones. It's comparing naive datetimes.", "signature": "def hours_between(dt1_str: str, tz1: str, dt2_str: str, tz2: str) -> float:", "starter_code": "from datetime import datetime\nimport zoneinfo\n\ndef hours_between(dt1_str: str, tz1: str, dt2_str: str, tz2: str) -> float:\n    dt1 = datetime.fromisoformat(dt1_str)\n    dt2 = datetime.fromisoformat(dt2_str)\n    diff = dt2 - dt1\n    return diff.total_seconds() / 3600\n", "tests": "def test_hours_between():\n    result = hours_between('2024-01-01T10:00:00', 'UTC', '2024-01-01T12:00:00', 'UTC')\n    assert abs(result - 2.0) < 0.01\n    result = hours_between('2024-06-01T10:00:00', 'America/New_York', '2024-06-01T10:00:00', 'Europe/London')\n    assert abs(result - (-5.0)) < 0.01\n", "category": "bugfix", "topic": "timezone", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_decimal_precision_01", "prompt": "Fix this function that performs precise financial calculations. Float precision causes errors.", "signature": "def calculate_compound_interest(principal: str, rate: str, years: int) -> str:", "starter_code": "def calculate_compound_interest(principal: str, rate: str, years: int) -> str:\n    return '0.00'  # Bug: returns wrong value\n", "tests": "def test_calculate_compound_interest():\n    result = calculate_compound_interest(\"1000.00\", \"0.05\", 10)\n    # Exact: 1000 * 1.05^10 = 1628.894626777442...\n    # Float gives: 1628.89 but may have small errors\n    # Decimal gives exact: 1628.89\n    assert result == \"1628.89\", f\"Got {result}\"\n", "category": "bugfix", "topic": "decimal_precision", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_unicode_normalize_01", "prompt": "Fix this function that compares strings accounting for Unicode normalization (composed vs decomposed forms).", "signature": "def strings_equal(s1: str, s2: str) -> bool:", "starter_code": "def strings_equal(s1: str, s2: str) -> bool:\n    return s1 == s2\n", "tests": "def test_strings_equal():\n    assert strings_equal('hello', 'hello') == True\n    assert strings_equal('hello', 'world') == False\n    s1 = 'caf\\u00e9'\n    s2 = 'cafe\\u0301'\n    assert strings_equal(s1, s2) == True\n    s3 = '\\u00f1'\n    s4 = 'n\\u0303'\n    assert strings_equal(s3, s4) == True\n", "category": "bugfix", "topic": "unicode", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_weakref_callback_01", "prompt": "Fix this cache that should automatically remove entries when objects are garbage collected.", "signature": "class WeakCache:", "starter_code": "import weakref\n\nclass WeakCache:\n    def __init__(self):\n        self._cache = {}\n    \n    def set(self, key, value):\n        self._cache[id(key)] = (key, value)\n    \n    def get(self, key):\n        entry = self._cache.get(id(key))\n        if entry:\n            return entry[1]\n        return None\n", "tests": "def test_weak_cache():\n    import gc\n    cache = WeakCache()\n    class Key:\n        def __init__(self, name):\n            self.name = name\n    k1 = Key('first')\n    cache.set(k1, 'value1')\n    assert cache.get(k1) == 'value1'\n    del k1\n    gc.collect()\n    gc.collect()\n    remaining = len([k for k in cache._cache.keys()])\n    assert remaining == 0, f'Cache has {remaining} entries - strong reference leak'\n", "category": "bugfix", "topic": "weakref", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_descriptor_protocol_01", "prompt": "Fix this descriptor that provides type validation on attribute access. It crashes when accessing unset attributes.", "signature": "class TypedAttribute:", "starter_code": "class TypedAttribute:\n    def __init__(self, name, expected_type):\n        self.name = name\n        self.expected_type = expected_type\n    \n    def __get__(self, obj, objtype=None):\n        if obj is None:\n            return self\n        return obj.__dict__[self.name]\n    \n    def __set__(self, obj, value):\n        if not isinstance(value, self.expected_type):\n            raise TypeError(f'Expected {self.expected_type}')\n        obj.__dict__[self.name] = value\n\nclass Person:\n    name = TypedAttribute('name', str)\n    age = TypedAttribute('age', int)\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n", "tests": "def test_typed_attribute():\n    p = Person('Alice', 30)\n    assert p.name == 'Alice'\n    assert p.age == 30\n    p.name = 'Bob'\n    assert p.name == 'Bob'\n    try:\n        p.age = 'thirty'\n        assert False, 'Should have raised TypeError'\n    except TypeError:\n        pass\n    class WithDefault:\n        value = TypedAttribute('value', int)\n    w = WithDefault()\n    try:\n        _ = w.value\n        assert False, 'Should have raised AttributeError'\n    except AttributeError:\n        pass\n", "category": "bugfix", "topic": "descriptor", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_metaclass_registry_01", "prompt": "Fix this metaclass that should register all subclasses but not the base class itself.", "signature": "class PluginMeta:", "starter_code": "class PluginMeta(type):\n    registry = {}\n    \n    def __new__(mcs, name, bases, namespace):\n        cls = super().__new__(mcs, name, bases, namespace)\n        mcs.registry[name] = cls\n        return cls\n\nclass Plugin(metaclass=PluginMeta):\n    pass\n", "tests": "def test_plugin_meta():\n    class PluginA(Plugin):\n        pass\n    class PluginB(Plugin):\n        pass\n    assert 'Plugin' not in PluginMeta.registry\n    assert 'PluginA' in PluginMeta.registry\n    assert 'PluginB' in PluginMeta.registry\n    assert PluginMeta.registry['PluginA'] is PluginA\n", "category": "bugfix", "topic": "metaclass", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_slots_inheritance_01", "prompt": "Fix this class hierarchy using __slots__ for memory efficiency. The child class duplicates parent slots.", "signature": "class OptimizedPoint:", "starter_code": "class OptimizedPoint:\n    __slots__ = ['x', 'y']\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\nclass OptimizedPoint3D(OptimizedPoint):\n    __slots__ = ['x', 'y', 'z']\n    def __init__(self, x, y, z):\n        super().__init__(x, y)\n        self.z = z\n", "tests": "def test_optimized_points():\n    p2d = OptimizedPoint(1, 2)\n    assert p2d.x == 1\n    assert p2d.y == 2\n    assert not hasattr(p2d, '__dict__')\n    p3d = OptimizedPoint3D(1, 2, 3)\n    assert p3d.x == 1\n    assert p3d.y == 2\n    assert p3d.z == 3\n    base_slots = set(OptimizedPoint.__slots__)\n    child_slots = set(OptimizedPoint3D.__slots__)\n    overlap = base_slots & child_slots\n    assert len(overlap) == 0, f'Duplicated slots: {overlap}'\n", "category": "bugfix", "topic": "slots", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_lru_cache_method_01", "prompt": "Fix this class method that should use LRU caching properly without memory leaks.", "signature": "class DataProcessor:", "starter_code": "from functools import lru_cache\n\nclass DataProcessor:\n    def __init__(self, multiplier):\n        self.multiplier = multiplier\n    \n    def process(self, value):\n        return value  # Bug: ignores multiplier\n", "tests": "def test_data_processor():\n    p1 = DataProcessor(2)\n    p2 = DataProcessor(3)\n    assert p1.process(5) == 10\n    result = p2.process(5)\n    assert result == 15, f\"Expected 15 but got {result} (cache shared between instances)\"\n", "category": "bugfix", "topic": "caching", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_property_delete_01", "prompt": "Fix this property that should support getting, setting, and deleting with history tracking.", "signature": "class ManagedAttribute:", "starter_code": "class ManagedAttribute:\n    def __init__(self):\n        self._value = None\n        self._history = []\n    \n    @property\n    def value(self):\n        return self._value\n    \n    @value.setter\n    def value(self, new_value):\n        if new_value is not None and not isinstance(new_value, (int, float)):\n            raise ValueError('Value must be numeric or None')\n        self._history.append(self._value)\n        self._value = new_value\n    \n    def get_history(self):\n        return self._history[:]\n", "tests": "def test_managed_attribute():\n    m = ManagedAttribute()\n    m.value = 10\n    assert m.value == 10\n    m.value = 20\n    assert m.value == 20\n    assert m.get_history() == [None, 10]\n    del m.value\n    assert m.value is None\n    assert m.get_history() == [None, 10, 20]\n    try:\n        m.value = 'string'\n        assert False, 'Should raise ValueError'\n    except ValueError:\n        pass\n", "category": "bugfix", "topic": "property", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_abstract_classmethod_01", "prompt": "Fix this abstract base class that should require a classmethod implementation. The decorator order is wrong.", "signature": "class Serializable:", "starter_code": "from abc import ABC, abstractmethod\n\nclass Serializable(ABC):\n    @abstractmethod\n    def to_dict(self) -> dict:\n        pass\n    \n    @abstractmethod\n    @classmethod\n    def from_dict(cls, data: dict):\n        pass\n", "tests": "def test_serializable():\n    class Incomplete(Serializable):\n        def to_dict(self):\n            return {}\n    try:\n        Incomplete()\n        assert False, 'Should not instantiate without from_dict'\n    except TypeError:\n        pass\n    class Complete(Serializable):\n        def __init__(self, value):\n            self.value = value\n        def to_dict(self):\n            return {'value': self.value}\n        @classmethod\n        def from_dict(cls, data):\n            return cls(data['value'])\n    obj = Complete(42)\n    assert obj.to_dict() == {'value': 42}\n    restored = Complete.from_dict({'value': 42})\n    assert restored.value == 42\n", "category": "bugfix", "topic": "abc", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_context_var_01", "prompt": "Fix this context variable implementation that should properly restore previous values in nested contexts.", "signature": "class RequestContext:", "starter_code": "from contextvars import ContextVar\n\nrequest_id = ContextVar('request_id', default=None)\n\nclass RequestContext:\n    def __init__(self, req_id):\n        self.req_id = req_id\n    \n    def __enter__(self):\n        request_id.set(self.req_id)\n        return self\n    \n    def __exit__(self, *args):\n        request_id.set(None)\n\ndef get_request_id():\n    return request_id.get()\n", "tests": "def test_request_context():\n    assert get_request_id() is None\n    with RequestContext('req-123'):\n        assert get_request_id() == 'req-123'\n        with RequestContext('req-456'):\n            assert get_request_id() == 'req-456'\n        assert get_request_id() == 'req-123'\n    assert get_request_id() is None\n", "category": "bugfix", "topic": "contextvars", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_dataclass_inheritance_01", "prompt": "Fix this dataclass inheritance that fails because a field without default follows one with default.", "signature": "class Employee:", "starter_code": "from dataclasses import dataclass\n\n@dataclass\nclass Person:\n    name: str\n    age: int = 0\n\n@dataclass\nclass Employee(Person):\n    employee_id: str\n    department: str = 'General'\n", "tests": "def test_employee():\n    e = Employee(name='Alice', employee_id='E001')\n    assert e.name == 'Alice'\n    assert e.age == 0\n    assert e.employee_id == 'E001'\n    assert e.department == 'General'\n    e2 = Employee(name='Bob', age=30, employee_id='E002', department='Engineering')\n    assert e2.age == 30\n    assert e2.department == 'Engineering'\n", "category": "bugfix", "topic": "dataclass", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_enum_comparison_01", "prompt": "Fix this enum that should support ordering comparisons but only with other enum members.", "signature": "class Priority:", "starter_code": "from enum import Enum\n\nclass Priority(Enum):\n    LOW = 1\n    MEDIUM = 2\n    HIGH = 3\n    CRITICAL = 4\n    \n    def __lt__(self, other):\n        return self.value < other.value\n", "tests": "def test_priority():\n    assert Priority.LOW < Priority.HIGH\n    assert Priority.CRITICAL > Priority.MEDIUM\n    assert Priority.MEDIUM <= Priority.MEDIUM\n    assert Priority.HIGH >= Priority.LOW\n    try:\n        _ = Priority.LOW < 5\n        assert False, 'Should raise TypeError'\n    except TypeError:\n        pass\n    items = [Priority.HIGH, Priority.LOW, Priority.CRITICAL, Priority.MEDIUM]\n    sorted_items = sorted(items)\n    assert sorted_items == [Priority.LOW, Priority.MEDIUM, Priority.HIGH, Priority.CRITICAL]\n", "category": "bugfix", "topic": "enum", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_copy_protocol_01", "prompt": "Fix this tree node class that should support deep copying with circular parent references.", "signature": "class TreeNode:", "starter_code": "class TreeNode:\n    def __init__(self, value, children=None):\n        self.value = value\n        self.children = children or []\n        self.parent = None\n    \n    def add_child(self, child):\n        child.parent = None  # Bug: doesn't set parent correctly\n        self.children.append(child)\n", "tests": "def test_tree_node():\n    import copy\n    root = TreeNode(\"root\")\n    child = TreeNode(\"child\")\n    root.add_child(child)\n    deep = copy.deepcopy(root)\n    assert deep.children[0].parent is deep, \"Child parent should point to deep copy root\"\n", "category": "bugfix", "topic": "copy_protocol", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_hash_eq_01", "prompt": "Fix this class so it can be used in sets and as dictionary keys by implementing __hash__.", "signature": "class Coordinate:", "starter_code": "class Coordinate:\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n    \n    def __eq__(self, other):\n        if not isinstance(other, Coordinate):\n            return NotImplemented\n        return self.x == other.x and self.y == other.y\n", "tests": "def test_coordinate():\n    c1 = Coordinate(1, 2)\n    c2 = Coordinate(1, 2)\n    c3 = Coordinate(3, 4)\n    assert c1 == c2\n    assert c1 != c3\n    s = {c1, c2, c3}\n    assert len(s) == 2\n    d = {c1: 'origin', c3: 'other'}\n    assert d[c2] == 'origin'\n", "category": "bugfix", "topic": "hash_eq", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_getattr_recursion_01", "prompt": "Fix this class that uses __getattr__ for dynamic attribute access but causes infinite recursion.", "signature": "class DynamicConfig:", "starter_code": "class DynamicConfig:\n    def __init__(self, data=None):\n        self._data = data or {}\n    \n    def __getattr__(self, name):\n        return None  # Bug: always returns None\n", "tests": "def test_dynamic_config():\n    config = DynamicConfig({\"debug\": True})\n    assert config.debug == True\n", "category": "bugfix", "topic": "getattr", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_singledispatch_method_01", "prompt": "Fix this class that should use single dispatch for method overloading on instance methods.", "signature": "class Formatter:", "starter_code": "from functools import singledispatch\n\nclass Formatter:\n    @singledispatch\n    def format(self, value):\n        return str(value)\n    \n    @format.register(int)\n    def _(self, value):\n        return f'Integer: {value}'\n    \n    @format.register(list)\n    def _(self, value):\n        return f'List with {len(value)} items'\n", "tests": "def test_formatter():\n    f = Formatter()\n    assert f.format(42) == 'Integer: 42'\n    assert f.format([1, 2, 3]) == 'List with 3 items'\n    assert f.format('hello') == 'hello'\n    assert f.format(3.14) == '3.14'\n", "category": "bugfix", "topic": "singledispatch", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_ordered_dict_move_01", "prompt": "Fix this ordered dictionary that should move accessed items to the end (LRU style access).", "signature": "class AccessOrderedDict:", "starter_code": "from collections import OrderedDict\n\nclass AccessOrderedDict(OrderedDict):\n    def __getitem__(self, key):\n        value = super().__getitem__(key)\n        return value\n", "tests": "def test_access_ordered_dict():\n    d = AccessOrderedDict()\n    d['a'] = 1\n    d['b'] = 2\n    d['c'] = 3\n    _ = d['a']\n    assert list(d.keys()) == ['b', 'c', 'a']\n    _ = d['b']\n    assert list(d.keys()) == ['c', 'a', 'b']\n", "category": "bugfix", "topic": "ordered_dict", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_namedtuple_default_01", "prompt": "Fix this namedtuple that should have default values for some fields.", "signature": "def create_config_type():", "starter_code": "from collections import namedtuple\n\ndef create_config_type():\n    Config = namedtuple('Config', ['host', 'port', 'debug', 'timeout'])\n    return Config\n", "tests": "def test_config_type():\n    Config = create_config_type()\n    c1 = Config(host='localhost', port=8080)\n    assert c1.host == 'localhost'\n    assert c1.port == 8080\n    assert c1.debug == False\n    assert c1.timeout == 30\n    c2 = Config('example.com', 443, True, 60)\n    assert c2.debug == True\n    assert c2.timeout == 60\n", "category": "bugfix", "topic": "namedtuple", "tier": 4, "starter_check": "fail"}
{"task_id": "tier5_reduce_protocol_01", "prompt": "Fix this class that should support pickle with a custom __reduce__ method to avoid pickling sensitive data.", "signature": "class SecureConnection:", "starter_code": "import pickle\n\nclass SecureConnection:\n    def __init__(self, host, port, password):\n        self.host = host\n        self.port = port\n        self.password = password\n        self._socket = None\n    \n    def connect(self):\n        self._socket = f'connected to {self.host}:{self.port}'\n", "tests": "def test_secure_connection():\n    import pickle\n    conn = SecureConnection('localhost', 5432, 'secret123')\n    conn.connect()\n    pickled = pickle.dumps(conn)\n    restored = pickle.loads(pickled)\n    assert restored.host == 'localhost'\n    assert restored.port == 5432\n    assert restored.password is None\n    assert restored._socket is None\n", "category": "bugfix", "topic": "reduce_protocol", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_async_context_01", "prompt": "Fix this async context manager that should handle cleanup even when tasks are cancelled.", "signature": "class AsyncResourcePool:", "starter_code": "import asyncio\n\nclass AsyncResourcePool:\n    def __init__(self, size):\n        self.size = size\n        self.resources = []\n        self.acquired = 0\n    \n    async def __aenter__(self):\n        return self\n    \n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        pass  # Bug: doesn't clean up resources\n    \n    async def acquire(self):\n        return None  # Bug: doesn't track acquisition\n    \n    async def release(self):\n        pass\n", "tests": "def test_async_resource_pool():\n    import asyncio\n    async def run():\n        pool = AsyncResourcePool(3)\n        async with pool:\n            r = await pool.acquire()\n            assert r is not None, \"acquire() should return a resource\"\n            assert pool.acquired == 1, f\"acquired should be 1, got {pool.acquired}\"\n    asyncio.run(run())\n", "category": "bugfix", "topic": "async_context", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_import_hook_01", "prompt": "Fix this import hook that should intercept imports of specific modules.", "signature": "class MockImporter:", "starter_code": "import sys\nimport importlib.abc\nimport importlib.machinery\n\nclass MockImporter(importlib.abc.MetaPathFinder, importlib.abc.Loader):\n    def __init__(self, mocks):\n        self.mocks = mocks\n    \n    def find_module(self, fullname, path=None):\n        if fullname in self.mocks:\n            return self\n        return None\n    \n    def load_module(self, fullname):\n        return self.mocks[fullname]\n", "tests": "def test_mock_importer():\n    import sys\n    import types\n    mock_module = types.ModuleType('fake_module')\n    mock_module.value = 42\n    mock_module.greet = lambda: 'Hello from mock'\n    importer = MockImporter({'fake_module': mock_module})\n    sys.meta_path.insert(0, importer)\n    try:\n        import fake_module\n        assert fake_module.value == 42\n        assert fake_module.greet() == 'Hello from mock'\n    finally:\n        sys.meta_path.remove(importer)\n        if 'fake_module' in sys.modules:\n            del sys.modules['fake_module']\n", "category": "bugfix", "topic": "import_hook", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_traceback_chain_01", "prompt": "Fix this exception handling that should preserve the exception chain for debugging.", "signature": "def process_with_context(data, processor):", "starter_code": "def process_with_context(data, processor):\n    try:\n        return processor(data)\n    except Exception as e:\n        raise RuntimeError(f'Processing failed for data: {data}')\n", "tests": "def test_process_with_context():\n    import traceback\n    def bad_processor(data):\n        raise ValueError('Invalid data format')\n    try:\n        process_with_context('test', bad_processor)\n        assert False, 'Should have raised'\n    except RuntimeError as e:\n        assert 'Processing failed' in str(e)\n        assert e.__cause__ is not None\n        assert isinstance(e.__cause__, ValueError)\n        assert 'Invalid data format' in str(e.__cause__)\n", "category": "bugfix", "topic": "exception_chain", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_exec_namespace_01", "prompt": "Fix this dynamic code executor that should properly isolate execution namespaces.", "signature": "class SafeExecutor:", "starter_code": "class SafeExecutor:\n    def __init__(self):\n        self.results = {}\n    \n    def execute(self, code, name):\n        self.results[name] = None  # Bug: doesn't execute code\n    \n    def get_result(self, name):\n        return self.results.get(name)\n", "tests": "def test_safe_executor():\n    executor = SafeExecutor()\n    executor.execute(\"result = 1 + 2\", \"add\")\n    assert executor.get_result(\"add\") == 3\n", "category": "bugfix", "topic": "exec_namespace", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_class_getitem_01", "prompt": "Fix this generic class that should support subscript syntax like MyClass[int].", "signature": "class TypedList:", "starter_code": "class TypedList:\n    def __init__(self, item_type):\n        self.item_type = item_type\n        self.items = []\n    \n    def append(self, item):\n        if not isinstance(item, self.item_type):\n            raise TypeError(f'Expected {self.item_type}')\n        self.items.append(item)\n    \n    def __iter__(self):\n        return iter(self.items)\n", "tests": "def test_typed_list():\n    IntList = TypedList[int]\n    lst = IntList()\n    lst.append(1)\n    lst.append(2)\n    assert list(lst) == [1, 2]\n    try:\n        lst.append('string')\n        assert False, 'Should raise TypeError'\n    except TypeError:\n        pass\n    StrList = TypedList[str]\n    strs = StrList()\n    strs.append('hello')\n    assert list(strs) == ['hello']\n", "category": "bugfix", "topic": "class_getitem", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_descriptor_slots_01", "prompt": "Fix this descriptor that should work with classes using __slots__.", "signature": "class ValidatedProperty:", "starter_code": "class ValidatedProperty:\n    def __init__(self, validator):\n        self.validator = validator\n        self.name = None\n    \n    def __set_name__(self, owner, name):\n        self.name = name\n    \n    def __get__(self, obj, objtype=None):\n        if obj is None:\n            return self\n        return obj.__dict__[self.name]\n    \n    def __set__(self, obj, value):\n        if not self.validator(value):\n            raise ValueError(f'Invalid value for {self.name}')\n        obj.__dict__[self.name] = value\n", "tests": "def test_validated_property():\n    class Person:\n        __slots__ = ('_name', '_age')\n        name = ValidatedProperty(lambda x: isinstance(x, str) and len(x) > 0)\n        age = ValidatedProperty(lambda x: isinstance(x, int) and x >= 0)\n        def __init__(self, name, age):\n            self.name = name\n            self.age = age\n    p = Person('Alice', 30)\n    assert p.name == 'Alice'\n    assert p.age == 30\n    try:\n        p.name = ''\n        assert False, 'Should raise ValueError'\n    except ValueError:\n        pass\n    try:\n        p.age = -1\n        assert False, 'Should raise ValueError'\n    except ValueError:\n        pass\n", "category": "bugfix", "topic": "descriptor_slots", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_multiprocess_shared_01", "prompt": "Fix this multiprocessing code that should properly share state between processes.", "signature": "class SharedCounter:", "starter_code": "from multiprocessing import Process\n\nclass SharedCounter:\n    def __init__(self):\n        self.value = 0\n    \n    def increment(self):\n        self.value += 1\n    \n    def get(self):\n        return self.value\n", "tests": "def test_shared_counter():\n    from multiprocessing import Process\n    counter = SharedCounter()\n    def worker(c, n):\n        for _ in range(n):\n            c.increment()\n    processes = []\n    for _ in range(4):\n        p = Process(target=worker, args=(counter, 100))\n        processes.append(p)\n        p.start()\n    for p in processes:\n        p.join()\n    assert counter.get() == 400\n", "category": "bugfix", "topic": "multiprocessing", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_contextmanager_decorator_01", "prompt": "Fix this contextmanager-decorated generator that should handle exceptions properly.", "signature": "def temp_attribute(obj, name, value):", "starter_code": "from contextlib import contextmanager\n\n@contextmanager\ndef temp_attribute(obj, name, value):\n    old_value = getattr(obj, name, None)\n    had_attr = hasattr(obj, name)\n    setattr(obj, name, value)\n    yield\n    if had_attr:\n        setattr(obj, name, old_value)\n    else:\n        delattr(obj, name)\n", "tests": "def test_temp_attribute():\n    class Obj:\n        x = 10\n    o = Obj()\n    with temp_attribute(o, 'x', 99):\n        assert o.x == 99\n    assert o.x == 10\n    with temp_attribute(o, 'y', 'temp'):\n        assert o.y == 'temp'\n    assert not hasattr(o, 'y')\n    try:\n        with temp_attribute(o, 'x', 50):\n            assert o.x == 50\n            raise ValueError('test error')\n    except ValueError:\n        pass\n    assert o.x == 10\n", "category": "bugfix", "topic": "contextmanager", "tier": 5, "starter_check": "pass"}
{"task_id": "tier5_gc_callback_01", "prompt": "Fix this class that should track all instances using weak references without preventing garbage collection.", "signature": "class TrackedObject:", "starter_code": "import weakref\n\nclass TrackedObject:\n    _instances = []\n    \n    def __init__(self, name):\n        self.name = name\n        TrackedObject._instances.append(self)\n    \n    @classmethod\n    def get_all_instances(cls):\n        return [obj for obj in cls._instances]\n    \n    @classmethod\n    def count_instances(cls):\n        return len(cls._instances)\n", "tests": "def test_tracked_object():\n    import gc\n    TrackedObject._instances = []\n    a = TrackedObject('a')\n    b = TrackedObject('b')\n    assert TrackedObject.count_instances() == 2\n    del a\n    gc.collect()\n    assert TrackedObject.count_instances() == 1\n    instances = TrackedObject.get_all_instances()\n    assert len(instances) == 1\n    assert instances[0].name == 'b'\n", "category": "bugfix", "topic": "gc_weak_tracking", "tier": 5, "starter_check": "fail"}
{"task_id": "tier4_functools_wraps_01", "prompt": "Fix this decorator that should preserve the wrapped function's metadata.", "signature": "def log_calls(func):", "starter_code": "def log_calls(func):\n    def wrapper(*args, **kwargs):\n        print(f'Calling {func.__name__}')\n        return func(*args, **kwargs)\n    return wrapper\n", "tests": "def test_log_calls():\n    @log_calls\n    def greet(name):\n        '''Greet someone by name.'''\n        return f'Hello, {name}'\n    assert greet.__name__ == 'greet'\n    assert greet.__doc__ == 'Greet someone by name.'\n    assert greet('World') == 'Hello, World'\n", "category": "bugfix", "topic": "functools", "tier": 4, "starter_check": "fail"}
{"task_id": "tier5_thread_local_01", "prompt": "Fix this thread-local storage implementation that should isolate data between threads.", "signature": "class ThreadLocalContext:", "starter_code": "class ThreadLocalContext:\n    _data = {}\n    \n    def set(self, key, value):\n        self._data[key] = value\n    \n    def get(self, key, default=None):\n        return self._data.get(key, default)\n    \n    def clear(self):\n        self._data.clear()\n", "tests": "def test_thread_local_context():\n    import threading\n    import time\n    ctx = ThreadLocalContext()\n    results = {}\n    def worker(thread_id):\n        ctx.set('id', thread_id)\n        time.sleep(0.1)\n        results[thread_id] = ctx.get('id')\n    threads = [threading.Thread(target=worker, args=(i,)) for i in range(5)]\n    for t in threads:\n        t.start()\n    for t in threads:\n        t.join()\n    for thread_id, value in results.items():\n        assert value == thread_id\n", "category": "bugfix", "topic": "thread_local", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_semaphore_release_01", "prompt": "Fix this bounded semaphore that should prevent over-release.", "signature": "class BoundedSemaphore:", "starter_code": "import threading\n\nclass BoundedSemaphore:\n    def __init__(self, value=1):\n        self._value = value\n        self._initial = value\n        self._lock = threading.Lock()\n        self._condition = threading.Condition(self._lock)\n    \n    def acquire(self, blocking=True):\n        with self._condition:\n            while self._value == 0:\n                if not blocking:\n                    return False\n                self._condition.wait()\n            self._value -= 1\n            return True\n    \n    def release(self):\n        with self._condition:\n            self._value += 1\n            self._condition.notify()\n", "tests": "def test_bounded_semaphore():\n    sem = BoundedSemaphore(2)\n    sem.acquire()\n    sem.acquire()\n    sem.release()\n    sem.release()\n    try:\n        sem.release()\n        assert False, 'Should raise ValueError on over-release'\n    except ValueError:\n        pass\n", "category": "bugfix", "topic": "semaphore", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_queue_timeout_01", "prompt": "Fix this queue implementation that should support timeout on blocking operations.", "signature": "class TimeoutQueue:", "starter_code": "import threading\nimport time\n\nclass TimeoutQueue:\n    def __init__(self, maxsize=0):\n        self._queue = []\n        self._maxsize = maxsize\n        self._lock = threading.Lock()\n    \n    def put(self, item, timeout=None):\n        with self._lock:\n            if self._maxsize > 0 and len(self._queue) >= self._maxsize:\n                raise Full('Queue is full')\n            self._queue.append(item)\n    \n    def get(self, timeout=None):\n        with self._lock:\n            if not self._queue:\n                raise Empty('Queue is empty')\n            return self._queue.pop(0)\n\nclass Full(Exception): pass\nclass Empty(Exception): pass\n", "tests": "def test_timeout_queue():\n    import threading\n    import time\n    q = TimeoutQueue(maxsize=2)\n    q.put(1)\n    q.put(2)\n    assert q.get() == 1\n    assert q.get() == 2\n    start = time.time()\n    try:\n        q.get(timeout=0.1)\n        assert False, 'Should raise Empty'\n    except Empty:\n        elapsed = time.time() - start\n        assert 0.05 < elapsed < 0.2\n    def delayed_put():\n        time.sleep(0.1)\n        q.put('delayed')\n    threading.Thread(target=delayed_put).start()\n    result = q.get(timeout=1.0)\n    assert result == 'delayed'\n", "category": "bugfix", "topic": "queue", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_rwlock_01", "prompt": "Fix this read-write lock that should allow multiple readers but only one writer.", "signature": "class ReadWriteLock:", "starter_code": "import threading\n\nclass ReadWriteLock:\n    def __init__(self):\n        pass\n    \n    def acquire_read(self):\n        pass  # Bug: no-op\n    \n    def release_read(self):\n        pass\n    \n    def acquire_write(self):\n        pass\n    \n    def release_write(self):\n        pass\n", "tests": "def test_read_write_lock():\n    import threading\n    import time\n    lock = ReadWriteLock()\n    data = {\"value\": 0}\n    results = []\n    def reader(n):\n        lock.acquire_read()\n        time.sleep(0.02)\n        results.append((\"read\", n, data[\"value\"]))\n        lock.release_read()\n    def writer(val):\n        lock.acquire_write()\n        time.sleep(0.05)\n        data[\"value\"] = val\n        lock.release_write()\n    t1 = threading.Thread(target=reader, args=(1,))\n    t2 = threading.Thread(target=writer, args=(42,))\n    t3 = threading.Thread(target=reader, args=(2,))\n    t1.start()\n    time.sleep(0.01)\n    t2.start()\n    time.sleep(0.01)\n    t3.start()\n    t1.join()\n    t2.join()\n    t3.join()\n    # Reader 1 should see 0, reader 2 after writer should see 42\n    r1 = [r for r in results if r[1] == 1][0][2]\n    r2 = [r for r in results if r[1] == 2][0][2]\n    assert r1 == 0, f\"Reader 1 should see 0, got {r1}\"\n    assert r2 == 42, f\"Reader 2 should see 42, got {r2}\"\n", "category": "bugfix", "topic": "rwlock", "tier": 5, "starter_check": "fail"}
{"task_id": "tier1_list_sum_01", "prompt": "Fix this function that should return the sum of all elements in a list.", "signature": "def list_sum(lst: list) -> int:", "starter_code": "def list_sum(lst: list) -> int:\n    total = 0\n    for i in range(len(lst)):\n        total += i\n    return total\n", "tests": "def test_list_sum():\n    assert list_sum([1, 2, 3]) == 6\n    assert list_sum([10]) == 10\n    assert list_sum([]) == 0\n", "category": "bugfix", "topic": "iteration", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_is_negative_01", "prompt": "Fix this function that should return True if x is negative.", "signature": "def is_negative(x: int) -> bool:", "starter_code": "def is_negative(x: int) -> bool:\n    return x > 0\n", "tests": "def test_is_negative():\n    assert is_negative(-5) == True\n    assert is_negative(5) == False\n    assert is_negative(0) == False\n", "category": "bugfix", "topic": "comparison", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_first_element_01", "prompt": "Fix this function that should return the first element of a list.", "signature": "def first_element(lst: list):", "starter_code": "def first_element(lst: list):\n    return lst[1]\n", "tests": "def test_first_element():\n    assert first_element([1, 2, 3]) == 1\n    assert first_element(['a', 'b']) == 'a'\n    assert first_element([True]) == True\n", "category": "bugfix", "topic": "indexing", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_double_value_01", "prompt": "Fix this function that should return double the input value.", "signature": "def double(x: int) -> int:", "starter_code": "def double(x: int) -> int:\n    return x + 2\n", "tests": "def test_double():\n    assert double(5) == 10\n    assert double(0) == 0\n    assert double(-3) == -6\n", "category": "bugfix", "topic": "arithmetic", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_is_empty_01", "prompt": "Fix this function that should return True if the list is empty.", "signature": "def is_empty(lst: list) -> bool:", "starter_code": "def is_empty(lst: list) -> bool:\n    return lst == None\n", "tests": "def test_is_empty():\n    assert is_empty([]) == True\n    assert is_empty([1]) == False\n    assert is_empty([1, 2, 3]) == False\n", "category": "bugfix", "topic": "comparison", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_string_length_01", "prompt": "Fix this function that should return the length of a string.", "signature": "def string_length(s: str) -> int:", "starter_code": "def string_length(s: str) -> int:\n    return s.count()\n", "tests": "def test_string_length():\n    assert string_length('hello') == 5\n    assert string_length('') == 0\n    assert string_length('a') == 1\n", "category": "bugfix", "topic": "method_call", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_subtract_01", "prompt": "Fix this function that should return a minus b.", "signature": "def subtract(a: int, b: int) -> int:", "starter_code": "def subtract(a: int, b: int) -> int:\n    return b - a\n", "tests": "def test_subtract():\n    assert subtract(5, 3) == 2\n    assert subtract(10, 4) == 6\n    assert subtract(3, 3) == 0\n", "category": "bugfix", "topic": "arithmetic", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_to_lowercase_01", "prompt": "Fix this function that should convert a string to lowercase.", "signature": "def to_lowercase(s: str) -> str:", "starter_code": "def to_lowercase(s: str) -> str:\n    return s.upper()\n", "tests": "def test_to_lowercase():\n    assert to_lowercase('HELLO') == 'hello'\n    assert to_lowercase('World') == 'world'\n    assert to_lowercase('abc') == 'abc'\n", "category": "bugfix", "topic": "string_method", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_square_01", "prompt": "Fix this function that should return the square of a number.", "signature": "def square(x: int) -> int:", "starter_code": "def square(x: int) -> int:\n    return x * 2\n", "tests": "def test_square():\n    assert square(4) == 16\n    assert square(3) == 9\n    assert square(0) == 0\n", "category": "bugfix", "topic": "arithmetic", "tier": 1, "starter_check": "fail"}
{"task_id": "tier1_concat_strings_01", "prompt": "Fix this function that should concatenate two strings.", "signature": "def concat(a: str, b: str) -> str:", "starter_code": "def concat(a: str, b: str) -> str:\n    return a - b\n", "tests": "def test_concat():\n    assert concat('hello', 'world') == 'helloworld'\n    assert concat('', 'test') == 'test'\n    assert concat('a', 'b') == 'ab'\n", "category": "bugfix", "topic": "string_handling", "tier": 1, "starter_check": "fail"}
{"task_id": "tier2_get_or_default_01", "prompt": "Fix this function that should return a dictionary value or a default, but only if the key is missing (not if the value is falsy).", "signature": "def get_or_default(d: dict, key, default):", "starter_code": "def get_or_default(d: dict, key, default):\n    return d.get(key) or default\n", "tests": "def test_get_or_default():\n    assert get_or_default({'a': 1}, 'a', 99) == 1\n    assert get_or_default({'a': 0}, 'a', 99) == 0\n    assert get_or_default({'a': ''}, 'a', 'default') == ''\n    assert get_or_default({'a': None}, 'a', 'default') == None\n    assert get_or_default({}, 'b', 99) == 99\n", "category": "bugfix", "topic": "dict_access", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_safe_divide_01", "prompt": "Fix this function that should safely divide two numbers, returning 0 for division by zero.", "signature": "def safe_divide(a: float, b: float) -> float:", "starter_code": "def safe_divide(a: float, b: float) -> float:\n    return a / b\n", "tests": "def test_safe_divide():\n    assert safe_divide(10, 2) == 5.0\n    assert safe_divide(0, 5) == 0.0\n    assert safe_divide(10, 0) == 0\n    assert safe_divide(-6, 2) == -3.0\n", "category": "bugfix", "topic": "exception_handling", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_remove_duplicates_01", "prompt": "Fix this function that removes duplicates while preserving order, but crashes on unhashable items.", "signature": "def remove_duplicates(lst: list) -> list:", "starter_code": "def remove_duplicates(lst: list) -> list:\n    seen = set()\n    result = []\n    for item in lst:\n        if item not in seen:\n            seen.add(item)\n            result.append(item)\n    return result\n", "tests": "def test_remove_duplicates():\n    assert remove_duplicates([1, 2, 2, 3, 1]) == [1, 2, 3]\n    assert remove_duplicates(['a', 'b', 'a']) == ['a', 'b']\n    assert remove_duplicates([[1, 2], [3, 4], [1, 2]]) == [[1, 2], [3, 4]]\n    assert remove_duplicates([]) == []\n", "category": "bugfix", "topic": "hashability", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_truncate_string_01", "prompt": "Fix this function that should truncate a string to max_length and add ellipsis if truncated.", "signature": "def truncate(s: str, max_length: int) -> str:", "starter_code": "def truncate(s: str, max_length: int) -> str:\n    if len(s) > max_length:\n        return s[:max_length] + '...'\n    return s\n", "tests": "def test_truncate():\n    assert truncate('hello', 10) == 'hello'\n    assert truncate('hello world', 5) == 'he...'\n    assert truncate('hello world', 8) == 'hello...'\n    assert truncate('hi', 2) == 'hi'\n    assert truncate('hello', 3) == '...'\n", "category": "bugfix", "topic": "string_logic", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_clamp_list_01", "prompt": "Fix this function that should clamp all values in a list to be within min and max bounds.", "signature": "def clamp_list(lst: list, min_val: int, max_val: int) -> list:", "starter_code": "def clamp_list(lst: list, min_val: int, max_val: int) -> list:\n    for i in range(len(lst)):\n        if lst[i] < min_val:\n            lst[i] = min_val\n        elif lst[i] > max_val:\n            lst[i] = max_val\n    return lst\n", "tests": "def test_clamp_list():\n    original = [1, 5, 10, 15, 20]\n    result = clamp_list(original, 5, 15)\n    assert result == [5, 5, 10, 15, 15]\n    assert original == [1, 5, 10, 15, 20]\n", "category": "bugfix", "topic": "mutation", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_merge_dicts_01", "prompt": "Fix this function that should merge two dictionaries without modifying the originals.", "signature": "def merge_dicts(d1: dict, d2: dict) -> dict:", "starter_code": "def merge_dicts(d1: dict, d2: dict) -> dict:\n    d1.update(d2)\n    return d1\n", "tests": "def test_merge_dicts():\n    a = {'x': 1, 'y': 2}\n    b = {'y': 3, 'z': 4}\n    result = merge_dicts(a, b)\n    assert result == {'x': 1, 'y': 3, 'z': 4}\n    assert a == {'x': 1, 'y': 2}\n    assert b == {'y': 3, 'z': 4}\n", "category": "bugfix", "topic": "mutation", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_find_all_indices_01", "prompt": "Fix this function that should find all indices of a value in a list.", "signature": "def find_all_indices(lst: list, val) -> list:", "starter_code": "def find_all_indices(lst: list, val) -> list:\n    return [i for i, x in enumerate(lst) if x is val]\n", "tests": "def test_find_all_indices():\n    assert find_all_indices([1, 2, 1, 3, 1], 1) == [0, 2, 4]\n    assert find_all_indices(['a', 'b', 'a'], 'a') == [0, 2]\n    assert find_all_indices([1, 2, 3], 4) == []\n    assert find_all_indices([1.0, 2, 1], 1) == [0, 2]\n", "category": "bugfix", "topic": "identity_vs_equality", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_round_to_places_01", "prompt": "Fix this function that should round a float to n decimal places.", "signature": "def round_to_places(x: float, n: int) -> float:", "starter_code": "def round_to_places(x: float, n: int) -> float:\n    multiplier = 10 ** n\n    return int(x * multiplier) / multiplier\n", "tests": "def test_round_to_places():\n    assert round_to_places(3.14159, 2) == 3.14\n    assert round_to_places(2.5, 0) == 3.0\n    assert round_to_places(2.555, 2) == 2.56\n    assert round_to_places(-2.5, 0) == -2.0\n", "category": "bugfix", "topic": "rounding", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_interleave_01", "prompt": "Fix this function that should interleave two lists, handling unequal lengths.", "signature": "def interleave(lst1: list, lst2: list) -> list:", "starter_code": "def interleave(lst1: list, lst2: list) -> list:\n    result = []\n    for a, b in zip(lst1, lst2):\n        result.append(a)\n        result.append(b)\n    return result\n", "tests": "def test_interleave():\n    assert interleave([1, 2, 3], ['a', 'b', 'c']) == [1, 'a', 2, 'b', 3, 'c']\n    assert interleave([1, 2, 3], ['a']) == [1, 'a', 2, 3]\n    assert interleave([1], ['a', 'b', 'c']) == [1, 'a', 'b', 'c']\n    assert interleave([], [1, 2]) == [1, 2]\n", "category": "bugfix", "topic": "iteration", "tier": 2, "starter_check": "fail"}
{"task_id": "tier2_is_valid_email_01", "prompt": "Fix this basic email validator that should check for @ and domain.", "signature": "def is_valid_email(email: str) -> bool:", "starter_code": "def is_valid_email(email: str) -> bool:\n    return '@' in email\n", "tests": "def test_is_valid_email():\n    assert is_valid_email('user@example.com') == True\n    assert is_valid_email('user@domain') == False\n    assert is_valid_email('invalid') == False\n    assert is_valid_email('@example.com') == False\n    assert is_valid_email('user@') == False\n    assert is_valid_email('user@sub.domain.com') == True\n", "category": "bugfix", "topic": "validation", "tier": 2, "starter_check": "fail"}
{"task_id": "tier3_balanced_parens_01", "prompt": "Fix this function that checks for balanced parentheses but doesn't handle multiple bracket types.", "signature": "def is_balanced(s: str) -> bool:", "starter_code": "def is_balanced(s: str) -> bool:\n    count = 0\n    for char in s:\n        if char == '(':\n            count += 1\n        elif char == ')':\n            count -= 1\n        if count < 0:\n            return False\n    return count == 0\n", "tests": "def test_is_balanced():\n    assert is_balanced('()') == True\n    assert is_balanced('([])') == True\n    assert is_balanced('([)]') == False\n    assert is_balanced('{[()]}') == True\n    assert is_balanced('((())') == False\n    assert is_balanced('') == True\n", "category": "bugfix", "topic": "stack", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_debounce_01", "prompt": "Fix this debounce decorator that should only call the function after no calls for the specified delay.", "signature": "def debounce(delay: float):", "starter_code": "import time\nimport threading\n\ndef debounce(delay: float):\n    def decorator(func):\n        timer = None\n        def wrapper(*args, **kwargs):\n            nonlocal timer\n            if timer:\n                timer.cancel()\n            timer = threading.Timer(delay, func, args, kwargs)\n            timer.start()\n        return wrapper\n    return decorator\n", "tests": "def test_debounce():\n    import time\n    results = []\n    @debounce(0.1)\n    def append_value(val):\n        results.append(val)\n    append_value(1)\n    append_value(2)\n    append_value(3)\n    time.sleep(0.05)\n    assert results == [], f'Called too early: {results}'\n    time.sleep(0.15)\n    assert results == [3], f'Expected [3], got {results}'\n    assert hasattr(append_value, '__wrapped__') or append_value.__name__ == 'append_value'\n", "category": "bugfix", "topic": "decorator", "tier": 3, "starter_check": "pass"}
{"task_id": "tier3_rate_limiter_01", "prompt": "Fix this rate limiter that should allow n calls per time window.", "signature": "class RateLimiter:", "starter_code": "import time\n\nclass RateLimiter:\n    def __init__(self, max_calls: int, window_seconds: float):\n        self.max_calls = max_calls\n        self.window = window_seconds\n        self.calls = []\n    \n    def allow(self) -> bool:\n        now = time.time()\n        self.calls = [t for t in self.calls if now - t < self.window]\n        if len(self.calls) < self.max_calls:\n            self.calls.append(now)\n            return True\n        return False\n", "tests": "def test_rate_limiter():\n    import time\n    limiter = RateLimiter(3, 0.1)\n    assert limiter.allow() == True\n    assert limiter.allow() == True\n    assert limiter.allow() == True\n    assert limiter.allow() == False\n    time.sleep(0.15)\n    assert limiter.allow() == True\n    limiter2 = RateLimiter(2, 0.1)\n    limiter2.allow()\n    limiter2.allow()\n    assert hasattr(limiter2, 'remaining') or hasattr(limiter2, 'time_until_next'), 'Missing method'\n", "category": "bugfix", "topic": "rate_limiting", "tier": 3, "starter_check": "pass"}
{"task_id": "tier3_run_length_encode_01", "prompt": "Fix this run-length encoder that loses the last run.", "signature": "def rle_encode(s: str) -> list:", "starter_code": "def rle_encode(s: str) -> list:\n    if not s:\n        return []\n    result = []\n    count = 1\n    for i in range(1, len(s)):\n        if s[i] == s[i-1]:\n            count += 1\n        else:\n            result.append((s[i-1], count))\n            count = 1\n    return result\n", "tests": "def test_rle_encode():\n    assert rle_encode('aaabbc') == [('a', 3), ('b', 2), ('c', 1)]\n    assert rle_encode('aaa') == [('a', 3)]\n    assert rle_encode('abc') == [('a', 1), ('b', 1), ('c', 1)]\n    assert rle_encode('') == []\n    assert rle_encode('a') == [('a', 1)]\n", "category": "bugfix", "topic": "loop_boundary", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_dedupe_sorted_01", "prompt": "Fix this function that removes consecutive duplicates but also needs to handle the mutation issue.", "signature": "def dedupe_consecutive(lst: list) -> list:", "starter_code": "def dedupe_consecutive(lst: list) -> list:\n    if not lst:\n        return []\n    i = 0\n    while i < len(lst) - 1:\n        if lst[i] == lst[i + 1]:\n            lst.pop(i + 1)\n        else:\n            i += 1\n    return lst\n", "tests": "def test_dedupe_consecutive():\n    original = [1, 1, 2, 2, 2, 3, 3, 1, 1]\n    result = dedupe_consecutive(original)\n    assert result == [1, 2, 3, 1]\n    assert original == [1, 1, 2, 2, 2, 3, 3, 1, 1]\n", "category": "bugfix", "topic": "mutation", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_once_decorator_01", "prompt": "Fix this decorator that should only execute the function once and cache the result.", "signature": "def once(func):", "starter_code": "def once(func):\n    called = False\n    result = None\n    def wrapper(*args, **kwargs):\n        if not called:\n            result = func(*args, **kwargs)\n            called = True\n        return result\n    return wrapper\n", "tests": "def test_once():\n    call_count = [0]\n    @once\n    def expensive():\n        call_count[0] += 1\n        return 'computed'\n    assert expensive() == 'computed'\n    assert expensive() == 'computed'\n    assert expensive() == 'computed'\n    assert call_count[0] == 1\n", "category": "bugfix", "topic": "closure", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_trie_search_01", "prompt": "Fix this trie that should support prefix search but returns wrong results.", "signature": "class Trie:", "starter_code": "class Trie:\n    def __init__(self):\n        self.children = {}\n        self.is_word = False\n    \n    def insert(self, word: str):\n        node = self\n        for char in word:\n            if char not in node.children:\n                node.children[char] = Trie()\n            node = node.children[char]\n        node.is_word = True\n    \n    def search(self, word: str) -> bool:\n        node = self\n        for char in word:\n            if char not in node.children:\n                return False\n            node = node.children[char]\n        return True\n    \n    def starts_with(self, prefix: str) -> bool:\n        return self.search(prefix)\n", "tests": "def test_trie():\n    t = Trie()\n    t.insert('hello')\n    t.insert('help')\n    t.insert('world')\n    assert t.search('hello') == True\n    assert t.search('hell') == False\n    assert t.search('help') == True\n    assert t.starts_with('hel') == True\n    assert t.starts_with('wor') == True\n    assert t.starts_with('abc') == False\n", "category": "bugfix", "topic": "data_structure", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_matrix_transpose_01", "prompt": "Fix this matrix transpose that doesn't handle non-square matrices.", "signature": "def transpose(matrix: list) -> list:", "starter_code": "def transpose(matrix: list) -> list:\n    n = len(matrix)\n    for i in range(n):\n        for j in range(i + 1, n):\n            matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j]\n    return matrix\n", "tests": "def test_transpose():\n    assert transpose([[1, 2, 3], [4, 5, 6]]) == [[1, 4], [2, 5], [3, 6]]\n    assert transpose([[1, 2], [3, 4], [5, 6]]) == [[1, 3, 5], [2, 4, 6]]\n    assert transpose([[1]]) == [[1]]\n    original = [[1, 2], [3, 4]]\n    transpose(original)\n    assert original == [[1, 2], [3, 4]]\n", "category": "bugfix", "topic": "matrix", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_partition_list_01", "prompt": "Fix this function that partitions a list into two based on a predicate.", "signature": "def partition(lst: list, predicate) -> tuple:", "starter_code": "def partition(lst: list, predicate) -> tuple:\n    true_list = []\n    false_list = []\n    for item in lst:\n        if predicate(item):\n            true_list.append(item)\n        false_list.append(item)\n    return true_list, false_list\n", "tests": "def test_partition():\n    evens, odds = partition([1, 2, 3, 4, 5], lambda x: x % 2 == 0)\n    assert evens == [2, 4]\n    assert odds == [1, 3, 5]\n    pos, neg = partition([-1, 2, -3, 4], lambda x: x > 0)\n    assert pos == [2, 4]\n    assert neg == [-1, -3]\n", "category": "bugfix", "topic": "control_flow", "tier": 3, "starter_check": "fail"}
{"task_id": "tier3_memoize_recursive_01", "prompt": "Fix this memoized fibonacci that doesn't properly share cache between calls.", "signature": "def make_fib():", "starter_code": "def make_fib():\n    def fib(n, cache={}):\n        if n < 2:\n            return n\n        if n in cache:\n            return cache[n]\n        result = fib(n-1, {}) + fib(n-2, {})\n        cache[n] = result\n        return result\n    return fib\n", "tests": "def test_memoize_recursive():\n    fib = make_fib()\n    assert fib(0) == 0\n    assert fib(1) == 1\n    assert fib(10) == 55\n    assert fib(30) == 832040\n    import time\n    start = time.time()\n    fib(35)\n    elapsed = time.time() - start\n    assert elapsed < 1.0\n", "category": "bugfix", "topic": "memoization", "tier": 3, "starter_check": "fail"}
{"task_id": "tier4_total_ordering_01", "prompt": "Fix this class that should support all comparison operators but only defines __eq__ and __lt__.", "signature": "class Version:", "starter_code": "class Version:\n    def __init__(self, major, minor, patch):\n        self.major = major\n        self.minor = minor\n        self.patch = patch\n    \n    def __eq__(self, other):\n        if not isinstance(other, Version):\n            return NotImplemented\n        return (self.major, self.minor, self.patch) == (other.major, other.minor, other.patch)\n    \n    def __lt__(self, other):\n        if not isinstance(other, Version):\n            return NotImplemented\n        return (self.major, self.minor, self.patch) < (other.major, other.minor, other.patch)\n", "tests": "def test_version():\n    v1 = Version(1, 0, 0)\n    v2 = Version(1, 0, 1)\n    v3 = Version(1, 0, 0)\n    assert v1 < v2\n    assert v2 > v1\n    assert v1 <= v3\n    assert v1 >= v3\n    assert v1 == v3\n    assert v1 != v2\n    versions = [Version(2, 0, 0), Version(1, 0, 0), Version(1, 5, 0)]\n    assert sorted(versions)[0] == Version(1, 0, 0)\n", "category": "bugfix", "topic": "total_ordering", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_cached_property_01", "prompt": "Fix this cached property that should compute value once and cache it.", "signature": "class cached_property:", "starter_code": "class cached_property:\n    def __init__(self, func):\n        self.func = func\n    \n    def __get__(self, obj, objtype=None):\n        if obj is None:\n            return self\n        value = self.func(obj)\n        return value\n", "tests": "def test_cached_property():\n    call_count = [0]\n    class MyClass:\n        @cached_property\n        def expensive(self):\n            call_count[0] += 1\n            return 'computed'\n    obj = MyClass()\n    assert obj.expensive == 'computed'\n    assert obj.expensive == 'computed'\n    assert obj.expensive == 'computed'\n    assert call_count[0] == 1\n    obj2 = MyClass()\n    assert obj2.expensive == 'computed'\n    assert call_count[0] == 2\n", "category": "bugfix", "topic": "descriptor", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_class_decorator_01", "prompt": "Fix this class decorator that should add a timestamp to all instances.", "signature": "def timestamped(cls):", "starter_code": "import time\n\ndef timestamped(cls):\n    return cls  # Bug: doesn't add created_at\n", "tests": "def test_timestamped():\n    @timestamped\n    class NoInit:\n        pass\n    obj = NoInit()\n    assert hasattr(obj, \"created_at\")\n", "category": "bugfix", "topic": "class_decorator", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_subclass_hook_01", "prompt": "Fix this ABC that should recognize classes implementing the protocol via __subclasshook__.", "signature": "class Drawable:", "starter_code": "from abc import ABC, abstractmethod\n\nclass Drawable(ABC):\n    @abstractmethod\n    def draw(self):\n        pass\n    \n    @classmethod\n    def __subclasshook__(cls, C):\n        if hasattr(C, 'draw'):\n            return True\n        return NotImplemented\n", "tests": "def test_drawable():\n    class Circle(Drawable):\n        def draw(self):\n            return 'circle'\n    class Square:\n        def draw(self):\n            return 'square'\n    class NotCallable:\n        draw = 'not callable'\n    class Empty:\n        pass\n    assert isinstance(Circle(), Drawable)\n    assert isinstance(Square(), Drawable)\n    assert not isinstance(Empty(), Drawable)\n    assert not isinstance(NotCallable(), Drawable), 'Non-callable draw should not satisfy protocol'\n", "category": "bugfix", "topic": "abc_hook", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_new_vs_init_01", "prompt": "Fix this singleton class that uses __new__ incorrectly.", "signature": "class Singleton:", "starter_code": "class Singleton:\n    _instance = None\n    \n    def __new__(cls, value):\n        if cls._instance is None:\n            cls._instance = super().__new__(cls)\n        return cls._instance\n    \n    def __init__(self, value):\n        self.value = value\n", "tests": "def test_singleton():\n    s1 = Singleton('first')\n    s2 = Singleton('second')\n    assert s1 is s2\n    assert s1.value == 'first'\n    assert s2.value == 'first'\n", "category": "bugfix", "topic": "new_init", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_method_resolution_01", "prompt": "Fix this diamond inheritance that should properly call all parent __init__ methods.", "signature": "class D:", "starter_code": "class A:\n    def __init__(self):\n        self.a = 'A'\n\nclass B(A):\n    def __init__(self):\n        A.__init__(self)\n        self.b = 'B'\n\nclass C(A):\n    def __init__(self):\n        A.__init__(self)\n        self.c = 'C'\n\nclass D(B, C):\n    def __init__(self):\n        B.__init__(self)\n        C.__init__(self)\n        self.d = 'D'\n", "tests": "def test_diamond():\n    init_count = [0]\n    orig_a_init = A.__init__\n    def counting_init(self):\n        init_count[0] += 1\n        self.a = 'A'\n    A.__init__ = counting_init\n    try:\n        d = D()\n        assert hasattr(d, 'a')\n        assert hasattr(d, 'b')\n        assert hasattr(d, 'c')\n        assert hasattr(d, 'd')\n        assert init_count[0] == 1, f'A.__init__ called {init_count[0]} times - diamond problem'\n    finally:\n        A.__init__ = orig_a_init\n", "category": "bugfix", "topic": "mro", "tier": 4, "starter_check": "pass"}
{"task_id": "tier4_iter_protocol_01", "prompt": "Fix this iterator class that should be reusable (iterable, not just iterator).", "signature": "class Range:", "starter_code": "class Range:\n    def __init__(self, start, end):\n        self.start = start\n        self.end = end\n        self.current = start\n    \n    def __iter__(self):\n        return self\n    \n    def __next__(self):\n        if self.current >= self.end:\n            raise StopIteration\n        value = self.current\n        self.current += 1\n        return value\n", "tests": "def test_range():\n    r = Range(0, 3)\n    assert list(r) == [0, 1, 2]\n    assert list(r) == [0, 1, 2]\n    assert list(r) == [0, 1, 2]\n", "category": "bugfix", "topic": "iterator_protocol", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_context_decorator_01", "prompt": "Fix this class that should work both as a decorator and context manager.", "signature": "class Timer:", "starter_code": "import time\n\nclass Timer:\n    def __init__(self, name='Timer'):\n        self.name = name\n        self.elapsed = None\n    \n    def __enter__(self):\n        self.start = time.time()\n        return self\n    \n    def __exit__(self, *args):\n        self.elapsed = time.time() - self.start\n        return False\n    \n    def __call__(self, func):\n        def wrapper(*args, **kwargs):\n            self.start = time.time()\n            result = func(*args, **kwargs)\n            self.elapsed = time.time() - self.start\n            return result\n        return wrapper\n", "tests": "def test_timer():\n    import time\n    with Timer('test') as t:\n        time.sleep(0.05)\n    assert t.elapsed is not None\n    assert t.elapsed > 0.03\n    @Timer('decorated')\n    def slow_func():\n        '''My docstring.'''\n        time.sleep(0.01)\n        return 'done'\n    assert slow_func() == 'done'\n    assert slow_func.__name__ == 'slow_func', f'__name__ not preserved: {slow_func.__name__}'\n    assert slow_func.__doc__ is not None, '__doc__ not preserved'\n", "category": "bugfix", "topic": "dual_use", "tier": 4, "starter_check": "pass"}
{"task_id": "tier4_setattr_guard_01", "prompt": "Fix this immutable class that should prevent attribute modification after creation.", "signature": "class Immutable:", "starter_code": "class Immutable:\n    def __init__(self, **kwargs):\n        pass  # Bug: doesn't set any attributes\n", "tests": "def test_immutable():\n    obj = Immutable(x=1)\n    assert obj.x == 1\n", "category": "bugfix", "topic": "setattr", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_call_method_01", "prompt": "Fix this callable class that should maintain state across calls.", "signature": "class Counter:", "starter_code": "class Counter:\n    def __init__(self, start=0):\n        self.count = start\n    \n    def __call__(self):\n        return -1  # Bug: always returns -1\n", "tests": "def test_counter():\n    c = Counter()\n    assert c() == 0\n    assert c() == 1\n    assert c.count == 2  # After 2 calls, count should be 2\n", "category": "bugfix", "topic": "callable", "tier": 4, "starter_check": "pass"}
{"task_id": "tier5_async_iterator_01", "prompt": "Fix this async iterator that should yield values with delays.", "signature": "class AsyncRange:", "starter_code": "class AsyncRange:\n    def __init__(self, start, end, delay=0.1):\n        self.start = start\n        self.end = end\n        self.delay = delay\n        self.current = start\n    \n    def __aiter__(self):\n        return self\n    \n    async def __anext__(self):\n        import asyncio\n        if self.current >= self.end:\n            raise StopAsyncIteration\n        await asyncio.sleep(self.delay)\n        value = self.current\n        self.current += 1\n        return value\n", "tests": "def test_async_range():\n    import asyncio\n    async def run():\n        results = []\n        async for i in AsyncRange(0, 3, 0.01):\n            results.append(i)\n        assert results == [0, 1, 2]\n        r = AsyncRange(0, 2, 0.01)\n        results2 = []\n        async for i in r:\n            results2.append(i)\n        results3 = []\n        async for i in r:\n            results3.append(i)\n        assert results2 == [0, 1]\n        assert results3 == [0, 1]\n    asyncio.run(run())\n", "category": "bugfix", "topic": "async_iterator", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_async_lock_01", "prompt": "Fix this async lock that should prevent concurrent access to a resource.", "signature": "class AsyncLock:", "starter_code": "import asyncio\n\nclass AsyncLock:\n    def __init__(self):\n        pass\n    \n    async def acquire(self):\n        pass  # Bug: no locking\n    \n    def release(self):\n        pass\n    \n    async def __aenter__(self):\n        return self\n    \n    async def __aexit__(self, *args):\n        pass\n", "tests": "def test_async_lock():\n    import asyncio\n    async def run():\n        lock = AsyncLock()\n        results = []\n        async def worker(n):\n            async with lock:\n                results.append(f'{n}_start')\n                await asyncio.sleep(0.02)\n                results.append(f'{n}_end')\n        await asyncio.gather(worker(1), worker(2), worker(3))\n        for i in range(0, len(results), 2):\n            start_n = results[i].split('_')[0]\n            end_n = results[i+1].split('_')[0]\n            assert start_n == end_n, f'Interleaved: {results}'\n    asyncio.run(run())\n", "category": "bugfix", "topic": "async_lock", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_event_emitter_01", "prompt": "Fix this event emitter that should support multiple listeners and proper cleanup.", "signature": "class EventEmitter:", "starter_code": "class EventEmitter:\n    def __init__(self):\n        self._listeners = {}\n    \n    def on(self, event, callback):\n        pass  # Bug: doesn't register\n    \n    def off(self, event, callback):\n        pass\n    \n    def emit(self, event, *args, **kwargs):\n        pass  # Bug: doesn't call handlers\n", "tests": "def test_event_emitter():\n    emitter = EventEmitter()\n    results = []\n    def h1(x): results.append(f'h1:{x}')\n    def h2(x): results.append(f'h2:{x}')\n    emitter.on('data', h1)\n    emitter.on('data', h2)\n    emitter.emit('data', 'test')\n    assert 'h1:test' in results\n    assert 'h2:test' in results\n    def self_remove(x):\n        results.append(f'self:{x}')\n        emitter.off('special', self_remove)\n    emitter.on('special', self_remove)\n    emitter.on('special', h1)\n    emitter.emit('special', 'event')\n    assert 'self:event' in results\n", "category": "bugfix", "topic": "event_emitter", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_lazy_import_01", "prompt": "Fix this lazy import module that should defer imports until first access.", "signature": "class LazyModule:", "starter_code": "import sys\n\nclass LazyModule:\n    def __init__(self, name):\n        self._name = name\n    \n    def __getattr__(self, name):\n        return None  # Bug: doesn't load module\n", "tests": "def test_lazy_module():\n    import sys\n    if 'json' in sys.modules:\n        del sys.modules['json']\n    lazy_json = LazyModule('json')\n    assert 'json' not in sys.modules, 'Imported too early'\n    result = lazy_json.dumps({'a': 1})\n    assert result == '{\"a\": 1}'\n    assert 'json' in sys.modules\n", "category": "bugfix", "topic": "lazy_import", "tier": 5, "starter_check": "pass"}
{"task_id": "tier5_task_scheduler_01", "prompt": "Fix this task scheduler that should run tasks with dependencies in correct order.", "signature": "class TaskScheduler:", "starter_code": "class TaskScheduler:\n    def __init__(self):\n        self.tasks = {}\n        self.dependencies = {}\n    \n    def add_task(self, name, func, depends_on=None):\n        self.tasks[name] = func\n    \n    def run_all(self):\n        return {}  # Bug: doesn't run tasks\n", "tests": "def test_task_scheduler():\n    scheduler = TaskScheduler()\n    order = []\n    scheduler.add_task('a', lambda: order.append('a') or 'A')\n    scheduler.add_task('b', lambda: order.append('b') or 'B', depends_on=['a'])\n    scheduler.add_task('c', lambda: order.append('c') or 'C', depends_on=['a'])\n    scheduler.add_task('d', lambda: order.append('d') or 'D', depends_on=['b', 'c'])\n    results = scheduler.run_all()\n    assert order.index('a') < order.index('b')\n    assert order.index('a') < order.index('c')\n    assert order.index('b') < order.index('d')\n    scheduler2 = TaskScheduler()\n    scheduler2.add_task('x', lambda: 'X', depends_on=['y'])\n    scheduler2.add_task('y', lambda: 'Y', depends_on=['x'])\n    try:\n        scheduler2.run_all()\n        assert False, 'Should detect cycle'\n    except ValueError as e:\n        assert 'cycle' in str(e).lower()\n", "category": "bugfix", "topic": "task_scheduler", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_object_pool_01", "prompt": "Fix this object pool that should reuse objects efficiently.", "signature": "class ObjectPool:", "starter_code": "class ObjectPool:\n    def __init__(self, factory, max_size=10):\n        self.factory = factory\n    \n    def acquire(self):\n        return None  # Bug: doesn't create objects\n    \n    def release(self, obj):\n        pass\n", "tests": "def test_object_pool():\n    import threading\n    created = [0]\n    def factory():\n        created[0] += 1\n        return {'id': created[0]}\n    pool = ObjectPool(factory, max_size=2)\n    obj1 = pool.acquire()\n    obj2 = pool.acquire()\n    assert created[0] == 2\n    pool.release(obj1)\n    obj3 = pool.acquire()\n    assert created[0] == 2, 'Should reuse'\n    assert obj3 is obj1\n    errors = []\n    def worker():\n        try:\n            for _ in range(100):\n                o = pool.acquire()\n                pool.release(o)\n        except Exception as e:\n            errors.append(e)\n    threads = [threading.Thread(target=worker) for _ in range(5)]\n    for t in threads:\n        t.start()\n    for t in threads:\n        t.join()\n    assert len(errors) == 0, f'Thread errors: {errors}'\n", "category": "bugfix", "topic": "object_pool", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_proxy_object_01", "prompt": "Fix this proxy object that should forward all attribute access while tracking calls.", "signature": "class TracingProxy:", "starter_code": "class TracingProxy:\n    def __init__(self, target):\n        self._target = target\n        self._calls = []\n    \n    def __getattr__(self, name):\n        return None  # Bug: doesn't proxy\n    \n    def get_calls(self):\n        return self._calls\n", "tests": "def test_tracing_proxy():\n    class Calculator:\n        def __init__(self):\n            self.value = 0\n        def add(self, x):\n            self.value += x\n            return self.value\n    calc = Calculator()\n    proxy = TracingProxy(calc)\n    assert proxy.add(5) == 5\n    assert proxy.add(3) == 8\n    assert proxy.value == 8, 'Property access failed'\n    calls = proxy.get_calls()\n    assert len(calls) == 2\n    assert calls[0][0] == 'add'\n", "category": "bugfix", "topic": "proxy", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_dependency_injection_01", "prompt": "Fix this dependency injection container that should handle singleton vs transient lifetimes.", "signature": "class Container:", "starter_code": "class Container:\n    def __init__(self):\n        self._registry = {}\n    \n    def register(self, interface, implementation, singleton=False):\n        pass  # Bug: doesn't register\n    \n    def resolve(self, interface):\n        return None  # Bug: doesn't resolve\n", "tests": "def test_container():\n    container = Container()\n    class Database:\n        count = 0\n        def __init__(self):\n            Database.count += 1\n    class Logger:\n        count = 0\n        def __init__(self):\n            Logger.count += 1\n    Database.count = 0\n    Logger.count = 0\n    container.register('db', Database, singleton=True)\n    container.register('logger', Logger, singleton=False)\n    db1 = container.resolve('db')\n    db2 = container.resolve('db')\n    assert db1 is db2, 'Singleton not working'\n    assert Database.count == 1\n    log1 = container.resolve('logger')\n    log2 = container.resolve('logger')\n    assert log1 is not log2\n    assert Logger.count == 2\n", "category": "bugfix", "topic": "di_container", "tier": 5, "starter_check": "pass"}
{"task_id": "tier5_circuit_breaker_01", "prompt": "Fix this circuit breaker that should prevent cascading failures.", "signature": "class CircuitBreaker:", "starter_code": "class CircuitBreaker:\n    def __init__(self, failure_threshold=5, reset_timeout=30):\n        self.state = 'closed'\n    \n    def call(self, func, *args, **kwargs):\n        return None  # Bug: doesn't call function\n\nclass CircuitOpenError(Exception): pass\n", "tests": "def test_circuit_breaker():\n    import time\n    cb = CircuitBreaker(failure_threshold=3, reset_timeout=0.1)\n    def success(): return 'ok'\n    def failure(): raise ValueError('fail')\n    assert cb.call(success) == 'ok'\n    for _ in range(3):\n        try:\n            cb.call(failure)\n        except ValueError:\n            pass\n    assert cb.state == 'open', f'State should be open, got {cb.state}'\n    try:\n        cb.call(success)\n        assert False, 'Should raise CircuitOpenError'\n    except CircuitOpenError:\n        pass\n    time.sleep(0.15)\n    assert cb.call(success) == 'ok'\n    assert cb.state == 'closed'\n", "category": "bugfix", "topic": "circuit_breaker", "tier": 5, "starter_check": "pass"}
{"task_id": "tier5_state_machine_01", "prompt": "Fix this state machine that should enforce valid transitions.", "signature": "class StateMachine:", "starter_code": "class StateMachine:\n    def __init__(self, initial_state):\n        self.state = initial_state\n    \n    def add_transition(self, from_state, to_state, event):\n        pass  # Bug: doesn't add transitions\n    \n    def trigger(self, event):\n        pass  # Bug: doesn't transition\n\nclass InvalidTransitionError(Exception): pass\n", "tests": "def test_state_machine():\n    sm = StateMachine('idle')\n    sm.add_transition('idle', 'running', 'start')\n    sm.add_transition('running', 'paused', 'pause')\n    sm.add_transition('paused', 'running', 'resume')\n    sm.add_transition('running', 'idle', 'stop')\n    assert sm.state == 'idle'\n    sm.trigger('start')\n    assert sm.state == 'running'\n    try:\n        sm.trigger('resume')\n        assert False, 'Should raise InvalidTransitionError'\n    except InvalidTransitionError:\n        pass\n    assert sm.state == 'running', 'State changed despite invalid transition'\n", "category": "bugfix", "topic": "state_machine", "tier": 5, "starter_check": "pass"}
{"task_id": "tier5_async_semaphore_01", "prompt": "Fix this async semaphore that should limit concurrent access to a resource.", "signature": "class AsyncSemaphore:", "starter_code": "import asyncio\n\nclass AsyncSemaphore:\n    def __init__(self, value=1):\n        pass\n    \n    async def acquire(self):\n        pass  # Bug: no semaphore logic\n    \n    def release(self):\n        pass\n    \n    async def __aenter__(self):\n        return self\n    \n    async def __aexit__(self, *args):\n        pass\n", "tests": "def test_async_semaphore():\n    import asyncio\n    async def run():\n        sem = AsyncSemaphore(2)\n        max_concurrent = [0]\n        current = [0]\n        async def worker():\n            async with sem:\n                current[0] += 1\n                max_concurrent[0] = max(max_concurrent[0], current[0])\n                await asyncio.sleep(0.02)\n                current[0] -= 1\n        await asyncio.gather(*[worker() for _ in range(5)])\n        assert max_concurrent[0] <= 2, f'Max was {max_concurrent[0]}'\n    asyncio.run(run())\n", "category": "bugfix", "topic": "async_semaphore", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_pubsub_01", "prompt": "Fix this pub/sub system that should handle async subscribers and proper cleanup.", "signature": "class PubSub:", "starter_code": "class PubSub:\n    def __init__(self):\n        self._subscribers = {}\n    \n    def subscribe(self, topic, callback):\n        return lambda: None  # Bug: doesn't subscribe\n    \n    async def publish(self, topic, message):\n        pass  # Bug: doesn't publish\n", "tests": "def test_pubsub():\n    import asyncio\n    async def run():\n        ps = PubSub()\n        results = []\n        def sync_handler(msg):\n            results.append(f'sync:{msg}')\n        async def async_handler(msg):\n            await asyncio.sleep(0.01)\n            results.append(f'async:{msg}')\n        unsub = ps.subscribe('news', sync_handler)\n        ps.subscribe('news', async_handler)\n        await ps.publish('news', 'hello')\n        assert 'sync:hello' in results\n        assert 'async:hello' in results\n        unsub()\n        results.clear()\n        await ps.publish('news', 'world')\n        assert 'sync:world' not in results\n        assert 'async:world' in results\n    asyncio.run(run())\n", "category": "bugfix", "topic": "pubsub", "tier": 5, "starter_check": "pass"}
{"task_id": "tier5_coroutine_wrapper_01", "prompt": "Fix this wrapper that should convert sync functions to work in async context.", "signature": "def run_in_executor(func):", "starter_code": "import asyncio\nimport functools\n\ndef run_in_executor(func):\n    @functools.wraps(func)\n    async def wrapper(*args, **kwargs):\n        loop = asyncio.get_event_loop()\n        return await loop.run_in_executor(None, func, *args)\n    return wrapper\n", "tests": "def test_run_in_executor():\n    import asyncio\n    import time\n    @run_in_executor\n    def blocking_io(duration, value, multiplier=1):\n        time.sleep(duration)\n        return value * multiplier\n    async def run():\n        start = time.time()\n        results = await asyncio.gather(\n            blocking_io(0.05, 5),\n            blocking_io(0.05, 10),\n            blocking_io(0.05, 15, multiplier=2)\n        )\n        elapsed = time.time() - start\n        assert results == [5, 10, 30], f'Got {results}'\n        assert elapsed < 0.15, f'Not parallel: {elapsed}s'\n    asyncio.run(run())\n", "category": "bugfix", "topic": "executor", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_memo_with_ttl_01", "prompt": "Fix this memoization decorator that should expire cached values after a TTL.", "signature": "def memoize_with_ttl(ttl_seconds: float):", "starter_code": "import time\nfrom functools import wraps\n\ndef memoize_with_ttl(ttl_seconds: float):\n    def decorator(func):\n        cache = {}\n        \n        @wraps(func)\n        def wrapper(*args):\n            now = time.time()\n            if args in cache:\n                result, timestamp = cache[args]\n                if now - timestamp < ttl_seconds:\n                    return result\n            result = func(*args)\n            cache[args] = (result, now)\n            return result\n        return wrapper\n    return decorator\n", "tests": "def test_memoize_with_ttl():\n    import time\n    call_count = [0]\n    @memoize_with_ttl(0.1)\n    def expensive(x):\n        call_count[0] += 1\n        return x * 2\n    assert expensive(5) == 10\n    assert expensive(5) == 10\n    assert call_count[0] == 1\n    time.sleep(0.15)\n    assert expensive(5) == 10\n    assert call_count[0] == 2\n    @memoize_with_ttl(0.1)\n    def with_list(lst):\n        return sum(lst)\n    assert with_list([1, 2, 3]) == 6\n    assert with_list([1, 2, 3]) == 6\n", "category": "bugfix", "topic": "memoization_ttl", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_retry_async_01", "prompt": "Fix this async retry decorator that should handle retries with exponential backoff.", "signature": "def async_retry(max_attempts: int, base_delay: float = 1.0):", "starter_code": "from functools import wraps\n\ndef async_retry(max_attempts, base_delay=1.0):\n    def decorator(func):\n        @wraps(func)\n        async def wrapper(*args, **kwargs):\n            raise RuntimeError('Not implemented')  # Bug: always fails\n        return wrapper\n    return decorator\n", "tests": "def test_async_retry():\n    import asyncio\n    async def run():\n        attempts = [0]\n        @async_retry(max_attempts=3, base_delay=0.01)\n        async def flaky():\n            attempts[0] += 1\n            if attempts[0] < 3:\n                raise ValueError('Not yet')\n            return 'success'\n        result = await flaky()\n        assert result == 'success'\n        assert attempts[0] == 3\n        attempts[0] = 0\n        @async_retry(max_attempts=2, base_delay=0.01)\n        async def always_fails():\n            attempts[0] += 1\n            raise RuntimeError('fail')\n        try:\n            await always_fails()\n            assert False, 'Should raise'\n        except RuntimeError:\n            pass\n        assert attempts[0] == 2\n    asyncio.run(run())\n", "category": "bugfix", "topic": "async_retry", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_cancellation_scope_01", "prompt": "Fix this cancellation scope that should cancel child tasks when the scope exits.", "signature": "class CancellationScope:", "starter_code": "import asyncio\n\nclass CancellationScope:\n    def __init__(self):\n        self.tasks = []\n    \n    async def __aenter__(self):\n        return self\n    \n    async def __aexit__(self, *args):\n        pass  # Bug: doesn't cancel tasks\n    \n    def spawn(self, coro):\n        return None  # Bug: doesn't spawn\n", "tests": "def test_cancellation_scope():\n    import asyncio\n    async def run():\n        results = []\n        async def worker(n, delay):\n            try:\n                await asyncio.sleep(delay)\n                results.append(f'done:{n}')\n            except asyncio.CancelledError:\n                results.append(f'cancelled:{n}')\n                raise\n        async with CancellationScope() as scope:\n            scope.spawn(worker(1, 0.01))\n            scope.spawn(worker(2, 1.0))\n            scope.spawn(worker(3, 1.0))\n            await asyncio.sleep(0.05)\n        assert 'done:1' in results\n        assert 'cancelled:2' in results\n        assert 'cancelled:3' in results\n    asyncio.run(run())\n", "category": "bugfix", "topic": "cancellation", "tier": 5, "starter_check": "pass"}
{"task_id": "tier4_reprlib_01", "prompt": "Fix this class that should have a useful repr that truncates long content.", "signature": "class DataContainer:", "starter_code": "class DataContainer:\n    def __init__(self, items):\n        self.items = items\n    \n    def __repr__(self):\n        return f'DataContainer({self.items})'\n", "tests": "def test_data_container():\n    small = DataContainer([1, 2, 3])\n    assert 'DataContainer' in repr(small)\n    assert '1' in repr(small)\n    large = DataContainer(list(range(1000)))\n    r = repr(large)\n    assert len(r) < 200\n    assert '...' in r\n", "category": "bugfix", "topic": "repr", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_format_spec_01", "prompt": "Fix this class that should support custom format specifications.", "signature": "class Temperature:", "starter_code": "class Temperature:\n    def __init__(self, celsius):\n        self.celsius = celsius\n    \n    def __format__(self, spec):\n        return str(self.celsius)\n", "tests": "def test_temperature():\n    t = Temperature(25)\n    assert f'{t}' == '25'\n    assert f'{t:c}' == '25C'\n    assert f'{t:f}' == '77.0F'\n    assert f'{t:k}' == '298.15K'\n    assert f'{t:.1f}' == '77.0F'\n", "category": "bugfix", "topic": "format_protocol", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_exit_stack_01", "prompt": "Fix this function that should manage multiple context managers dynamically.", "signature": "def process_files(filenames: list) -> list:", "starter_code": "def process_files(filenames: list) -> list:\n    return []  # Bug: doesn't read files\n", "tests": "def test_process_files():\n    import tempfile\n    import os\n    temps = []\n    for i in range(3):\n        f = tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt')\n        f.write(f'content{i}')\n        f.close()\n        temps.append(f.name)\n    try:\n        results = process_files(temps)\n        assert results == ['content0', 'content1', 'content2']\n        bad_temps = temps + ['/nonexistent/file.txt']\n        try:\n            process_files(bad_temps)\n            assert False, 'Should have raised FileNotFoundError'\n        except FileNotFoundError:\n            pass\n    finally:\n        for t in temps:\n            os.unlink(t)\n", "category": "bugfix", "topic": "exit_stack", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_partial_application_01", "prompt": "Fix this partial function application that should preserve function metadata.", "signature": "def create_logger(level: str):", "starter_code": "from functools import partial\n\ndef log_message(level, message, timestamp=None):\n    '''Log a message with level and optional timestamp.'''\n    import time\n    ts = timestamp or time.time()\n    return f'[{level}] {ts}: {message}'\n\ndef create_logger(level: str):\n    return partial(log_message, level)\n", "tests": "def test_create_logger():\n    info_logger = create_logger('INFO')\n    result = info_logger('test message', timestamp=12345)\n    assert '[INFO]' in result\n    assert 'test message' in result\n    assert info_logger.__doc__ is not None\n    assert 'Log a message' in info_logger.__doc__\n    assert info_logger.__name__ == 'log_message'\n", "category": "bugfix", "topic": "partial", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_namespace_package_01", "prompt": "Fix this class that simulates a namespace with attribute access and prevents accidental overwrites.", "signature": "class Namespace:", "starter_code": "class Namespace:\n    def __init__(self, **kwargs):\n        pass  # Bug: doesn't set attributes\n", "tests": "def test_namespace():\n    ns = Namespace(x=1, y=2)\n    assert ns.x == 1\n    assert ns.y == 2\n    error_raised = False\n    try:\n        ns.x = 10\n    except AttributeError:\n        error_raised = True\n    assert error_raised, 'Should not allow overwriting'\n    ns.z = 3\n    assert ns.z == 3\n", "category": "bugfix", "topic": "namespace", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_chainmap_01", "prompt": "Fix this configuration class that should support layered lookups with proper precedence.", "signature": "class LayeredConfig:", "starter_code": "class LayeredConfig:\n    def __init__(self):\n        self.layers = []\n    \n    def add_layer(self, config: dict):\n        self.layers.append(config)\n    \n    def get(self, key, default=None):\n        for layer in self.layers:\n            if key in layer:\n                return layer[key]\n        return default\n", "tests": "def test_layered_config():\n    config = LayeredConfig()\n    config.add_layer({'a': 1, 'b': 2})\n    config.add_layer({'b': 20, 'c': 30})\n    assert config.get('a') == 1\n    assert config.get('b') == 20\n    assert config.get('c') == 30\n    assert config.get('d', 'default') == 'default'\n    config.add_layer({'a': 100})\n    assert config.get('a') == 100\n", "category": "bugfix", "topic": "chainmap", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_bisect_custom_01", "prompt": "Fix this sorted container that should maintain sort order with custom key function.", "signature": "class SortedList:", "starter_code": "import bisect\n\nclass SortedList:\n    def __init__(self, key=None):\n        self.key = key or (lambda x: x)\n        self._items = []\n    \n    def insert(self, item):\n        bisect.insort(self._items, item)\n    \n    def __iter__(self):\n        return iter(self._items)\n    \n    def __len__(self):\n        return len(self._items)\n", "tests": "def test_sorted_list():\n    sl = SortedList()\n    sl.insert(3)\n    sl.insert(1)\n    sl.insert(2)\n    assert list(sl) == [1, 2, 3]\n    sl2 = SortedList(key=lambda x: -x)\n    sl2.insert(3)\n    sl2.insert(1)\n    sl2.insert(2)\n    assert list(sl2) == [3, 2, 1]\n    sl3 = SortedList(key=lambda x: x['priority'])\n    sl3.insert({'name': 'low', 'priority': 3})\n    sl3.insert({'name': 'high', 'priority': 1})\n    sl3.insert({'name': 'med', 'priority': 2})\n    assert [x['name'] for x in sl3] == ['high', 'med', 'low']\n", "category": "bugfix", "topic": "bisect", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_counter_ops_01", "prompt": "Fix this inventory class that should support arithmetic operations like Counter.", "signature": "class Inventory:", "starter_code": "class Inventory:\n    def __init__(self, items=None):\n        self.items = {}\n    \n    def __add__(self, other):\n        return Inventory()  # Bug: empty result\n    \n    def __sub__(self, other):\n        return Inventory()\n", "tests": "def test_inventory():\n    inv1 = Inventory({'apple': 5, 'banana': 3})\n    inv2 = Inventory({'apple': 2, 'orange': 4})\n    combined = inv1 + inv2\n    assert combined.items['apple'] == 7\n    assert combined.items['banana'] == 3\n    assert combined.items['orange'] == 4\n    diff = inv1 - inv2\n    assert diff.items['apple'] == 3\n    assert inv1.items['apple'] == 5, 'Original mutated'\n", "category": "bugfix", "topic": "counter_ops", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_defaultdict_factory_01", "prompt": "Fix this nested defaultdict that should auto-create nested levels.", "signature": "def nested_dict():", "starter_code": "from collections import defaultdict\n\ndef nested_dict():\n    return defaultdict(dict)\n", "tests": "def test_nested_dict():\n    d = nested_dict()\n    d['a']['b']['c'] = 1\n    d['a']['b']['d'] = 2\n    d['a']['e'] = 3\n    d['f']['g']['h']['i'] = 4\n    assert d['a']['b']['c'] == 1\n    assert d['a']['b']['d'] == 2\n    assert d['a']['e'] == 3\n    assert d['f']['g']['h']['i'] == 4\n", "category": "bugfix", "topic": "defaultdict", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_operator_module_01", "prompt": "Fix this reducer that should use operator functions for better performance.", "signature": "def multi_reduce(funcs: list, items: list):", "starter_code": "from functools import reduce\n\ndef multi_reduce(funcs: list, items: list):\n    '''Apply multiple reduction functions and return results.'''\n    results = []\n    for func in funcs:\n        results.append(reduce(func, items))\n    return results\n", "tests": "def test_multi_reduce():\n    import operator\n    items = [1, 2, 3, 4, 5]\n    funcs = [operator.add, operator.mul, max, min]\n    results = multi_reduce(funcs, items)\n    assert results[0] == 15\n    assert results[1] == 120\n    assert results[2] == 5\n    assert results[3] == 1\n    results2 = multi_reduce([operator.add], [])\n    assert results2 == [0]\n    results3 = multi_reduce([operator.mul], [])\n    assert results3 == [1]\n", "category": "bugfix", "topic": "operator", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_suppress_context_01", "prompt": "Fix this function that should suppress specific exceptions but re-raise others.", "signature": "def safe_operation(func, *args, suppress=(), default=None):", "starter_code": "def safe_operation(func, *args, suppress=(), default=None):\n    return func(*args)  # Bug: doesn't suppress\n", "tests": "def test_safe_operation():\n    result = safe_operation(int, '42')\n    assert result == 42\n    result = safe_operation(int, 'bad', suppress=(ValueError,), default=-1)\n    assert result == -1\n    error_raised = False\n    try:\n        safe_operation(lambda: 1/0, suppress=(ValueError,), default=0)\n    except ZeroDivisionError:\n        error_raised = True\n    assert error_raised, 'Should not suppress ZeroDivisionError'\n", "category": "bugfix", "topic": "exception_suppress", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_attrgetter_01", "prompt": "Fix this sorter that should sort objects by nested attributes.", "signature": "def sort_by_attrs(items: list, *attrs):", "starter_code": "def sort_by_attrs(items: list, *attrs):\n    def get_key(item):\n        values = []\n        for attr in attrs:\n            values.append(getattr(item, attr))\n        return tuple(values)\n    return sorted(items, key=get_key)\n", "tests": "def test_sort_by_attrs():\n    class Person:\n        def __init__(self, name, address):\n            self.name = name\n            self.address = address\n    class Address:\n        def __init__(self, city, zip_code):\n            self.city = city\n            self.zip_code = zip_code\n    people = [\n        Person('Alice', Address('NYC', '10001')),\n        Person('Bob', Address('LA', '90001')),\n        Person('Charlie', Address('NYC', '10002')),\n    ]\n    by_city = sort_by_attrs(people, 'address.city')\n    assert [p.name for p in by_city] == ['Bob', 'Alice', 'Charlie']\n    by_city_zip = sort_by_attrs(people, 'address.city', 'address.zip_code')\n    assert [p.name for p in by_city_zip] == ['Bob', 'Alice', 'Charlie']\n", "category": "bugfix", "topic": "attrgetter", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_slots_with_weakref_01", "prompt": "Fix this class using __slots__ that should also support weak references.", "signature": "class SlottedNode:", "starter_code": "import weakref\n\nclass SlottedNode:\n    __slots__ = ['value', 'next']\n    \n    def __init__(self, value):\n        self.value = value\n        self.next = None\n", "tests": "def test_slotted_node():\n    import weakref\n    import gc\n    node = SlottedNode(42)\n    assert node.value == 42\n    assert not hasattr(node, '__dict__')\n    ref = weakref.ref(node)\n    assert ref() is node\n    del node\n    gc.collect()\n    assert ref() is None\n", "category": "bugfix", "topic": "slots_weakref", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_class_method_override_01", "prompt": "Fix this inheritance where classmethod should properly reference the subclass.", "signature": "class Animal:", "starter_code": "class Animal:\n    species = 'Unknown'\n    \n    @classmethod\n    def describe(cls):\n        return f'A {Animal.species}'\n    \n    @classmethod\n    def create(cls, name):\n        instance = Animal()\n        instance.name = name\n        return instance\n    \n    def __init__(self):\n        self.name = None\n\nclass Dog(Animal):\n    species = 'Dog'\n\nclass Cat(Animal):\n    species = 'Cat'\n", "tests": "def test_animal():\n    assert Animal.describe() == 'A Unknown'\n    assert Dog.describe() == 'A Dog'\n    assert Cat.describe() == 'A Cat'\n    dog = Dog.create('Buddy')\n    assert isinstance(dog, Dog)\n    assert dog.name == 'Buddy'\n    cat = Cat.create('Whiskers')\n    assert isinstance(cat, Cat)\n    assert cat.name == 'Whiskers'\n", "category": "bugfix", "topic": "classmethod", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_static_init_01", "prompt": "Fix this class that should lazily initialize a class-level resource once.", "signature": "class DatabasePool:", "starter_code": "class DatabasePool:\n    _pool = None\n    \n    @staticmethod\n    def get_pool():\n        if DatabasePool._pool is None:\n            DatabasePool._pool = DatabasePool._create_pool()\n        return DatabasePool._pool\n    \n    @staticmethod\n    def _create_pool():\n        return {'connections': [], 'created': True}\n    \n    @staticmethod\n    def reset():\n        DatabasePool._pool = None\n", "tests": "def test_database_pool():\n    DatabasePool.reset()\n    pool1 = DatabasePool.get_pool()\n    pool2 = DatabasePool.get_pool()\n    assert pool1 is pool2\n    assert pool1['created'] == True\n    class CustomPool(DatabasePool):\n        @staticmethod\n        def _create_pool():\n            return {'connections': [], 'created': True, 'custom': True}\n    CustomPool.reset()\n    custom_pool = CustomPool.get_pool()\n    assert custom_pool.get('custom') == True\n", "category": "bugfix", "topic": "static_init", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_covariant_return_01", "prompt": "Fix this builder pattern that should return the correct type for method chaining.", "signature": "class Builder:", "starter_code": "class Builder:\n    def __init__(self):\n        self.config = {}\n    \n    def set(self, key, value):\n        return None  # Bug: doesn't return self\n    \n    def build(self):\n        return {}\n\nclass ExtendedBuilder(Builder):\n    def set_special(self, value):\n        return None\n", "tests": "def test_builder():\n    result = Builder().set('a', 1).set('b', 2).build()\n    assert result == {'a': 1, 'b': 2}\n    ext = ExtendedBuilder()\n    chained = ext.set('x', 1)\n    assert isinstance(chained, ExtendedBuilder), f'set() returns {type(chained).__name__}'\n    result = ExtendedBuilder().set('a', 1).set_special('s').set('b', 2).build()\n    assert result == {'a': 1, 'b': 2, 'special': 's'}\n", "category": "bugfix", "topic": "builder_pattern", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_init_subclass_01", "prompt": "Fix this plugin system that should auto-register subclasses using __init_subclass__.", "signature": "class Plugin:", "starter_code": "class Plugin:\n    registry = {}\n    \n    def __init_subclass__(cls, **kwargs):\n        pass  # Bug: doesn't register\n", "tests": "def test_plugin():\n    Plugin.registry.clear()\n    class AudioPlugin(Plugin):\n        pass\n    class VideoPlugin(Plugin):\n        pass\n    assert 'Plugin' not in Plugin.registry, 'Base should not be registered'\n    assert 'AudioPlugin' in Plugin.registry\n    assert 'VideoPlugin' in Plugin.registry\n", "category": "bugfix", "topic": "init_subclass", "tier": 4, "starter_check": "pass"}
{"task_id": "tier4_prepare_metaclass_01", "prompt": "Fix this metaclass that should use __prepare__ to maintain definition order.", "signature": "class OrderedMeta:", "starter_code": "class OrderedMeta(type):\n    def __new__(mcs, name, bases, namespace):\n        cls = super().__new__(mcs, name, bases, dict(namespace))\n        cls._fields = []  # Bug: empty fields\n        return cls\n", "tests": "def test_ordered_meta():\n    class Record(metaclass=OrderedMeta):\n        first = 1\n        second = 2\n        third = 3\n        _private = 4\n    assert Record._fields == ['first', 'second', 'third'], f'Got {Record._fields}'\n    assert '_private' not in Record._fields\n    class Another(metaclass=OrderedMeta):\n        z_field = 'z'\n        a_field = 'a'\n        m_field = 'm'\n    assert Another._fields == ['z_field', 'a_field', 'm_field'], f'Order not preserved: {Another._fields}'\n", "category": "bugfix", "topic": "metaclass_prepare", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_descriptor_del_01", "prompt": "Fix this descriptor that should support deletion of the attribute.", "signature": "class ManagedAttribute:", "starter_code": "class ManagedAttribute:\n    def __init__(self, name):\n        self.name = name\n    \n    def __get__(self, obj, objtype=None):\n        if obj is None:\n            return self\n        return obj.__dict__.get(self.name)\n    \n    def __set__(self, obj, value):\n        obj.__dict__[self.name] = value\n", "tests": "def test_managed_attribute():\n    class MyClass:\n        attr = ManagedAttribute('attr')\n    obj = MyClass()\n    obj.attr = 42\n    assert obj.attr == 42\n    del obj.attr\n    assert obj.attr is None\n    obj.attr = 'new value'\n    assert obj.attr == 'new value'\n", "category": "bugfix", "topic": "descriptor_delete", "tier": 4, "starter_check": "fail"}
{"task_id": "tier4_reduce_pickle_01", "prompt": "Fix this class so it can be pickled despite having a lambda.", "signature": "class Transform:", "starter_code": "import pickle\n\nclass Transform:\n    def __init__(self, name, func=None):\n        self.name = name\n        self.func = func or (lambda x: x)\n    \n    def apply(self, value):\n        return self.func(value)\n", "tests": "def test_transform():\n    import pickle\n    t1 = Transform('double', lambda x: x * 2)\n    assert t1.apply(5) == 10\n    t2 = Transform('identity')\n    pickled = pickle.dumps(t2)\n    restored = pickle.loads(pickled)\n    assert restored.name == 'identity'\n    assert restored.apply(42) == 42\n    def triple(x):\n        return x * 3\n    t3 = Transform('triple', triple)\n    pickled = pickle.dumps(t3)\n    restored = pickle.loads(pickled)\n    assert restored.apply(5) == 15\n", "category": "bugfix", "topic": "pickle_lambda", "tier": 4, "starter_check": "fail"}
{"task_id": "tier5_async_timeout_01", "prompt": "Fix this async timeout context manager that should cancel operations after timeout.", "signature": "class async_timeout:", "starter_code": "import asyncio\n\nclass async_timeout:\n    def __init__(self, seconds):\n        self.seconds = seconds\n        self.task = None\n    \n    async def __aenter__(self):\n        return self\n    \n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        return False\n", "tests": "def test_async_timeout():\n    import asyncio\n    async def run():\n        async def slow_op():\n            await asyncio.sleep(1)\n            return 'done'\n        async def fast_op():\n            await asyncio.sleep(0.01)\n            return 'fast'\n        async with async_timeout(0.5):\n            result = await fast_op()\n            assert result == 'fast'\n        try:\n            async with async_timeout(0.05):\n                await slow_op()\n            assert False, 'Should have timed out'\n        except asyncio.TimeoutError:\n            pass\n    asyncio.run(run())\n", "category": "bugfix", "topic": "async_timeout", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_async_queue_01", "prompt": "Fix this async queue that should support blocking get with timeout.", "signature": "class AsyncQueue:", "starter_code": "import asyncio\n\nclass AsyncQueue:\n    def __init__(self, maxsize=0):\n        self._queue = []\n        self._maxsize = maxsize\n    \n    async def put(self, item):\n        self._queue.append(item)\n    \n    async def get(self, timeout=None):\n        if not self._queue:\n            return None\n        return self._queue.pop(0)\n    \n    def qsize(self):\n        return len(self._queue)\n", "tests": "def test_async_queue():\n    import asyncio\n    async def run():\n        q = AsyncQueue()\n        await q.put(1)\n        await q.put(2)\n        assert await q.get() == 1\n        assert await q.get() == 2\n        async def delayed_put():\n            await asyncio.sleep(0.05)\n            await q.put('delayed')\n        asyncio.create_task(delayed_put())\n        result = await q.get(timeout=0.2)\n        assert result == 'delayed'\n        try:\n            await q.get(timeout=0.05)\n            assert False, 'Should timeout'\n        except asyncio.TimeoutError:\n            pass\n    asyncio.run(run())\n", "category": "bugfix", "topic": "async_queue", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_async_event_01", "prompt": "Fix this async event that should allow multiple waiters to be notified.", "signature": "class AsyncEvent:", "starter_code": "import asyncio\n\nclass AsyncEvent:\n    def __init__(self):\n        self._set = False\n        self._waiter = None\n    \n    def set(self):\n        self._set = True\n        if self._waiter:\n            self._waiter.set_result(None)\n    \n    def clear(self):\n        self._set = False\n    \n    def is_set(self):\n        return self._set\n    \n    async def wait(self):\n        if self._set:\n            return\n        self._waiter = asyncio.get_event_loop().create_future()\n        await self._waiter\n", "tests": "def test_async_event():\n    import asyncio\n    async def run():\n        event = AsyncEvent()\n        results = []\n        async def waiter(n):\n            await event.wait()\n            results.append(n)\n        tasks = [asyncio.create_task(waiter(i)) for i in range(3)]\n        await asyncio.sleep(0.01)\n        assert len(results) == 0\n        event.set()\n        await asyncio.sleep(0.01)\n        assert sorted(results) == [0, 1, 2]\n    asyncio.run(run())\n", "category": "bugfix", "topic": "async_event", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_async_barrier_01", "prompt": "Fix this async barrier that should block until n parties arrive.", "signature": "class AsyncBarrier:", "starter_code": "import asyncio\n    pass  # Bug: not implemented\n", "tests": "def test_async_barrier():\n    import asyncio\n    async def run():\n        barrier = AsyncBarrier(3)\n        results = []\n        async def worker(n, delay):\n            await asyncio.sleep(delay)\n            results.append(f'{n}_arrived')\n            await barrier.wait()\n            results.append(f'{n}_passed')\n        await asyncio.gather(worker(0, 0.01), worker(1, 0.02), worker(2, 0.03))\n        arrived_idx = [i for i, r in enumerate(results) if 'arrived' in r]\n        passed_idx = [i for i, r in enumerate(results) if 'passed' in r]\n        assert max(arrived_idx) < min(passed_idx), f'Barrier failed: {results}'\n    asyncio.run(run())\n", "category": "bugfix", "topic": "async_barrier", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_async_pool_01", "prompt": "Fix this async worker pool that should limit concurrent task execution.", "signature": "class AsyncWorkerPool:", "starter_code": "import asyncio\n    pass  # Bug: not implemented\n", "tests": "def test_async_worker_pool():\n    import asyncio\n    import time\n    async def run():\n        pool = AsyncWorkerPool(2)\n        max_concurrent = [0]\n        current = [0]\n        async def work(x):\n            current[0] += 1\n            max_concurrent[0] = max(max_concurrent[0], current[0])\n            await asyncio.sleep(0.03)\n            current[0] -= 1\n            return x * 2\n        start = time.time()\n        results = await pool.map(work, [1, 2, 3, 4])\n        elapsed = time.time() - start\n        assert sorted(results) == [2, 4, 6, 8]\n        assert max_concurrent[0] <= 2\n        assert elapsed >= 0.05\n    asyncio.run(run())\n", "category": "bugfix", "topic": "async_pool", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_channel_01", "prompt": "Fix this Go-style channel for async communication between coroutines.", "signature": "class Channel:", "starter_code": "import asyncio\n    pass  # Bug: not implemented\n", "tests": "def test_channel():\n    import asyncio\n    async def run():\n        ch = Channel(capacity=2)\n        await ch.send(1)\n        await ch.send(2)\n        assert await ch.receive() == 1\n        assert await ch.receive() == 2\n        ch2 = Channel()\n        async def sender():\n            for i in range(3):\n                await ch2.send(i)\n            ch2.close()\n        asyncio.create_task(sender())\n        await asyncio.sleep(0.05)\n        received = []\n        while True:\n            val = await ch2.receive()\n            if val is None:\n                break\n            received.append(val)\n        assert received == [0, 1, 2]\n    asyncio.run(run())\n", "category": "bugfix", "topic": "channel", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_future_chain_01", "prompt": "Fix this future that should support chaining with then() callbacks.", "signature": "class ChainableFuture:", "starter_code": "import asyncio\n    pass  # Bug: not implemented\n", "tests": "def test_chainable_future():\n    f = ChainableFuture()\n    results = []\n    chain = f.then(lambda x: x * 2).then(lambda x: x + 1).then(lambda x: results.append(x))\n    f.set_result(5)\n    assert results == [11], f'Chain not executed: {results}'\n    f2 = ChainableFuture()\n    f2.set_result(10)\n    final = f2.then(lambda x: x * 2)\n    assert final.result() == 20\n", "category": "bugfix", "topic": "future_chain", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_watch_file_01", "prompt": "Fix this file watcher that should detect file changes asynchronously.", "signature": "class FileWatcher:", "starter_code": "import asyncio\n    pass  # Bug: not implemented\n", "tests": "def test_file_watcher():\n    import asyncio\n    import tempfile\n    import os\n    async def run():\n        with tempfile.NamedTemporaryFile(mode='w', delete=False) as f:\n            f.write('initial')\n            path = f.name\n        try:\n            changes = []\n            watcher = FileWatcher(path)\n            async def do_watch():\n                try:\n                    await watcher.watch(lambda p: changes.append(p), interval=0.03)\n                except asyncio.CancelledError:\n                    pass\n            task = asyncio.create_task(do_watch())\n            await asyncio.sleep(0.05)\n            with open(path, 'w') as f:\n                f.write('modified')\n            await asyncio.sleep(0.1)\n            watcher.stop()\n            task.cancel()\n            try:\n                await task\n            except asyncio.CancelledError:\n                pass\n            assert len(changes) >= 1, f'No changes: {changes}'\n        finally:\n            os.unlink(path)\n    asyncio.run(run())\n", "category": "bugfix", "topic": "file_watcher", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_subprocess_stream_01", "prompt": "Fix this async subprocess runner that should stream output line by line.", "signature": "async def run_streaming(cmd: list, on_stdout=None, on_stderr=None):", "starter_code": "import asyncio\n\nasync def run_streaming(cmd: list, on_stdout=None, on_stderr=None):\n    process = await asyncio.create_subprocess_exec(\n        *cmd,\n        stdout=asyncio.subprocess.PIPE,\n        stderr=asyncio.subprocess.PIPE\n    )\n    stdout, stderr = await process.communicate()\n    if on_stdout and stdout:\n        on_stdout(stdout.decode())\n    if on_stderr and stderr:\n        on_stderr(stderr.decode())\n    return process.returncode\n", "tests": "def test_run_streaming():\n    import asyncio\n    import sys\n    async def run():\n        lines = []\n        code = await run_streaming(\n            [sys.executable, '-c', 'import time; print(\"line1\"); print(\"line2\"); print(\"line3\")'],\n            on_stdout=lambda line: lines.append(line.strip())\n        )\n        assert code == 0\n        assert 'line1' in lines\n        assert 'line2' in lines\n        assert 'line3' in lines\n        error_lines = []\n        code = await run_streaming(\n            [sys.executable, '-c', 'import sys; sys.stderr.write(\"error1\\\\n\"); sys.stderr.write(\"error2\\\\n\")'],\n            on_stderr=lambda line: error_lines.append(line.strip())\n        )\n        assert 'error1' in error_lines\n    asyncio.run(run())\n", "category": "bugfix", "topic": "subprocess_stream", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_periodic_task_01", "prompt": "Fix this periodic task runner that should execute tasks at fixed intervals.", "signature": "class PeriodicTask:", "starter_code": "import asyncio\n    pass  # Bug: not implemented\n", "tests": "def test_periodic_task():\n    import asyncio\n    async def run():\n        count = [0]\n        def increment():\n            count[0] += 1\n        task = PeriodicTask(0.03, increment)\n        task.start()\n        await asyncio.sleep(0.12)\n        task.stop()\n        assert count[0] >= 3, f'Only ran {count[0]} times'\n        assert count[0] <= 6, f'Ran too many: {count[0]}'\n    asyncio.run(run())\n", "category": "bugfix", "topic": "periodic_task", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_connection_pool_async_01", "prompt": "Fix this async connection pool that should manage database connections.", "signature": "class AsyncConnectionPool:", "starter_code": "import asyncio\n    pass  # Bug: not implemented\n", "tests": "def test_async_connection_pool():\n    import asyncio\n    async def run():\n        created = [0]\n        async def factory():\n            created[0] += 1\n            return {'id': created[0]}\n        pool = AsyncConnectionPool(factory, max_size=2)\n        c1 = await pool.acquire()\n        c2 = await pool.acquire()\n        assert created[0] == 2\n        await pool.release(c1)\n        c3 = await pool.acquire()\n        assert created[0] == 2, 'Should reuse'\n        assert c3['id'] == c1['id']\n    asyncio.run(run())\n", "category": "bugfix", "topic": "connection_pool", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_distributed_lock_01", "prompt": "Fix this distributed lock simulation that should handle lock expiry and renewal.", "signature": "class DistributedLock:", "starter_code": "import asyncio\n    pass  # Bug: not implemented\n", "tests": "def test_distributed_lock():\n    import asyncio\n    async def run():\n        DistributedLock._locks.clear()\n        lock1 = DistributedLock('resource', ttl=0.1)\n        lock2 = DistributedLock('resource', ttl=0.1)\n        assert await lock1.acquire() == True\n        assert await lock2.acquire(timeout=0.02) == False\n        await lock1.release()\n        assert await lock2.acquire() == True\n        await lock2.release()\n        lock3 = DistributedLock('res2', ttl=0.05)\n        await lock3.acquire()\n        await asyncio.sleep(0.1)\n        lock4 = DistributedLock('res2', ttl=0.1)\n        assert await lock4.acquire(timeout=0.01) == True\n    asyncio.run(run())\n", "category": "bugfix", "topic": "distributed_lock", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_saga_pattern_01", "prompt": "Fix this saga pattern implementation that should handle compensating transactions on failure.", "signature": "class Saga:", "starter_code": "import asyncio\n\nclass Saga:\n    def __init__(self):\n        self.steps = []\n        self.completed = []\n    \n    def add_step(self, action, compensate):\n        self.steps.append((action, compensate))\n    \n    async def execute(self):\n        for action, compensate in self.steps:\n            try:\n                if asyncio.iscoroutinefunction(action):\n                    await action()\n                else:\n                    action()\n                self.completed.append(compensate)\n            except Exception as e:\n                for comp in self.completed:\n                    if asyncio.iscoroutinefunction(comp):\n                        await comp()\n                    else:\n                        comp()\n                raise\n", "tests": "def test_saga():\n    import asyncio\n    async def run():\n        log = []\n        saga = Saga()\n        saga.add_step(lambda: log.append('s1'), lambda: log.append('c1'))\n        saga.add_step(lambda: log.append('s2'), lambda: log.append('c2'))\n        await saga.execute()\n        assert log == ['s1', 's2']\n        log.clear()\n        saga2 = Saga()\n        saga2.add_step(lambda: log.append('s1'), lambda: log.append('c1'))\n        saga2.add_step(lambda: log.append('s2'), lambda: log.append('c2'))\n        def fail():\n            log.append('s3_fail')\n            raise ValueError('fail')\n        saga2.add_step(fail, lambda: log.append('c3'))\n        try:\n            await saga2.execute()\n        except ValueError:\n            pass\n        assert 'c1' in log and 'c2' in log\n        assert 'c3' not in log\n        assert log.index('c2') < log.index('c1'), 'Reverse order'\n    asyncio.run(run())\n", "category": "bugfix", "topic": "saga_pattern", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_backpressure_01", "prompt": "Fix this stream processor that should handle backpressure when consumer is slow.", "signature": "class BackpressureStream:", "starter_code": "import asyncio\n    pass  # Bug: not implemented\n", "tests": "def test_backpressure_stream():\n    import asyncio\n    async def run():\n        stream = BackpressureStream(high_water=3, low_water=1)\n        consumed = []\n        async def producer():\n            for i in range(6):\n                await stream.write(i)\n        async def consumer():\n            for _ in range(6):\n                item = await stream.read()\n                consumed.append(item)\n                await asyncio.sleep(0.02)\n        await asyncio.gather(producer(), consumer())\n        assert consumed == list(range(6))\n    asyncio.run(run())\n", "category": "bugfix", "topic": "backpressure", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_graceful_shutdown_01", "prompt": "Fix this server that should gracefully shutdown, completing in-flight requests.", "signature": "class GracefulServer:", "starter_code": "import asyncio\n    pass  # Bug: not implemented\n", "tests": "def test_graceful_server():\n    import asyncio\n    async def run():\n        server = GracefulServer()\n        results = []\n        async def request(rid, dur):\n            try:\n                r = await server.handle_request(rid, dur)\n                results.append(r)\n            except RuntimeError:\n                results.append(f'rejected:{rid}')\n        t1 = asyncio.create_task(request(1, 0.1))\n        t2 = asyncio.create_task(request(2, 0.1))\n        await asyncio.sleep(0.03)\n        shutdown = asyncio.create_task(server.shutdown(timeout=1))\n        t3 = asyncio.create_task(request(3, 0.05))\n        await asyncio.gather(t1, t2, t3, shutdown)\n        assert 'completed:1' in results\n        assert 'completed:2' in results\n        assert 'rejected:3' in results\n    asyncio.run(run())\n", "category": "bugfix", "topic": "graceful_shutdown", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_bulkhead_01", "prompt": "Fix this bulkhead pattern that should isolate failures between different resources.", "signature": "class Bulkhead:", "starter_code": "import asyncio\n    pass  # Bug: not implemented\n", "tests": "def test_bulkhead():\n    import asyncio\n    async def run():\n        full = Bulkhead('full', max_concurrent=1, max_wait=0)\n        async def block():\n            await asyncio.sleep(1)\n        blocking = asyncio.create_task(full.execute(block()))\n        await asyncio.sleep(0.01)\n        try:\n            await asyncio.wait_for(full.execute(asyncio.sleep(0.01)), timeout=0.1)\n            assert False, 'Should raise'\n        except (BulkheadFullError, asyncio.TimeoutError):\n            pass\n        blocking.cancel()\n    asyncio.run(run())\n", "category": "bugfix", "topic": "bulkhead", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_request_coalescing_01", "prompt": "Fix this request coalescer that should batch identical concurrent requests.", "signature": "class RequestCoalescer:", "starter_code": "import asyncio\n    pass  # Bug: not implemented\n", "tests": "def test_request_coalescing():\n    import asyncio\n    async def run():\n        call_count = [0]\n        async def fetch(key):\n            call_count[0] += 1\n            await asyncio.sleep(0.05)\n            return f'data:{key}'\n        coalescer = RequestCoalescer(fetch)\n        results = await asyncio.gather(\n            coalescer.execute('user:1'),\n            coalescer.execute('user:1'),\n            coalescer.execute('user:1'),\n            coalescer.execute('user:2'),\n        )\n        assert call_count[0] == 2, f'Called {call_count[0]} times'\n        assert results[0] == results[1] == results[2] == 'data:user:1'\n        assert results[3] == 'data:user:2'\n    asyncio.run(run())\n", "category": "bugfix", "topic": "request_coalescing", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_health_check_01", "prompt": "Fix this health checker that should monitor multiple dependencies with timeouts.", "signature": "class HealthChecker:", "starter_code": "import asyncio\n\nclass HealthChecker:\n    def __init__(self):\n        self.checks = {}\n    \n    def register(self, name, check_func, timeout=5.0):\n        self.checks[name] = (check_func, timeout)\n    \n    async def check_all(self):\n        results = {}\n        for name, (check_func, timeout) in self.checks.items():\n            try:\n                if asyncio.iscoroutinefunction(check_func):\n                    result = await check_func()\n                else:\n                    result = check_func()\n                results[name] = {'healthy': True, 'details': result}\n            except Exception as e:\n                results[name] = {'healthy': False, 'error': str(e)}\n        return results\n    \n    async def is_healthy(self):\n        results = await self.check_all()\n        return all(r['healthy'] for r in results.values())\n", "tests": "def test_health_checker():\n    import asyncio\n    async def run():\n        checker = HealthChecker()\n        async def db_check():\n            await asyncio.sleep(0.01)\n            return 'connected'\n        async def slow_check():\n            await asyncio.sleep(1)\n            return 'ok'\n        def sync_check():\n            return 'ok'\n        checker.register('database', db_check, timeout=0.5)\n        checker.register('sync_service', sync_check, timeout=0.5)\n        checker.register('slow_service', slow_check, timeout=0.05)\n        results = await checker.check_all()\n        assert results['database']['healthy'] == True\n        assert results['sync_service']['healthy'] == True\n        assert results['slow_service']['healthy'] == False\n        assert 'timeout' in results['slow_service'].get('error', '').lower() or not results['slow_service']['healthy']\n        assert await checker.is_healthy() == False\n    asyncio.run(run())\n", "category": "bugfix", "topic": "health_check", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_middleware_chain_01", "prompt": "Fix this middleware chain that should process requests through a pipeline of handlers.", "signature": "class MiddlewareChain:", "starter_code": "import asyncio\n    pass  # Bug: not implemented\n", "tests": "def test_middleware_chain():\n    import asyncio\n    async def run():\n        chain = MiddlewareChain()\n        async def logger(req, next):\n            req['log'] = req.get('log', []) + ['start']\n            result = await next()\n            return result\n        async def auth(req, next):\n            if not req.get('user'):\n                return {'error': 'unauthorized'}\n            return await next()\n        async def handler(req, next):\n            return {'success': True}\n        chain.use(logger)\n        chain.use(auth)\n        chain.use(handler)\n        result = await chain.execute({'user': 'alice'})\n        assert result['success'] == True\n        result2 = await chain.execute({})\n        assert result2.get('error') == 'unauthorized'\n    asyncio.run(run())\n", "category": "bugfix", "topic": "middleware", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_lease_manager_01", "prompt": "Fix this lease manager that should handle lease acquisition and renewal.", "signature": "class LeaseManager:", "starter_code": "import asyncio\n    pass  # Bug: not implemented\n", "tests": "def test_lease_manager():\n    import asyncio\n    async def run():\n        lm = LeaseManager()\n        assert await lm.acquire('db', 'w1', 0.1) == True\n        assert await lm.acquire('db', 'w2', 0.1) == False\n        assert await lm.renew('db', 'w1', 0.1) == True\n        assert await lm.renew('db', 'w2', 0.1) == False\n        await asyncio.sleep(0.15)\n        assert await lm.acquire('db', 'w2', 0.1) == True\n    asyncio.run(run())\n", "category": "bugfix", "topic": "lease_manager", "tier": 5, "starter_check": "pass"}
{"task_id": "tier5_token_bucket_01", "prompt": "Fix this token bucket rate limiter that should allow bursts up to bucket capacity.", "signature": "class TokenBucket:", "starter_code": "import asyncio\n    pass  # Bug: not implemented\n", "tests": "def test_token_bucket():\n    import asyncio\n    async def run():\n        bucket = TokenBucket(capacity=3, refill_rate=10)\n        assert await bucket.acquire(1, timeout=0.01) == True\n        assert await bucket.acquire(1, timeout=0.01) == True\n        assert await bucket.acquire(1, timeout=0.01) == True\n        assert await bucket.acquire(1, timeout=0.01) == False\n        await asyncio.sleep(0.15)\n        assert await bucket.acquire(1, timeout=0.01) == True\n    asyncio.run(run())\n", "category": "bugfix", "topic": "token_bucket", "tier": 5, "starter_check": "pass"}
{"task_id": "tier5_sliding_window_01", "prompt": "Fix this sliding window rate limiter that should track requests per time window.", "signature": "class SlidingWindowLimiter:", "starter_code": "import asyncio\n    pass  # Bug: not implemented\n", "tests": "def test_sliding_window_limiter():\n    import asyncio\n    async def run():\n        limiter = SlidingWindowLimiter(max_requests=3, window_seconds=0.1)\n        assert await limiter.acquire() == True\n        assert await limiter.acquire() == True\n        assert await limiter.acquire() == True\n        assert await limiter.acquire() == False\n        await asyncio.sleep(0.12)\n        assert await limiter.acquire() == True\n    asyncio.run(run())\n", "category": "bugfix", "topic": "sliding_window", "tier": 5, "starter_check": "pass"}
{"task_id": "tier5_priority_executor_01", "prompt": "Fix this priority-based task executor that should run higher priority tasks first.", "signature": "class PriorityExecutor:", "starter_code": "import asyncio\n    pass  # Bug: not implemented\n", "tests": "def test_priority_executor():\n    import asyncio\n    async def run():\n        executor = PriorityExecutor(max_concurrent=1)\n        order = []\n        async def task(name):\n            order.append(name)\n            await asyncio.sleep(0.01)\n            return name\n        t1 = asyncio.create_task(executor.submit(3, task('low')))\n        await asyncio.sleep(0.001)\n        t2 = asyncio.create_task(executor.submit(1, task('high')))\n        t3 = asyncio.create_task(executor.submit(2, task('medium')))\n        await asyncio.gather(t1, t2, t3)\n        assert order[0] == 'low'\n        assert order[1] == 'high'\n        assert order[2] == 'medium'\n    asyncio.run(run())\n", "category": "bugfix", "topic": "priority_executor", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_dedup_queue_01", "prompt": "Fix this deduplicating queue that should only keep unique pending items.", "signature": "class DedupQueue:", "starter_code": "import asyncio\n\nclass DedupQueue:\n    def __init__(self):\n        self.queue = []\n        self.seen = set()\n    \n    async def put(self, item):\n        if item in self.seen:\n            return False\n        self.seen.add(item)\n        self.queue.append(item)\n        return True\n    \n    async def get(self):\n        while not self.queue:\n            await asyncio.sleep(0.01)\n        item = self.queue.pop(0)\n        return item\n    \n    def qsize(self):\n        return len(self.queue)\n", "tests": "def test_dedup_queue():\n    import asyncio\n    async def run():\n        q = DedupQueue()\n        assert await q.put('a') == True\n        assert await q.put('b') == True\n        assert await q.put('a') == False\n        assert q.qsize() == 2\n        item = await q.get()\n        assert item == 'a'\n        assert await q.put('a') == True\n        assert q.qsize() == 2\n    asyncio.run(run())\n", "category": "bugfix", "topic": "dedup_queue", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_batch_processor_01", "prompt": "Fix this batch processor that should collect items and process them in batches.", "signature": "class BatchProcessor:", "starter_code": "import asyncio\nimport time\n\nclass BatchProcessor:\n    def __init__(self, process_func, max_batch_size=10, max_wait_seconds=1.0):\n        self.process_func = process_func\n        self.max_batch_size = max_batch_size\n        self.max_wait_seconds = max_wait_seconds\n        self.batch = []\n        self.last_process_time = time.time()\n    \n    async def add(self, item):\n        self.batch.append(item)\n        if len(self.batch) >= self.max_batch_size:\n            await self._process_batch()\n        elif time.time() - self.last_process_time > self.max_wait_seconds:\n            await self._process_batch()\n    \n    async def _process_batch(self):\n        if not self.batch:\n            return\n        batch = self.batch\n        self.batch = []\n        self.last_process_time = time.time()\n        await self.process_func(batch)\n    \n    async def flush(self):\n        await self._process_batch()\n", "tests": "def test_batch_processor():\n    import asyncio\n    async def run():\n        processed = []\n        async def process(batch):\n            processed.append(batch[:])\n        bp = BatchProcessor(process, max_batch_size=3, max_wait_seconds=0.1)\n        await bp.add(1)\n        await bp.add(2)\n        assert len(processed) == 0\n        await bp.add(3)\n        assert len(processed) == 1\n        assert processed[0] == [1, 2, 3]\n        await bp.add(4)\n        await asyncio.sleep(0.15)\n        await bp.add(5)\n        assert len(processed) == 2\n        await bp.flush()\n        assert len(processed) == 3\n    asyncio.run(run())\n", "category": "bugfix", "topic": "batch_processor", "tier": 5, "starter_check": "fail"}
{"task_id": "tier5_work_stealing_01", "prompt": "Fix this work-stealing scheduler that should balance load across workers.", "signature": "class WorkStealingScheduler:", "starter_code": "import asyncio\n    pass  # Bug: not implemented\n", "tests": "def test_work_stealing_scheduler():\n    import asyncio\n    async def run():\n        scheduler = WorkStealingScheduler(3)\n        for i in range(10):\n            await scheduler.submit(f'task_{i}', worker_id=0)\n        assert len(scheduler.queues[0]) == 10\n        task = await scheduler.get_task(1)\n        assert task is not None, 'Should steal'\n        tasks = [task]\n        while True:\n            t = await scheduler.get_task(1)\n            if t is None:\n                break\n            tasks.append(t)\n        assert len(tasks) == 10\n    asyncio.run(run())\n", "category": "bugfix", "topic": "work_stealing", "tier": 5, "starter_check": "pass"}
{"task_id": "tier5_leader_election_01", "prompt": "Fix this simple leader election that should elect one leader among candidates.", "signature": "class LeaderElection:", "starter_code": "import asyncio\n    pass  # Bug: not implemented\n", "tests": "def test_leader_election():\n    import asyncio\n    async def run():\n        election = LeaderElection()\n        await election.register('node1', priority=1)\n        assert election.get_leader() == 'node1'\n        await election.register('node2', priority=5)\n        assert election.get_leader() == 'node2'\n        await election.register('node3', priority=3)\n        assert election.get_leader() == 'node2'\n        await election.unregister('node2')\n        assert election.get_leader() == 'node3'\n        assert election.is_leader('node3') == True\n        assert election.is_leader('node1') == False\n    asyncio.run(run())\n", "category": "bugfix", "topic": "leader_election", "tier": 5, "starter_check": "pass"}
{"task_id": "tier5_bloom_filter_01", "prompt": "Fix this probabilistic bloom filter that should support membership testing.", "signature": "class BloomFilter:", "starter_code": "import hashlib\n    pass  # Bug: not implemented\n", "tests": "def test_bloom_filter():\n    bf = BloomFilter(size=1000, num_hashes=3)\n    bf.add('apple')\n    bf.add('banana')\n    bf.add('cherry')\n    assert bf.might_contain('apple') == True\n    assert bf.might_contain('banana') == True\n    assert bf.might_contain('cherry') == True\n    fp = sum(1 for i in range(100) if bf.might_contain(f'nonexistent_{i}'))\n    assert fp < 15, f'Too many false positives: {fp}'\n", "category": "bugfix", "topic": "bloom_filter", "tier": 5, "starter_check": "pass"}
{"task_id": "tier5_consistent_hash_01", "prompt": "Fix this consistent hash ring for distributed caching.", "signature": "class ConsistentHash:", "starter_code": "import hashlib\n    pass  # Bug: not implemented\n", "tests": "def test_consistent_hash():\n    ch = ConsistentHash(replicas=50)\n    ch.add_node('server1')\n    ch.add_node('server2')\n    ch.add_node('server3')\n    assignments = {}\n    for i in range(1000):\n        assignments[f'key_{i}'] = ch.get_node(f'key_{i}')\n    counts = {}\n    for node in assignments.values():\n        counts[node] = counts.get(node, 0) + 1\n    assert len(counts) == 3\n    for count in counts.values():\n        assert 200 < count < 500, f'Unbalanced: {counts}'\n    ch.remove_node('server2')\n    changed = sum(1 for k, v in assignments.items() if ch.get_node(k) != v)\n    assert changed < 500, f'Too many moved: {changed}'\n", "category": "bugfix", "topic": "consistent_hash", "tier": 5, "starter_check": "pass"}
{"task_id": "tier5_cqrs_event_01", "prompt": "Fix this CQRS event store that should support event sourcing patterns.", "signature": "class EventStore:", "starter_code": "import asyncio\n    pass  # Bug: not implemented\n", "tests": "def test_event_store():\n    import asyncio\n    async def run():\n        store = EventStore()\n        received = []\n        async def handler(event):\n            received.append(event)\n        store.subscribe('UserCreated', handler)\n        e1 = await store.append('user-1', 'UserCreated', {'name': 'Alice'}, expected_version=0)\n        assert e1['version'] == 1\n        assert len(received) == 1\n        e2 = await store.append('user-1', 'UserUpdated', {'name': 'Alicia'}, expected_version=1)\n        assert e2['version'] == 2\n        try:\n            await store.append('user-1', 'UserUpdated', {'x': 1}, expected_version=1)\n            assert False, 'Should raise'\n        except ConcurrencyError:\n            pass\n        events = await store.get_events('user-1')\n        assert len(events) == 2\n    asyncio.run(run())\n", "category": "bugfix", "topic": "event_store", "tier": 5, "starter_check": "pass"}