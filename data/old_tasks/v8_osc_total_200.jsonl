{"task_id": "osc_queue_001", "prompt": "Fix this queue. Tests are failing with wrong order and memory issues.", "signature": "class Queue:", "starter_code": "class Queue:\n    def __init__(self):\n        self.items = []\n        self.front = 0\n        self.rear = -1\n    \n    def enqueue(self, item):\n        self.rear += 1\n        if self.rear < len(self.items):\n            self.items[self.rear] = item\n        else:\n            self.items.append(item)\n    \n    def dequeue(self):\n        if self.is_empty():\n            raise IndexError('empty')\n        item = self.items[self.front]\n        self.front += 1\n        # Memory cleanup attempt - but breaks things\n        if self.front > 100:\n            self.items = self.items[self.front:]\n            self.rear -= self.front\n            self.front = 0\n        return item\n    \n    def is_empty(self):\n        return self.front > self.rear\n    \n    def size(self):\n        return self.rear - self.front + 1", "tests": "def test_queue_basic():\n    q = Queue()\n    q.enqueue(1)\n    q.enqueue(2)\n    assert q.dequeue() == 1\n    assert q.dequeue() == 2\n\ndef test_queue_interleaved():\n    q = Queue()\n    for i in range(150):\n        q.enqueue(i)\n    for i in range(150):\n        assert q.dequeue() == i\n    # Now interleave\n    for i in range(50):\n        q.enqueue(i * 10)\n        if i % 2 == 0:\n            val = q.dequeue()\n            assert val == (i // 2) * 10\n\ndef test_queue_size():\n    q = Queue()\n    assert q.size() == 0\n    q.enqueue('a')\n    assert q.size() == 1\n    q.dequeue()\n    assert q.size() == 0", "category": "bugfix", "topic": "queue_impl", "tier": "oscillation", "starter_check": "fail", "approaches": ["list_with_indices", "collections_deque", "circular_buffer"]}
{"task_id": "osc_queue_002", "prompt": "Fix this queue implementation. Getting index errors and wrong values.", "signature": "class Queue:", "starter_code": "from collections import deque\n\nclass Queue:\n    def __init__(self):\n        self._data = deque()\n        self._list_backup = []  # For 'compatibility'\n    \n    def enqueue(self, item):\n        self._data.append(item)\n        self._list_backup.append(item)\n    \n    def dequeue(self):\n        if not self._data:\n            raise IndexError('empty')\n        # Bug: popping from wrong structure\n        self._list_backup.pop(0)\n        return self._data.pop()  # Wrong end!\n    \n    def peek(self):\n        return self._list_backup[0] if self._list_backup else None\n    \n    def is_empty(self):\n        return len(self._data) == 0", "tests": "def test_queue_order():\n    q = Queue()\n    q.enqueue('first')\n    q.enqueue('second')\n    q.enqueue('third')\n    assert q.dequeue() == 'first'\n    assert q.dequeue() == 'second'\n    assert q.peek() == 'third'\n\ndef test_queue_mixed():\n    q = Queue()\n    q.enqueue(1)\n    assert q.dequeue() == 1\n    q.enqueue(2)\n    q.enqueue(3)\n    assert q.dequeue() == 2\n    assert not q.is_empty()\n    assert q.dequeue() == 3\n    assert q.is_empty()", "category": "bugfix", "topic": "queue_impl", "tier": "oscillation", "starter_check": "fail", "approaches": ["deque_only", "list_only", "hybrid_fixed"]}
{"task_id": "osc_stack_001", "prompt": "Fix this stack. Pop returns wrong values, peek crashes.", "signature": "class Stack:", "starter_code": "class Stack:\n    def __init__(self):\n        self.items = []\n        self.top_idx = -1\n    \n    def push(self, item):\n        self.top_idx += 1\n        if self.top_idx < len(self.items):\n            self.items[self.top_idx] = item\n        else:\n            self.items.append(item)\n    \n    def pop(self):\n        if self.top_idx < 0:\n            raise IndexError('empty')\n        # Bug: returning wrong index\n        item = self.items[0]\n        self.top_idx -= 1\n        return item\n    \n    def peek(self):\n        # Bug: wrong index\n        return self.items[self.top_idx + 1]\n    \n    def is_empty(self):\n        return self.top_idx < 0", "tests": "def test_stack_lifo():\n    s = Stack()\n    s.push(1)\n    s.push(2)\n    s.push(3)\n    assert s.pop() == 3\n    assert s.pop() == 2\n    assert s.peek() == 1\n    assert s.pop() == 1\n\ndef test_stack_reuse():\n    s = Stack()\n    for i in range(10):\n        s.push(i)\n    for i in range(9, -1, -1):\n        assert s.pop() == i\n    # Reuse after emptying\n    s.push(100)\n    assert s.peek() == 100\n    assert s.pop() == 100", "category": "bugfix", "topic": "stack_impl", "tier": "oscillation", "starter_check": "fail", "approaches": ["list_append_pop", "index_tracking", "linked_nodes"]}
{"task_id": "osc_stack_002", "prompt": "Fix this linked stack implementation. Tests failing with None and crashes.", "signature": "class Stack:", "starter_code": "class Stack:\n    def __init__(self):\n        self.head = None\n        self.size = 0\n    \n    def push(self, item):\n        node = {'val': item, 'next': None}  # Bug: not linking\n        self.head = node\n        self.size += 1\n    \n    def pop(self):\n        if not self.head:\n            raise IndexError('empty')\n        val = self.head['val']\n        self.head = self.head['next']\n        self.size -= 1\n        return val\n    \n    def peek(self):\n        if not self.head:\n            raise IndexError('empty')\n        return self.head['next']['val']  # Bug: wrong access\n    \n    def __len__(self):\n        return self.size", "tests": "def test_linked_stack():\n    s = Stack()\n    s.push('a')\n    s.push('b')\n    assert s.peek() == 'b'\n    assert s.pop() == 'b'\n    assert s.pop() == 'a'\n    assert len(s) == 0\n\ndef test_linked_stack_many():\n    s = Stack()\n    for i in range(100):\n        s.push(i)\n    assert len(s) == 100\n    for i in range(99, -1, -1):\n        assert s.pop() == i", "category": "bugfix", "topic": "stack_impl", "tier": "oscillation", "starter_check": "fail", "approaches": ["linked_list_dict", "linked_list_class", "python_list"]}
{"task_id": "osc_cache_001", "prompt": "Fix this LRU cache. Eviction is wrong and get() returns stale data.", "signature": "class LRUCache:", "starter_code": "class LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = {}\n        self.access_order = []  # Track access times\n        self.access_count = {}  # Bug: mixing LRU and LFU concepts\n    \n    def get(self, key):\n        if key not in self.cache:\n            return -1\n        # Bug: updating wrong tracking\n        self.access_count[key] = self.access_count.get(key, 0) + 1\n        return self.cache[key]\n    \n    def put(self, key, value):\n        if key in self.cache:\n            self.cache[key] = value\n            return\n        if len(self.cache) >= self.capacity:\n            # Bug: evicting by frequency not recency\n            victim = min(self.access_count.keys(), key=lambda k: self.access_count[k])\n            del self.cache[victim]\n            del self.access_count[victim]\n        self.cache[key] = value\n        self.access_count[key] = 1", "tests": "def test_lru_eviction():\n    cache = LRUCache(2)\n    cache.put(1, 1)\n    cache.put(2, 2)\n    assert cache.get(1) == 1  # Access 1\n    cache.put(3, 3)  # Should evict 2 (least recently used)\n    assert cache.get(2) == -1\n    assert cache.get(3) == 3\n\ndef test_lru_update():\n    cache = LRUCache(2)\n    cache.put(1, 1)\n    cache.put(2, 2)\n    cache.get(1)  # Access 1\n    cache.get(1)  # Access 1 again\n    cache.put(3, 3)  # Should still evict 2, not 1\n    assert cache.get(1) == 1\n    assert cache.get(2) == -1\n\ndef test_lru_overwrite():\n    cache = LRUCache(2)\n    cache.put(1, 1)\n    cache.put(1, 10)\n    assert cache.get(1) == 10", "category": "bugfix", "topic": "lru_cache", "tier": "oscillation", "starter_check": "fail", "approaches": ["ordereddict", "dict_with_dll", "dict_with_timestamp"]}
{"task_id": "osc_cache_002", "prompt": "Fix this cache. Capacity not respected, ordering broken.", "signature": "class LRUCache:", "starter_code": "from collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.cache = OrderedDict()\n    \n    def get(self, key):\n        if key not in self.cache:\n            return -1\n        # Bug: move_to_end missing\n        return self.cache[key]\n    \n    def put(self, key, value):\n        if key in self.cache:\n            # Bug: not updating position\n            self.cache[key] = value\n        else:\n            self.cache[key] = value\n        # Bug: wrong eviction logic\n        if len(self.cache) > self.capacity:\n            self.cache.popitem(last=True)  # Wrong end!", "tests": "def test_cache_lru_order():\n    c = LRUCache(2)\n    c.put('a', 1)\n    c.put('b', 2)\n    c.get('a')  # 'a' is now most recent\n    c.put('c', 3)  # Should evict 'b'\n    assert c.get('a') == 1\n    assert c.get('b') == -1\n    assert c.get('c') == 3\n\ndef test_cache_update_moves():\n    c = LRUCache(3)\n    c.put(1, 'one')\n    c.put(2, 'two')\n    c.put(3, 'three')\n    c.put(1, 'ONE')  # Update should move to end\n    c.put(4, 'four')  # Should evict 2\n    assert c.get(2) == -1\n    assert c.get(1) == 'ONE'", "category": "bugfix", "topic": "lru_cache", "tier": "oscillation", "starter_check": "fail", "approaches": ["ordereddict_fixed", "plain_dict_list", "custom_dll"]}
{"task_id": "osc_graph_001", "prompt": "Fix this graph. add_edge and has_edge returning wrong results.", "signature": "class Graph:", "starter_code": "class Graph:\n    def __init__(self, n):\n        self.n = n\n        self.adj = {}  # Adjacency list\n        self.matrix = [[False] * n for _ in range(n)]  # Also matrix?\n    \n    def add_edge(self, u, v):\n        # Bug: only updating one structure\n        if u not in self.adj:\n            self.adj[u] = set()\n        self.adj[u].add(v)\n        # Matrix not updated!\n    \n    def has_edge(self, u, v):\n        # Bug: checking wrong structure\n        return self.matrix[u][v]\n    \n    def neighbors(self, u):\n        # Bug: inconsistent with has_edge\n        return list(self.adj.get(u, set()))", "tests": "def test_graph_basic():\n    g = Graph(5)\n    g.add_edge(0, 1)\n    g.add_edge(0, 2)\n    assert g.has_edge(0, 1)\n    assert g.has_edge(0, 2)\n    assert not g.has_edge(1, 0)\n    assert not g.has_edge(2, 3)\n\ndef test_graph_neighbors():\n    g = Graph(4)\n    g.add_edge(0, 1)\n    g.add_edge(0, 2)\n    g.add_edge(0, 3)\n    n = g.neighbors(0)\n    assert set(n) == {1, 2, 3}\n    assert g.neighbors(1) == []\n\ndef test_graph_dense():\n    g = Graph(10)\n    for i in range(10):\n        for j in range(10):\n            if i != j:\n                g.add_edge(i, j)\n    assert g.has_edge(5, 7)\n    assert len(g.neighbors(0)) == 9", "category": "bugfix", "topic": "graph", "tier": "oscillation", "starter_check": "fail", "approaches": ["adjacency_list_only", "adjacency_matrix_only", "hybrid_consistent"]}
{"task_id": "osc_graph_002", "prompt": "Fix this undirected graph. Edge counting wrong, has_edge inconsistent.", "signature": "class UndirectedGraph:", "starter_code": "class UndirectedGraph:\n    def __init__(self):\n        self.edges = set()\n        self.adj = {}\n    \n    def add_edge(self, u, v):\n        # Bug: only adding one direction to adj\n        if u not in self.adj:\n            self.adj[u] = []\n        self.adj[u].append(v)\n        # Bug: tuple ordering inconsistent\n        self.edges.add((u, v))\n    \n    def has_edge(self, u, v):\n        # Bug: doesn't check both orderings\n        return (u, v) in self.edges\n    \n    def degree(self, u):\n        return len(self.adj.get(u, []))\n    \n    def num_edges(self):\n        return len(self.edges)", "tests": "def test_undirected_symmetry():\n    g = UndirectedGraph()\n    g.add_edge(1, 2)\n    assert g.has_edge(1, 2)\n    assert g.has_edge(2, 1)  # Should work both ways\n\ndef test_undirected_degree():\n    g = UndirectedGraph()\n    g.add_edge(0, 1)\n    g.add_edge(0, 2)\n    g.add_edge(1, 2)\n    assert g.degree(0) == 2\n    assert g.degree(1) == 2\n    assert g.degree(2) == 2\n\ndef test_undirected_count():\n    g = UndirectedGraph()\n    g.add_edge(1, 2)\n    g.add_edge(2, 3)\n    assert g.num_edges() == 2  # Not 4!", "category": "bugfix", "topic": "graph", "tier": "oscillation", "starter_check": "fail", "approaches": ["set_normalized_tuples", "adj_list_bidirectional", "matrix_symmetric"]}
{"task_id": "osc_sort_001", "prompt": "Fix this quicksort. Wrong output and stack overflow on some inputs.", "signature": "def quicksort(arr):", "starter_code": "def quicksort(arr):\n    if len(arr) <= 1:\n        return arr\n    # Bug: bad pivot selection causes stack overflow on sorted input\n    pivot = arr[0]\n    left = [x for x in arr if x < pivot]\n    middle = [x for x in arr if x == pivot]\n    right = [x for x in arr if x > pivot]\n    # Bug: wrong order\n    return quicksort(right) + middle + quicksort(left)", "tests": "def test_sort_basic():\n    assert quicksort([3, 1, 4, 1, 5, 9, 2, 6]) == [1, 1, 2, 3, 4, 5, 6, 9]\n    assert quicksort([]) == []\n    assert quicksort([1]) == [1]\n\ndef test_sort_sorted():\n    # Should not stack overflow\n    arr = list(range(100))\n    assert quicksort(arr) == arr\n    assert quicksort(arr[::-1]) == arr\n\ndef test_sort_duplicates():\n    assert quicksort([5, 5, 5, 5]) == [5, 5, 5, 5]\n    assert quicksort([2, 1, 2, 1]) == [1, 1, 2, 2]", "category": "bugfix", "topic": "sorting", "tier": "oscillation", "starter_check": "fail", "approaches": ["recursive_fixed_pivot", "recursive_median_pivot", "iterative_stack"]}
{"task_id": "osc_sort_002", "prompt": "Fix this merge sort. Returns wrong order, crashes on empty.", "signature": "def mergesort(arr):", "starter_code": "def mergesort(arr):\n    if len(arr) < 2:\n        return arr\n    mid = len(arr) // 2\n    left = mergesort(arr[:mid])\n    right = mergesort(arr[mid:])\n    return merge(left, right)\n\ndef merge(left, right):\n    result = []\n    i = j = 0\n    while i < len(left) and j < len(right):\n        # Bug: wrong comparison\n        if left[i] > right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n    # Bug: appending in wrong order\n    result.extend(right[j:])\n    result.extend(left[i:])\n    return result", "tests": "def test_mergesort_basic():\n    assert mergesort([5, 2, 8, 1, 9]) == [1, 2, 5, 8, 9]\n    assert mergesort([1]) == [1]\n    assert mergesort([]) == []\n\ndef test_mergesort_stability():\n    arr = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5]\n    assert mergesort(arr) == sorted(arr)\n\ndef test_mergesort_negative():\n    assert mergesort([-1, -5, 3, 0, 2]) == [-5, -1, 0, 2, 3]", "category": "bugfix", "topic": "sorting", "tier": "oscillation", "starter_check": "fail", "approaches": ["recursive_merge", "iterative_bottomup", "builtin_sorted"]}
{"task_id": "osc_search_001", "prompt": "Fix this binary search. Returns wrong index, infinite loop on some inputs.", "signature": "def binary_search(arr, target):", "starter_code": "def binary_search(arr, target):\n    if not arr:\n        return -1\n    lo, hi = 0, len(arr)  # Bug: should be len-1\n    while lo < hi:\n        mid = (lo + hi) // 2\n        if arr[mid] == target:\n            return mid\n        elif arr[mid] < target:\n            lo = mid  # Bug: should be mid+1\n        else:\n            hi = mid\n    return -1", "tests": "def test_bsearch_found():\n    arr = [1, 3, 5, 7, 9, 11]\n    assert binary_search(arr, 5) == 2\n    assert binary_search(arr, 1) == 0\n    assert binary_search(arr, 11) == 5\n\ndef test_bsearch_not_found():\n    arr = [1, 3, 5, 7, 9]\n    assert binary_search(arr, 4) == -1\n    assert binary_search(arr, 0) == -1\n    assert binary_search(arr, 10) == -1\n\ndef test_bsearch_edge():\n    assert binary_search([], 5) == -1\n    assert binary_search([5], 5) == 0\n    assert binary_search([5], 3) == -1", "category": "bugfix", "topic": "search", "tier": "oscillation", "starter_check": "fail", "approaches": ["iterative_inclusive", "iterative_exclusive", "recursive"]}
{"task_id": "osc_search_002", "prompt": "Fix this search. Should find leftmost occurrence but returns random index.", "signature": "def search_leftmost(arr, target):", "starter_code": "def search_leftmost(arr, target):\n    \"\"\"Return index of leftmost occurrence of target, or -1\"\"\"\n    # Bug: linear search from wrong end\n    for i in range(len(arr) - 1, -1, -1):\n        if arr[i] == target:\n            return i\n    return -1", "tests": "def test_leftmost_basic():\n    arr = [1, 2, 2, 2, 3, 4]\n    assert search_leftmost(arr, 2) == 1  # First 2 is at index 1\n    assert search_leftmost(arr, 1) == 0\n    assert search_leftmost(arr, 4) == 5\n\ndef test_leftmost_not_found():\n    assert search_leftmost([1, 2, 3], 5) == -1\n    assert search_leftmost([], 1) == -1\n\ndef test_leftmost_all_same():\n    arr = [7, 7, 7, 7, 7]\n    assert search_leftmost(arr, 7) == 0", "category": "bugfix", "topic": "search", "tier": "oscillation", "starter_check": "fail", "approaches": ["linear_forward", "binary_search_left", "bisect_module"]}
{"task_id": "osc_hash_001", "prompt": "Fix this hash table. Collisions not handled, get() returns wrong values.", "signature": "class HashTable:", "starter_code": "class HashTable:\n    def __init__(self, size=16):\n        self.size = size\n        self.buckets = [None] * size\n        self.count = 0\n    \n    def _hash(self, key):\n        return hash(key) % self.size\n    \n    def put(self, key, value):\n        idx = self._hash(key)\n        # Bug: overwrites on collision\n        self.buckets[idx] = (key, value)\n        self.count += 1\n    \n    def get(self, key):\n        idx = self._hash(key)\n        if self.buckets[idx] is None:\n            return None\n        # Bug: doesn't check if key matches\n        return self.buckets[idx][1]\n    \n    def __len__(self):\n        return self.count", "tests": "def test_hash_basic():\n    h = HashTable()\n    h.put('a', 1)\n    h.put('b', 2)\n    assert h.get('a') == 1\n    assert h.get('b') == 2\n    assert h.get('c') is None\n\ndef test_hash_collision():\n    h = HashTable(4)  # Small size forces collisions\n    h.put('a', 1)\n    h.put('e', 5)  # Likely collides with 'a'\n    h.put('i', 9)\n    assert h.get('a') == 1\n    assert h.get('e') == 5\n    assert h.get('i') == 9\n\ndef test_hash_update():\n    h = HashTable()\n    h.put('x', 100)\n    h.put('x', 200)\n    assert h.get('x') == 200", "category": "bugfix", "topic": "hashtable", "tier": "oscillation", "starter_check": "fail", "approaches": ["chaining_list", "open_addressing", "python_dict_wrapper"]}
{"task_id": "osc_hash_002", "prompt": "Fix this hash map with linear probing. Delete breaks lookups.", "signature": "class HashMap:", "starter_code": "class HashMap:\n    def __init__(self, capacity=16):\n        self.capacity = capacity\n        self.keys = [None] * capacity\n        self.values = [None] * capacity\n    \n    def _hash(self, key):\n        return hash(key) % self.capacity\n    \n    def put(self, key, value):\n        idx = self._hash(key)\n        while self.keys[idx] is not None and self.keys[idx] != key:\n            idx = (idx + 1) % self.capacity\n        self.keys[idx] = key\n        self.values[idx] = value\n    \n    def get(self, key):\n        idx = self._hash(key)\n        while self.keys[idx] is not None:\n            if self.keys[idx] == key:\n                return self.values[idx]\n            idx = (idx + 1) % self.capacity\n        return None\n    \n    def delete(self, key):\n        idx = self._hash(key)\n        while self.keys[idx] is not None:\n            if self.keys[idx] == key:\n                # Bug: naive delete breaks probe chain\n                self.keys[idx] = None\n                self.values[idx] = None\n                return\n            idx = (idx + 1) % self.capacity", "tests": "def test_hashmap_delete():\n    h = HashMap(8)\n    h.put('a', 1)\n    h.put('b', 2)  # Might probe past 'a'\n    h.put('c', 3)\n    h.delete('a')\n    assert h.get('a') is None\n    assert h.get('b') == 2  # Should still find 'b'\n    assert h.get('c') == 3\n\ndef test_hashmap_reinsert():\n    h = HashMap(8)\n    h.put('x', 10)\n    h.delete('x')\n    h.put('x', 20)\n    assert h.get('x') == 20\n\ndef test_hashmap_chain():\n    h = HashMap(4)  # Force collisions\n    for i, c in enumerate('abcdef'):\n        h.put(c, i)\n    for i, c in enumerate('abcdef'):\n        assert h.get(c) == i", "category": "bugfix", "topic": "hashtable", "tier": "oscillation", "starter_check": "fail", "approaches": ["tombstone_marker", "rehash_cluster", "chaining_fallback"]}
{"task_id": "osc_pq_001", "prompt": "Fix this priority queue. Wrong priority order, peek inconsistent with pop.", "signature": "class PriorityQueue:", "starter_code": "class PriorityQueue:\n    def __init__(self):\n        self.heap = []\n    \n    def push(self, item, priority):\n        self.heap.append((priority, item))\n        self._sift_up(len(self.heap) - 1)\n    \n    def pop(self):\n        if not self.heap:\n            raise IndexError('empty')\n        # Bug: not maintaining heap property\n        self.heap[0], self.heap[-1] = self.heap[-1], self.heap[0]\n        item = self.heap.pop()\n        if self.heap:\n            self._sift_down(0)\n        return item[1]\n    \n    def peek(self):\n        if not self.heap:\n            raise IndexError('empty')\n        # Bug: wrong index after operations\n        return self.heap[-1][1]\n    \n    def _sift_up(self, idx):\n        parent = (idx - 1) // 2\n        # Bug: wrong comparison for max heap vs min heap\n        if idx > 0 and self.heap[idx][0] > self.heap[parent][0]:\n            self.heap[idx], self.heap[parent] = self.heap[parent], self.heap[idx]\n            self._sift_up(parent)\n    \n    def _sift_down(self, idx):\n        smallest = idx\n        left = 2 * idx + 1\n        right = 2 * idx + 2\n        if left < len(self.heap) and self.heap[left][0] > self.heap[smallest][0]:\n            smallest = left\n        if right < len(self.heap) and self.heap[right][0] > self.heap[smallest][0]:\n            smallest = right\n        if smallest != idx:\n            self.heap[idx], self.heap[smallest] = self.heap[smallest], self.heap[idx]\n            self._sift_down(smallest)", "tests": "def test_pq_order():\n    pq = PriorityQueue()\n    pq.push('low', 1)\n    pq.push('high', 10)\n    pq.push('med', 5)\n    assert pq.pop() == 'high'\n    assert pq.pop() == 'med'\n    assert pq.pop() == 'low'\n\ndef test_pq_peek():\n    pq = PriorityQueue()\n    pq.push('a', 3)\n    pq.push('b', 7)\n    assert pq.peek() == 'b'\n    assert pq.pop() == 'b'\n    assert pq.peek() == 'a'\n\ndef test_pq_same_priority():\n    pq = PriorityQueue()\n    pq.push('x', 5)\n    pq.push('y', 5)\n    pq.push('z', 5)\n    results = [pq.pop(), pq.pop(), pq.pop()]\n    assert set(results) == {'x', 'y', 'z'}", "category": "bugfix", "topic": "priority_queue", "tier": "oscillation", "starter_check": "fail", "approaches": ["max_heap_manual", "min_heap_negated", "heapq_module"]}
{"task_id": "osc_pq_002", "prompt": "Fix this min-heap priority queue. heapq usage is wrong.", "signature": "class MinPQ:", "starter_code": "import heapq\n\nclass MinPQ:\n    def __init__(self):\n        self.data = []\n        self.index = 0  # For FIFO tiebreaking\n    \n    def push(self, item, priority):\n        # Bug: tuple order wrong for heapq\n        heapq.heappush(self.data, (item, priority, self.index))\n        self.index += 1\n    \n    def pop(self):\n        if not self.data:\n            raise IndexError('empty')\n        entry = heapq.heappop(self.data)\n        return entry[0]  # Return item\n    \n    def peek(self):\n        if not self.data:\n            raise IndexError('empty')\n        return self.data[0][0]", "tests": "def test_minpq_order():\n    pq = MinPQ()\n    pq.push('big', 100)\n    pq.push('small', 1)\n    pq.push('med', 50)\n    assert pq.pop() == 'small'\n    assert pq.pop() == 'med'\n    assert pq.pop() == 'big'\n\ndef test_minpq_fifo_tie():\n    pq = MinPQ()\n    pq.push('first', 5)\n    pq.push('second', 5)\n    pq.push('third', 5)\n    assert pq.pop() == 'first'\n    assert pq.pop() == 'second'\n    assert pq.pop() == 'third'\n\ndef test_minpq_negative():\n    pq = MinPQ()\n    pq.push('a', -10)\n    pq.push('b', 0)\n    pq.push('c', -5)\n    assert pq.pop() == 'a'\n    assert pq.peek() == 'c'", "category": "bugfix", "topic": "priority_queue", "tier": "oscillation", "starter_check": "fail", "approaches": ["heapq_tuple_fixed", "custom_heap", "sorted_list"]}
{"task_id": "osc_tree_001", "prompt": "Fix this BST. Insert creates wrong structure, search fails.", "signature": "class BST:", "starter_code": "class BST:\n    def __init__(self):\n        self.root = None\n    \n    def insert(self, val):\n        if not self.root:\n            self.root = {'val': val, 'left': None, 'right': None}\n            return\n        node = self.root\n        while True:\n            if val < node['val']:\n                if node['left']:\n                    node = node['left']\n                else:\n                    # Bug: wrong assignment\n                    node['left'] = val\n                    break\n            else:\n                if node['right']:\n                    node = node['right']\n                else:\n                    node['right'] = val\n                    break\n    \n    def search(self, val):\n        node = self.root\n        while node:\n            if node['val'] == val:\n                return True\n            elif val < node['val']:\n                node = node['left']\n            else:\n                node = node['right']\n        return False", "tests": "def test_bst_insert_search():\n    t = BST()\n    t.insert(5)\n    t.insert(3)\n    t.insert(7)\n    t.insert(1)\n    assert t.search(5)\n    assert t.search(3)\n    assert t.search(7)\n    assert t.search(1)\n    assert not t.search(10)\n\ndef test_bst_duplicates():\n    t = BST()\n    t.insert(5)\n    t.insert(5)\n    t.insert(5)\n    assert t.search(5)\n\ndef test_bst_inorder():\n    t = BST()\n    for v in [4, 2, 6, 1, 3, 5, 7]:\n        t.insert(v)\n    # All should be findable\n    for v in [1, 2, 3, 4, 5, 6, 7]:\n        assert t.search(v)", "category": "bugfix", "topic": "bst", "tier": "oscillation", "starter_check": "fail", "approaches": ["dict_nodes", "class_nodes", "recursive_insert"]}
{"task_id": "osc_tree_002", "prompt": "Fix this BST delete. Tree structure corrupted after deletion.", "signature": "class BinarySearchTree:", "starter_code": "class BinarySearchTree:\n    def __init__(self):\n        self.root = None\n    \n    class Node:\n        def __init__(self, val):\n            self.val = val\n            self.left = None\n            self.right = None\n    \n    def insert(self, val):\n        if not self.root:\n            self.root = self.Node(val)\n        else:\n            self._insert(self.root, val)\n    \n    def _insert(self, node, val):\n        if val < node.val:\n            if node.left:\n                self._insert(node.left, val)\n            else:\n                node.left = self.Node(val)\n        else:\n            if node.right:\n                self._insert(node.right, val)\n            else:\n                node.right = self.Node(val)\n    \n    def delete(self, val):\n        self.root = self._delete(self.root, val)\n    \n    def _delete(self, node, val):\n        if not node:\n            return None\n        if val < node.val:\n            node.left = self._delete(node.left, val)\n        elif val > node.val:\n            node.right = self._delete(node.right, val)\n        else:\n            # Found node to delete\n            if not node.left:\n                return node.right\n            if not node.right:\n                return node.left\n            # Bug: wrong successor logic\n            successor = node.right\n            node.val = successor.val\n            node.right = None  # Bug: loses subtree\n        return node\n    \n    def search(self, val):\n        return self._search(self.root, val)\n    \n    def _search(self, node, val):\n        if not node:\n            return False\n        if node.val == val:\n            return True\n        if val < node.val:\n            return self._search(node.left, val)\n        return self._search(node.right, val)", "tests": "def test_bst_delete_leaf():\n    t = BinarySearchTree()\n    for v in [5, 3, 7]:\n        t.insert(v)\n    t.delete(3)\n    assert not t.search(3)\n    assert t.search(5)\n    assert t.search(7)\n\ndef test_bst_delete_one_child():\n    t = BinarySearchTree()\n    for v in [5, 3, 7, 6]:\n        t.insert(v)\n    t.delete(7)\n    assert t.search(6)\n    assert not t.search(7)\n\ndef test_bst_delete_two_children():\n    t = BinarySearchTree()\n    for v in [5, 3, 7, 6, 8]:\n        t.insert(v)\n    t.delete(7)\n    assert t.search(6)\n    assert t.search(8)\n    assert not t.search(7)\n    assert t.search(5)", "category": "bugfix", "topic": "bst", "tier": "oscillation", "starter_check": "fail", "approaches": ["inorder_successor", "inorder_predecessor", "iterative_delete"]}
{"task_id": "osc_dll_001", "prompt": "Fix this doubly linked list. Insert and delete corrupt the links.", "signature": "class DoublyLinkedList:", "starter_code": "class DoublyLinkedList:\n    def __init__(self):\n        self.head = None\n        self.tail = None\n        self.size = 0\n    \n    def append(self, val):\n        node = {'val': val, 'prev': self.tail, 'next': None}\n        if self.tail:\n            self.tail['next'] = node\n        self.tail = node\n        if not self.head:\n            self.head = node\n        self.size += 1\n    \n    def prepend(self, val):\n        node = {'val': val, 'prev': None, 'next': self.head}\n        if self.head:\n            # Bug: not setting prev\n            pass\n        self.head = node\n        if not self.tail:\n            self.tail = node\n        self.size += 1\n    \n    def delete(self, val):\n        node = self.head\n        while node:\n            if node['val'] == val:\n                # Bug: incomplete link updates\n                if node['prev']:\n                    node['prev']['next'] = node['next']\n                if node['next']:\n                    node['next']['prev'] = node['prev']\n                self.size -= 1\n                return True\n            node = node['next']\n        return False\n    \n    def to_list(self):\n        result = []\n        node = self.head\n        while node:\n            result.append(node['val'])\n            node = node['next']\n        return result", "tests": "def test_dll_append():\n    dll = DoublyLinkedList()\n    dll.append(1)\n    dll.append(2)\n    dll.append(3)\n    assert dll.to_list() == [1, 2, 3]\n\ndef test_dll_prepend():\n    dll = DoublyLinkedList()\n    dll.prepend(1)\n    dll.prepend(2)\n    dll.prepend(3)\n    assert dll.to_list() == [3, 2, 1]\n\ndef test_dll_delete_head():\n    dll = DoublyLinkedList()\n    dll.append(1)\n    dll.append(2)\n    dll.append(3)\n    dll.delete(1)\n    assert dll.to_list() == [2, 3]\n    assert dll.head['val'] == 2\n\ndef test_dll_delete_tail():\n    dll = DoublyLinkedList()\n    dll.append(1)\n    dll.append(2)\n    dll.append(3)\n    dll.delete(3)\n    assert dll.to_list() == [1, 2]\n    assert dll.tail['val'] == 2", "category": "bugfix", "topic": "linked_list", "tier": "oscillation", "starter_check": "fail", "approaches": ["dict_nodes", "class_nodes", "sentinel_nodes"]}
{"task_id": "osc_dll_002", "prompt": "Fix this linked list. Reverse doesn't work, iteration broken.", "signature": "class LinkedList:", "starter_code": "class LinkedList:\n    class Node:\n        def __init__(self, val):\n            self.val = val\n            self.next = None\n            self.prev = None\n    \n    def __init__(self):\n        self.head = None\n        self.tail = None\n    \n    def append(self, val):\n        node = self.Node(val)\n        if not self.head:\n            self.head = self.tail = node\n        else:\n            self.tail.next = node\n            node.prev = self.tail\n            self.tail = node\n    \n    def reverse(self):\n        current = self.head\n        while current:\n            # Bug: swap is incomplete\n            current.prev, current.next = current.next, current.prev\n            current = current.prev  # Bug: wrong direction after swap\n        # Bug: head/tail not swapped\n    \n    def __iter__(self):\n        node = self.head\n        while node:\n            yield node.val\n            node = node.next", "tests": "def test_ll_reverse():\n    ll = LinkedList()\n    for i in [1, 2, 3, 4, 5]:\n        ll.append(i)\n    ll.reverse()\n    assert list(ll) == [5, 4, 3, 2, 1]\n\ndef test_ll_reverse_single():\n    ll = LinkedList()\n    ll.append(42)\n    ll.reverse()\n    assert list(ll) == [42]\n\ndef test_ll_reverse_empty():\n    ll = LinkedList()\n    ll.reverse()\n    assert list(ll) == []\n\ndef test_ll_reverse_twice():\n    ll = LinkedList()\n    for i in [1, 2, 3]:\n        ll.append(i)\n    ll.reverse()\n    ll.reverse()\n    assert list(ll) == [1, 2, 3]", "category": "bugfix", "topic": "linked_list", "tier": "oscillation", "starter_check": "fail", "approaches": ["iterative_swap", "recursive_reverse", "new_list_copy"]}
{"task_id": "osc_timer_001", "prompt": "Fix this timer. Callback fires immediately, cancel doesn't work.", "signature": "class Timer:", "starter_code": "import threading\nimport time\n\nclass Timer:\n    def __init__(self, interval, callback):\n        self.interval = interval\n        self.callback = callback\n        self.cancelled = False\n        self.thread = None\n    \n    def start(self):\n        # Bug: no delay before callback\n        self.callback()\n    \n    def cancel(self):\n        # Bug: doesn't actually stop anything\n        self.cancelled = True", "tests": "def test_timer_delay():\n    import time\n    result = []\n    def cb():\n        result.append(time.time())\n    \n    start = time.time()\n    t = Timer(0.1, cb)\n    t.start()\n    time.sleep(0.15)\n    \n    assert len(result) == 1\n    assert result[0] - start >= 0.09  # Callback was delayed\n\ndef test_timer_cancel():\n    result = []\n    def cb():\n        result.append(1)\n    \n    t = Timer(0.1, cb)\n    t.start()\n    t.cancel()\n    time.sleep(0.15)\n    \n    assert len(result) == 0  # Callback never fired\n\ndef test_timer_multiple():\n    result = []\n    t1 = Timer(0.05, lambda: result.append('a'))\n    t2 = Timer(0.1, lambda: result.append('b'))\n    t1.start()\n    t2.start()\n    time.sleep(0.15)\n    assert result == ['a', 'b']", "category": "bugfix", "topic": "timer", "tier": "oscillation", "starter_check": "fail", "approaches": ["threading_timer", "thread_sleep", "event_based"]}
{"task_id": "osc_timer_002", "prompt": "Fix this repeating timer. Only fires once, stop doesn't work.", "signature": "class RepeatingTimer:", "starter_code": "import threading\nimport time\n\nclass RepeatingTimer:\n    def __init__(self, interval, callback):\n        self.interval = interval\n        self.callback = callback\n        self.running = False\n    \n    def start(self):\n        self.running = True\n        # Bug: only runs once\n        threading.Timer(self.interval, self.callback).start()\n    \n    def stop(self):\n        # Bug: doesn't stop the timer thread\n        self.running = False", "tests": "def test_repeating_timer():\n    import time\n    count = [0]\n    def cb():\n        count[0] += 1\n    \n    t = RepeatingTimer(0.05, cb)\n    t.start()\n    time.sleep(0.18)\n    t.stop()\n    \n    assert count[0] >= 3  # Should fire multiple times\n\ndef test_repeating_stop():\n    import time\n    count = [0]\n    def cb():\n        count[0] += 1\n    \n    t = RepeatingTimer(0.05, cb)\n    t.start()\n    time.sleep(0.08)\n    t.stop()\n    final = count[0]\n    time.sleep(0.1)\n    \n    assert count[0] == final  # No more fires after stop", "category": "bugfix", "topic": "timer", "tier": "oscillation", "starter_check": "fail", "approaches": ["recursive_timer", "loop_thread", "event_flag"]}
{"task_id": "osc_pool_001", "prompt": "Fix this thread pool. Tasks not executed, shutdown hangs.", "signature": "class ThreadPool:", "starter_code": "import threading\nimport queue\n\nclass ThreadPool:\n    def __init__(self, num_workers):\n        self.tasks = queue.Queue()\n        self.workers = []\n        for _ in range(num_workers):\n            t = threading.Thread(target=self._worker)\n            t.start()\n            # Bug: typo in attribute name\n            self.worker.append(t)\n    \n    def _worker(self):\n        while True:\n            task = self.tasks.get()\n            if task is None:\n                break\n            # Bug: not calling the task\n            task\n            self.tasks.task_done()\n    \n    def submit(self, fn):\n        self.tasks.put(fn)\n    \n    def shutdown(self):\n        for _ in self.workers:\n            self.tasks.put(None)\n        for w in self.workers:\n            w.join()", "tests": "def test_pool_execute():\n    import time\n    results = []\n    def task(x):\n        def inner():\n            results.append(x)\n        return inner\n    \n    pool = ThreadPool(2)\n    for i in range(5):\n        pool.submit(task(i))\n    time.sleep(0.1)\n    pool.shutdown()\n    \n    assert sorted(results) == [0, 1, 2, 3, 4]\n\ndef test_pool_concurrent():\n    import time\n    times = []\n    def slow_task():\n        time.sleep(0.05)\n        times.append(time.time())\n    \n    pool = ThreadPool(4)\n    start = time.time()\n    for _ in range(4):\n        pool.submit(slow_task)\n    pool.shutdown()\n    elapsed = time.time() - start\n    \n    assert elapsed < 0.1  # Concurrent, not serial", "category": "bugfix", "topic": "thread_pool", "tier": "oscillation", "starter_check": "fail", "approaches": ["queue_workers", "futures_pattern", "dynamic_threads"]}
{"task_id": "osc_pool_002", "prompt": "Fix this connection pool. Connections leak, exhaustion not handled.", "signature": "class ConnectionPool:", "starter_code": "import threading\nimport queue\n\nclass ConnectionPool:\n    def __init__(self, max_size, factory):\n        self.max_size = max_size\n        self.factory = factory\n        self.pool = queue.Queue(maxsize=max_size)\n        self.size = 0\n        self.lock = threading.Lock()\n    \n    def acquire(self):\n        # Bug: doesn't create new connections\n        try:\n            return self.pool.get_nowait()\n        except queue.Empty:\n            return None\n    \n    def release(self, conn):\n        # Bug: doesn't handle full pool\n        self.pool.put(conn)", "tests": "def test_pool_reuse():\n    created = [0]\n    def factory():\n        created[0] += 1\n        return f'conn_{created[0]}'\n    \n    pool = ConnectionPool(2, factory)\n    c1 = pool.acquire()\n    c2 = pool.acquire()\n    assert c1 is not None\n    assert c2 is not None\n    \n    pool.release(c1)\n    c3 = pool.acquire()\n    assert c3 == c1  # Reused\n\ndef test_pool_limit():\n    pool = ConnectionPool(2, lambda: object())\n    c1 = pool.acquire()\n    c2 = pool.acquire()\n    c3 = pool.acquire()  # Should block or return None\n    \n    # Either blocking with timeout or returns None\n    assert c3 is None or c3 is not None\n\ndef test_pool_exhaust_wait():\n    import time\n    pool = ConnectionPool(1, lambda: 'conn')\n    c1 = pool.acquire()\n    \n    result = [None]\n    def get_conn():\n        result[0] = pool.acquire()\n    \n    t = threading.Thread(target=get_conn)\n    t.start()\n    time.sleep(0.05)\n    pool.release(c1)\n    t.join(timeout=0.1)\n    \n    assert result[0] is not None", "category": "bugfix", "topic": "connection_pool", "tier": "oscillation", "starter_check": "fail", "approaches": ["semaphore_based", "queue_blocking", "list_with_lock"]}
{"task_id": "osc_ratelimit_001", "prompt": "Fix this rate limiter. Allows bursts beyond limit, doesn't reset properly.", "signature": "class RateLimiter:", "starter_code": "import time\n\nclass RateLimiter:\n    def __init__(self, max_requests, window_seconds):\n        self.max_requests = max_requests\n        self.window = window_seconds\n        self.requests = []\n    \n    def allow(self):\n        now = time.time()\n        # Bug: not cleaning old requests\n        self.requests.append(now)\n        return len(self.requests) <= self.max_requests", "tests": "def test_ratelimit_basic():\n    rl = RateLimiter(3, 1.0)\n    assert rl.allow()\n    assert rl.allow()\n    assert rl.allow()\n    assert not rl.allow()  # 4th should fail\n\ndef test_ratelimit_reset():\n    import time\n    rl = RateLimiter(2, 0.1)\n    assert rl.allow()\n    assert rl.allow()\n    assert not rl.allow()\n    time.sleep(0.15)\n    assert rl.allow()  # Should reset after window\n\ndef test_ratelimit_sliding():\n    import time\n    rl = RateLimiter(3, 0.1)\n    rl.allow()\n    time.sleep(0.05)\n    rl.allow()\n    time.sleep(0.05)\n    rl.allow()\n    time.sleep(0.05)\n    # First request expired, should allow\n    assert rl.allow()", "category": "bugfix", "topic": "rate_limiting", "tier": "oscillation", "starter_check": "fail", "approaches": ["sliding_window_log", "token_bucket", "fixed_window_counter"]}
{"task_id": "osc_ratelimit_002", "prompt": "Fix this token bucket. Tokens don't refill, bursts miscounted.", "signature": "class TokenBucket:", "starter_code": "import time\n\nclass TokenBucket:\n    def __init__(self, capacity, refill_rate):\n        self.capacity = capacity\n        self.tokens = capacity\n        self.refill_rate = refill_rate  # tokens per second\n        self.last_refill = time.time()\n    \n    def consume(self, tokens=1):\n        # Bug: refill calculation wrong\n        now = time.time()\n        elapsed = now - self.last_refill\n        # Bug: not updating last_refill\n        self.tokens = min(self.capacity, self.tokens + elapsed)\n        \n        if self.tokens >= tokens:\n            self.tokens -= tokens\n            return True\n        return False", "tests": "def test_bucket_initial():\n    tb = TokenBucket(5, 1.0)\n    for _ in range(5):\n        assert tb.consume()\n    assert not tb.consume()\n\ndef test_bucket_refill():\n    import time\n    tb = TokenBucket(2, 10.0)  # 10 tokens/sec\n    tb.consume()\n    tb.consume()\n    assert not tb.consume()\n    time.sleep(0.15)  # Should refill ~1.5 tokens\n    assert tb.consume()\n\ndef test_bucket_burst():\n    tb = TokenBucket(10, 1.0)\n    # Should allow burst up to capacity\n    for _ in range(10):\n        assert tb.consume()\n    assert not tb.consume()", "category": "bugfix", "topic": "rate_limiting", "tier": "oscillation", "starter_check": "fail", "approaches": ["token_bucket_fixed", "leaky_bucket", "sliding_window"]}
{"task_id": "osc_lru_001", "prompt": "Fix this LRU cache decorator. Caching wrong values, not respecting maxsize.", "signature": "def lru_cache(maxsize=128):", "starter_code": "def lru_cache(maxsize=128):\n    def decorator(func):\n        cache = {}\n        order = []  # Track access order\n        \n        def wrapper(*args):\n            key = args\n            if key in cache:\n                # Bug: not updating order\n                return cache[key]\n            \n            result = func(*args)\n            cache[key] = result\n            order.append(key)\n            \n            # Bug: wrong eviction\n            if len(cache) > maxsize:\n                oldest = order[0]\n                del cache[oldest]\n                # Bug: not removing from order\n            \n            return result\n        \n        return wrapper\n    return decorator", "tests": "def test_lru_basic():\n    call_count = [0]\n    \n    @lru_cache(maxsize=2)\n    def expensive(x):\n        call_count[0] += 1\n        return x * 2\n    \n    assert expensive(1) == 2\n    assert expensive(1) == 2  # Cached\n    assert call_count[0] == 1\n\ndef test_lru_eviction():\n    @lru_cache(maxsize=2)\n    def fn(x):\n        return x\n    \n    fn(1)\n    fn(2)\n    fn(1)  # Access 1, making 2 least recent\n    fn(3)  # Should evict 2\n    \n    # 1 should still be cached, 2 should be evicted\n    call_count = [0]\n    original_fn = fn.__wrapped__ if hasattr(fn, '__wrapped__') else None\n\ndef test_lru_order():\n    calls = []\n    \n    @lru_cache(maxsize=2)\n    def track(x):\n        calls.append(x)\n        return x\n    \n    track(1)\n    track(2)\n    track(1)  # Refresh 1\n    track(3)  # Evict 2\n    track(2)  # Miss - should call again\n    \n    assert calls == [1, 2, 3, 2]", "category": "bugfix", "topic": "caching", "tier": "oscillation", "starter_check": "fail", "approaches": ["ordereddict_move", "list_tracking", "functools_wrapper"]}
{"task_id": "osc_lru_002", "prompt": "Fix this memoization decorator. Thread-unsafe, memory leak.", "signature": "def memoize(func):", "starter_code": "import threading\n\ndef memoize(func):\n    cache = {}\n    \n    def wrapper(*args, **kwargs):\n        # Bug: kwargs not handled in key\n        key = args\n        if key in cache:\n            return cache[key]\n        # Bug: not thread-safe\n        result = func(*args, **kwargs)\n        cache[key] = result\n        return result\n    \n    wrapper.cache = cache\n    return wrapper", "tests": "def test_memo_basic():\n    calls = [0]\n    \n    @memoize\n    def fib(n):\n        calls[0] += 1\n        if n < 2:\n            return n\n        return fib(n-1) + fib(n-2)\n    \n    assert fib(10) == 55\n    initial_calls = calls[0]\n    fib(10)\n    assert calls[0] == initial_calls  # No new calls\n\ndef test_memo_kwargs():\n    @memoize\n    def greet(name, greeting='Hello'):\n        return f'{greeting}, {name}'\n    \n    assert greet('Alice') == 'Hello, Alice'\n    assert greet('Alice', greeting='Hi') == 'Hi, Alice'\n    assert greet(name='Alice') == 'Hello, Alice'\n\ndef test_memo_threadsafe():\n    import threading\n    import time\n    \n    calls = [0]\n    \n    @memoize\n    def slow(x):\n        calls[0] += 1\n        time.sleep(0.01)\n        return x * 2\n    \n    threads = [threading.Thread(target=lambda: slow(1)) for _ in range(10)]\n    for t in threads:\n        t.start()\n    for t in threads:\n        t.join()\n    \n    # With proper locking, should only call once\n    assert calls[0] <= 2  # Allow small race window", "category": "bugfix", "topic": "caching", "tier": "oscillation", "starter_check": "fail", "approaches": ["lock_protected", "thread_local", "concurrent_dict"]}
{"task_id": "osc_retry_001", "prompt": "Fix this retry decorator. Wrong delay, doesn't respect max attempts.", "signature": "def retry(max_attempts=3, delay=1.0):", "starter_code": "import time\n\ndef retry(max_attempts=3, delay=1.0):\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            attempts = 0\n            while True:  # Bug: infinite loop possible\n                try:\n                    return func(*args, **kwargs)\n                except Exception as e:\n                    attempts += 1\n                    # Bug: sleeps before checking attempts\n                    time.sleep(delay)\n                    if attempts >= max_attempts:\n                        raise\n        return wrapper\n    return decorator", "tests": "def test_retry_success():\n    attempts = [0]\n    \n    @retry(max_attempts=3, delay=0.01)\n    def flaky():\n        attempts[0] += 1\n        if attempts[0] < 2:\n            raise ValueError('fail')\n        return 'ok'\n    \n    assert flaky() == 'ok'\n    assert attempts[0] == 2\n\ndef test_retry_exhaust():\n    attempts = [0]\n    \n    @retry(max_attempts=3, delay=0.01)\n    def always_fail():\n        attempts[0] += 1\n        raise ValueError('fail')\n    \n    try:\n        always_fail()\n        assert False, 'Should have raised'\n    except ValueError:\n        pass\n    \n    assert attempts[0] == 3\n\ndef test_retry_no_delay_after_last():\n    import time\n    \n    @retry(max_attempts=2, delay=0.1)\n    def fail():\n        raise ValueError()\n    \n    start = time.time()\n    try:\n        fail()\n    except ValueError:\n        pass\n    elapsed = time.time() - start\n    \n    # Should only delay once (between attempt 1 and 2)\n    assert elapsed < 0.15", "category": "bugfix", "topic": "retry", "tier": "oscillation", "starter_check": "fail", "approaches": ["delay_between", "delay_after_fail", "exponential_backoff"]}
{"task_id": "osc_retry_002", "prompt": "Fix this exponential backoff retry. Backoff not exponential, jitter broken.", "signature": "def retry_with_backoff(max_attempts=3, base_delay=1.0, max_delay=60.0):", "starter_code": "import time\nimport random\n\ndef retry_with_backoff(max_attempts=3, base_delay=1.0, max_delay=60.0):\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            last_exception = None\n            for attempt in range(max_attempts):\n                try:\n                    return func(*args, **kwargs)\n                except Exception as e:\n                    last_exception = e\n                    # Bug: linear not exponential\n                    delay = base_delay * attempt\n                    # Bug: jitter can make delay negative\n                    delay += random.uniform(-delay, delay)\n                    delay = min(delay, max_delay)\n                    time.sleep(delay)\n            raise last_exception\n        return wrapper\n    return decorator", "tests": "def test_backoff_exponential():\n    import time\n    delays = []\n    \n    attempts = [0]\n    \n    @retry_with_backoff(max_attempts=4, base_delay=0.05, max_delay=1.0)\n    def measure_delays():\n        delays.append(time.time())\n        attempts[0] += 1\n        if attempts[0] < 4:\n            raise ValueError()\n        return 'ok'\n    \n    start = time.time()\n    result = measure_delays()\n    \n    # Delays should be roughly: 0.05, 0.1, 0.2 (exponential)\n    # Total should be > 0.3 for exponential\n    elapsed = time.time() - start\n    assert elapsed > 0.25\n\ndef test_backoff_max_delay():\n    @retry_with_backoff(max_attempts=2, base_delay=100.0, max_delay=0.05)\n    def fail():\n        raise ValueError()\n    \n    import time\n    start = time.time()\n    try:\n        fail()\n    except ValueError:\n        pass\n    \n    # Should be capped at max_delay\n    assert time.time() - start < 0.1\n\ndef test_backoff_jitter_positive():\n    @retry_with_backoff(max_attempts=3, base_delay=0.01, max_delay=1.0)\n    def fail():\n        raise ValueError()\n    \n    # Should not hang or error due to negative delays\n    import time\n    start = time.time()\n    try:\n        fail()\n    except ValueError:\n        pass\n    assert time.time() - start >= 0", "category": "bugfix", "topic": "retry", "tier": "oscillation", "starter_check": "fail", "approaches": ["power_of_two", "multiply_backoff", "decorrelated_jitter"]}
{"task_id": "osc_event_001", "prompt": "Fix this event emitter. Handlers not called, once doesn't work.", "signature": "class EventEmitter:", "starter_code": "class EventEmitter:\n    def __init__(self):\n        self.listeners = {}\n    \n    def on(self, event, handler):\n        if event not in self.listeners:\n            self.listeners[event] = []\n        # Bug: adding handler incorrectly\n        self.listeners[event] = handler\n    \n    def once(self, event, handler):\n        def wrapper(*args):\n            handler(*args)\n            # Bug: doesn't remove after call\n        self.on(event, wrapper)\n    \n    def emit(self, event, *args):\n        if event not in self.listeners:\n            return\n        # Bug: listeners is not a list anymore\n        for handler in self.listeners[event]:\n            handler(*args)\n    \n    def off(self, event, handler):\n        if event in self.listeners:\n            self.listeners[event].remove(handler)", "tests": "def test_emitter_basic():\n    ee = EventEmitter()\n    results = []\n    ee.on('data', lambda x: results.append(x))\n    ee.emit('data', 1)\n    ee.emit('data', 2)\n    assert results == [1, 2]\n\ndef test_emitter_multiple():\n    ee = EventEmitter()\n    results = []\n    ee.on('event', lambda: results.append('a'))\n    ee.on('event', lambda: results.append('b'))\n    ee.emit('event')\n    assert set(results) == {'a', 'b'}\n\ndef test_emitter_once():\n    ee = EventEmitter()\n    count = [0]\n    ee.once('single', lambda: count.__setitem__(0, count[0] + 1))\n    ee.emit('single')\n    ee.emit('single')\n    ee.emit('single')\n    assert count[0] == 1", "category": "bugfix", "topic": "events", "tier": "oscillation", "starter_check": "fail", "approaches": ["list_handlers", "dict_with_id", "weakref_handlers"]}
{"task_id": "osc_event_002", "prompt": "Fix this pub/sub system. Messages lost, unsubscribe doesn't work.", "signature": "class PubSub:", "starter_code": "class PubSub:\n    def __init__(self):\n        self.topics = {}\n        self.subscriber_id = 0\n    \n    def subscribe(self, topic, callback):\n        if topic not in self.topics:\n            self.topics[topic] = {}\n        self.subscriber_id += 1\n        # Bug: wrong key assignment\n        self.topics[topic] = {self.subscriber_id: callback}\n        return self.subscriber_id\n    \n    def unsubscribe(self, topic, sub_id):\n        if topic in self.topics and sub_id in self.topics[topic]:\n            # Bug: deletes wrong thing\n            del self.topics[topic]\n    \n    def publish(self, topic, message):\n        if topic not in self.topics:\n            return 0\n        count = 0\n        for callback in self.topics[topic].values():\n            callback(message)\n            count += 1\n        return count", "tests": "def test_pubsub_basic():\n    ps = PubSub()\n    results = []\n    ps.subscribe('news', lambda m: results.append(m))\n    ps.publish('news', 'hello')\n    assert results == ['hello']\n\ndef test_pubsub_multi_subscriber():\n    ps = PubSub()\n    results = []\n    ps.subscribe('topic', lambda m: results.append(f'a:{m}'))\n    ps.subscribe('topic', lambda m: results.append(f'b:{m}'))\n    count = ps.publish('topic', 'msg')\n    assert count == 2\n    assert 'a:msg' in results\n    assert 'b:msg' in results\n\ndef test_pubsub_unsubscribe():\n    ps = PubSub()\n    results = []\n    sub_id = ps.subscribe('ch', lambda m: results.append(m))\n    ps.publish('ch', 1)\n    ps.unsubscribe('ch', sub_id)\n    ps.publish('ch', 2)\n    assert results == [1]  # Second publish should not reach", "category": "bugfix", "topic": "events", "tier": "oscillation", "starter_check": "fail", "approaches": ["dict_subscribers", "list_with_ids", "weakref_callbacks"]}
{"task_id": "osc_trie_001", "prompt": "Fix this trie: search returns true for prefixes and case handling breaks exact matches.", "signature": "class Trie:", "starter_code": "class Trie:\n    def __init__(self):\n        self.children = {}  # dict children\n        self.end = False\n        self.count = 0\n\n    def insert(self, word: str) -> None:\n        node = self\n        for ch in word:\n            # Bug: lowercasing changes semantics; tests include case sensitivity\n            ch = ch.lower()\n            if ch not in node.children:\n                node.children[ch] = Trie()\n            node = node.children[ch]\n            # Bug: count updated on node, but should represent prefix counts at node\n            node.count += 1\n        node.end = True\n\n    def search(self, word: str) -> bool:\n        node = self\n        for ch in word:\n            if ch not in node.children:\n                return False\n            node = node.children[ch]\n        # Bug: should check node.end\n        return True\n\n    def starts_with(self, prefix: str) -> int:\n        node = self\n        for ch in prefix:\n            if ch not in node.children:\n                return 0\n            node = node.children[ch]\n        return node.count", "tests": "def test_trie_search_exact():\n    t = Trie()\n    t.insert(\"Apple\")\n    assert t.search(\"Apple\") is True\n    assert t.search(\"App\") is False\n    assert t.search(\"apple\") is False  # case-sensitive\n\ndef test_trie_prefix_counts():\n    t = Trie()\n    for w in [\"app\", \"apple\", \"application\"]:\n        t.insert(w)\n    assert t.starts_with(\"app\") == 3\n    assert t.starts_with(\"appl\") == 2\n    assert t.starts_with(\"b\") == 0\n\ndef test_trie_nonexistent():\n    t = Trie()\n    t.insert(\"a\")\n    assert t.search(\"aa\") is False\n    assert t.starts_with(\"aa\") == 0", "category": "bugfix", "topic": "trie", "tier": "oscillation", "starter_check": "fail", "approaches": ["dict_children", "array_children_fixed", "nested_dict_nodes"]}
{"task_id": "osc_trie_002", "prompt": "Fix this trie: prefix counting only counts terminals and insertion breaks on non-lowercase characters.", "signature": "class Trie:", "starter_code": "class Trie:\n    def __init__(self):\n        self.children = [None] * 26  # array approach\n        self.end = False\n        self.words = 0\n\n    def _idx(self, ch: str) -> int:\n        return ord(ch) - ord(\"a\")\n\n    def insert(self, word: str) -> None:\n        node = self\n        for ch in word:\n            j = node._idx(ch)\n            # Bug: no bounds/check for non-lowercase; should support arbitrary chars via dict or mapping\n            if node.children[j] is None:\n                node.children[j] = Trie()\n            node = node.children[j]\n        node.end = True\n        # Bug: increments words on leaf only; tests expect prefix counts too via count_prefix\n        node.words += 1\n\n    def search(self, word: str) -> bool:\n        node = self\n        for ch in word:\n            j = node._idx(ch)\n            if node.children[j] is None:\n                return False\n            node = node.children[j]\n        return node.end\n\n    def count_prefix(self, prefix: str) -> int:\n        node = self\n        for ch in prefix:\n            j = node._idx(ch)\n            if node.children[j] is None:\n                return 0\n            node = node.children[j]\n        # Bug: counts only terminal words at node, not all words under subtree\n        return node.words", "tests": "def test_trie_supports_mixed_chars():\n    t = Trie()\n    t.insert(\"a-1\")\n    assert t.search(\"a-1\") is True\n    assert t.search(\"a\") is False\n\ndef test_trie_prefix_subtree_count():\n    t = Trie()\n    for w in [\"ab\", \"abc\", \"abd\", \"b\"]:\n        t.insert(w)\n    assert t.count_prefix(\"a\") == 3\n    assert t.count_prefix(\"ab\") == 3\n    assert t.count_prefix(\"abc\") == 1\n    assert t.count_prefix(\"z\") == 0", "category": "bugfix", "topic": "trie", "tier": "oscillation", "starter_check": "fail", "approaches": ["dict_children_general", "array_children_with_escape_map", "nested_defaultdict"]}
{"task_id": "osc_trie_003", "prompt": "Fix this trie: remove deletes shared prefixes and can remove non-words.", "signature": "class Trie:", "starter_code": "class Trie:\n    def __init__(self):\n        self.children = {}\n        self.end = False\n        self.freq = 0\n    def insert(self, word: str) -> None:\n        node = self\n        for ch in word:\n            # Bug: uses setdefault but accidentally stores bool instead of node on existing path\n            node.children.setdefault(ch, Trie())\n            node = node.children[ch]\n        node.end = True\n        node.freq += 1\n    def remove(self, word: str) -> bool:\n        path = []\n        node = self\n        for ch in word:\n            if ch not in node.children:\n                return False\n            path.append((node, ch))\n            node = node.children[ch]\n        # Bug: removes even when not end (removing prefix)\n        node.end = False\n        node.freq = 0\n        # Bug: pruning condition wrong; may delete shared prefixes\n        for parent, ch in reversed(path):\n            child = parent.children[ch]\n            if child.children:\n                break\n            del parent.children[ch]\n        return True\n    def search(self, word: str) -> bool:\n        node = self\n        for ch in word:\n            if ch not in node.children:\n                return False\n            node = node.children[ch]\n        return node.end", "tests": "def test_trie_remove_keeps_shared_prefix():\n    t = Trie()\n    t.insert(\"car\")\n    t.insert(\"cart\")\n    assert t.search(\"car\") is True\n    assert t.search(\"cart\") is True\n    assert t.remove(\"car\") is True\n    assert t.search(\"car\") is False\n    assert t.search(\"cart\") is True  # shared path must remain\n\ndef test_trie_remove_only_exact_word():\n    t = Trie()\n    t.insert(\"app\")\n    t.insert(\"apple\")\n    assert t.remove(\"ap\") is False\n    assert t.search(\"app\") is True\n    assert t.search(\"apple\") is True\n\ndef test_trie_remove_idempotent():\n    t = Trie()\n    t.insert(\"x\")\n    assert t.remove(\"x\") is True\n    assert t.remove(\"x\") is False", "category": "bugfix", "topic": "trie", "tier": "oscillation", "starter_check": "fail", "approaches": ["dict_nodes_with_refcount", "recursive_delete", "stack_prune_safe"]}
{"task_id": "osc_trie_004", "prompt": "Fix this trie: search returns true for prefixes and case handling breaks exact matches.", "signature": "class Trie:", "starter_code": "class Trie:\n    def __init__(self):\n        self.children = {}  # dict children\n        self.end = False\n        self.count = 0\n\n    def insert(self, word: str) -> None:\n        node = self\n        for ch in word:\n            # Bug: lowercasing changes semantics; tests include case sensitivity\n            ch = ch.lower()\n            if ch not in node.children:\n                node.children[ch] = Trie()\n            node = node.children[ch]\n            # Bug: count updated on node, but should represent prefix counts at node\n            node.count += 1\n        node.end = True\n\n    def search(self, word: str) -> bool:\n        node = self\n        for ch in word:\n            if ch not in node.children:\n                return False\n            node = node.children[ch]\n        # Bug: should check node.end\n        return True\n\n    def starts_with(self, prefix: str) -> int:\n        node = self\n        for ch in prefix:\n            if ch not in node.children:\n                return 0\n            node = node.children[ch]\n        return node.count", "tests": "def test_trie_search_exact():\n    t = Trie()\n    t.insert(\"Apple\")\n    assert t.search(\"Apple\") is True\n    assert t.search(\"App\") is False\n    assert t.search(\"apple\") is False  # case-sensitive\n\ndef test_trie_prefix_counts():\n    t = Trie()\n    for w in [\"app\", \"apple\", \"application\"]:\n        t.insert(w)\n    assert t.starts_with(\"app\") == 3\n    assert t.starts_with(\"appl\") == 2\n    assert t.starts_with(\"b\") == 0\n\ndef test_trie_nonexistent():\n    t = Trie()\n    t.insert(\"a\")\n    assert t.search(\"aa\") is False\n    assert t.starts_with(\"aa\") == 0", "category": "bugfix", "topic": "trie", "tier": "oscillation", "starter_check": "fail", "approaches": ["dict_children", "array_children_fixed", "nested_dict_nodes"]}
{"task_id": "osc_trie_005", "prompt": "Fix this trie: prefix counting only counts terminals and insertion breaks on non-lowercase characters.", "signature": "class Trie:", "starter_code": "class Trie:\n    def __init__(self):\n        self.children = [None] * 26  # array approach\n        self.end = False\n        self.words = 0\n\n    def _idx(self, ch: str) -> int:\n        return ord(ch) - ord(\"a\")\n\n    def insert(self, word: str) -> None:\n        node = self\n        for ch in word:\n            j = node._idx(ch)\n            # Bug: no bounds/check for non-lowercase; should support arbitrary chars via dict or mapping\n            if node.children[j] is None:\n                node.children[j] = Trie()\n            node = node.children[j]\n        node.end = True\n        # Bug: increments words on leaf only; tests expect prefix counts too via count_prefix\n        node.words += 1\n\n    def search(self, word: str) -> bool:\n        node = self\n        for ch in word:\n            j = node._idx(ch)\n            if node.children[j] is None:\n                return False\n            node = node.children[j]\n        return node.end\n\n    def count_prefix(self, prefix: str) -> int:\n        node = self\n        for ch in prefix:\n            j = node._idx(ch)\n            if node.children[j] is None:\n                return 0\n            node = node.children[j]\n        # Bug: counts only terminal words at node, not all words under subtree\n        return node.words", "tests": "def test_trie_supports_mixed_chars():\n    t = Trie()\n    t.insert(\"a-1\")\n    assert t.search(\"a-1\") is True\n    assert t.search(\"a\") is False\n\ndef test_trie_prefix_subtree_count():\n    t = Trie()\n    for w in [\"ab\", \"abc\", \"abd\", \"b\"]:\n        t.insert(w)\n    assert t.count_prefix(\"a\") == 3\n    assert t.count_prefix(\"ab\") == 3\n    assert t.count_prefix(\"abc\") == 1\n    assert t.count_prefix(\"z\") == 0", "category": "bugfix", "topic": "trie", "tier": "oscillation", "starter_check": "fail", "approaches": ["dict_children_general", "array_children_with_escape_map", "nested_defaultdict"]}
{"task_id": "osc_trie_006", "prompt": "Fix this trie: remove deletes shared prefixes and can remove non-words.", "signature": "class Trie:", "starter_code": "class Trie:\n    def __init__(self):\n        self.children = {}\n        self.end = False\n        self.freq = 0\n    def insert(self, word: str) -> None:\n        node = self\n        for ch in word:\n            # Bug: uses setdefault but accidentally stores bool instead of node on existing path\n            node.children.setdefault(ch, Trie())\n            node = node.children[ch]\n        node.end = True\n        node.freq += 1\n    def remove(self, word: str) -> bool:\n        path = []\n        node = self\n        for ch in word:\n            if ch not in node.children:\n                return False\n            path.append((node, ch))\n            node = node.children[ch]\n        # Bug: removes even when not end (removing prefix)\n        node.end = False\n        node.freq = 0\n        # Bug: pruning condition wrong; may delete shared prefixes\n        for parent, ch in reversed(path):\n            child = parent.children[ch]\n            if child.children:\n                break\n            del parent.children[ch]\n        return True\n    def search(self, word: str) -> bool:\n        node = self\n        for ch in word:\n            if ch not in node.children:\n                return False\n            node = node.children[ch]\n        return node.end", "tests": "def test_trie_remove_keeps_shared_prefix():\n    t = Trie()\n    t.insert(\"car\")\n    t.insert(\"cart\")\n    assert t.search(\"car\") is True\n    assert t.search(\"cart\") is True\n    assert t.remove(\"car\") is True\n    assert t.search(\"car\") is False\n    assert t.search(\"cart\") is True  # shared path must remain\n\ndef test_trie_remove_only_exact_word():\n    t = Trie()\n    t.insert(\"app\")\n    t.insert(\"apple\")\n    assert t.remove(\"ap\") is False\n    assert t.search(\"app\") is True\n    assert t.search(\"apple\") is True\n\ndef test_trie_remove_idempotent():\n    t = Trie()\n    t.insert(\"x\")\n    assert t.remove(\"x\") is True\n    assert t.remove(\"x\") is False", "category": "bugfix", "topic": "trie", "tier": "oscillation", "starter_check": "fail", "approaches": ["dict_nodes_with_refcount", "recursive_delete", "stack_prune_safe"]}
{"task_id": "osc_trie_007", "prompt": "Fix this trie: search returns true for prefixes and case handling breaks exact matches.", "signature": "class Trie:", "starter_code": "class Trie:\n    def __init__(self):\n        self.children = {}  # dict children\n        self.end = False\n        self.count = 0\n\n    def insert(self, word: str) -> None:\n        node = self\n        for ch in word:\n            # Bug: lowercasing changes semantics; tests include case sensitivity\n            ch = ch.lower()\n            if ch not in node.children:\n                node.children[ch] = Trie()\n            node = node.children[ch]\n            # Bug: count updated on node, but should represent prefix counts at node\n            node.count += 1\n        node.end = True\n\n    def search(self, word: str) -> bool:\n        node = self\n        for ch in word:\n            if ch not in node.children:\n                return False\n            node = node.children[ch]\n        # Bug: should check node.end\n        return True\n\n    def starts_with(self, prefix: str) -> int:\n        node = self\n        for ch in prefix:\n            if ch not in node.children:\n                return 0\n            node = node.children[ch]\n        return node.count", "tests": "def test_trie_search_exact():\n    t = Trie()\n    t.insert(\"Apple\")\n    assert t.search(\"Apple\") is True\n    assert t.search(\"App\") is False\n    assert t.search(\"apple\") is False  # case-sensitive\n\ndef test_trie_prefix_counts():\n    t = Trie()\n    for w in [\"app\", \"apple\", \"application\"]:\n        t.insert(w)\n    assert t.starts_with(\"app\") == 3\n    assert t.starts_with(\"appl\") == 2\n    assert t.starts_with(\"b\") == 0\n\ndef test_trie_nonexistent():\n    t = Trie()\n    t.insert(\"a\")\n    assert t.search(\"aa\") is False\n    assert t.starts_with(\"aa\") == 0", "category": "bugfix", "topic": "trie", "tier": "oscillation", "starter_check": "fail", "approaches": ["dict_children", "array_children_fixed", "nested_dict_nodes"]}
{"task_id": "osc_trie_008", "prompt": "Fix this trie: prefix counting only counts terminals and insertion breaks on non-lowercase characters.", "signature": "class Trie:", "starter_code": "class Trie:\n    def __init__(self):\n        self.children = [None] * 26  # array approach\n        self.end = False\n        self.words = 0\n\n    def _idx(self, ch: str) -> int:\n        return ord(ch) - ord(\"a\")\n\n    def insert(self, word: str) -> None:\n        node = self\n        for ch in word:\n            j = node._idx(ch)\n            # Bug: no bounds/check for non-lowercase; should support arbitrary chars via dict or mapping\n            if node.children[j] is None:\n                node.children[j] = Trie()\n            node = node.children[j]\n        node.end = True\n        # Bug: increments words on leaf only; tests expect prefix counts too via count_prefix\n        node.words += 1\n\n    def search(self, word: str) -> bool:\n        node = self\n        for ch in word:\n            j = node._idx(ch)\n            if node.children[j] is None:\n                return False\n            node = node.children[j]\n        return node.end\n\n    def count_prefix(self, prefix: str) -> int:\n        node = self\n        for ch in prefix:\n            j = node._idx(ch)\n            if node.children[j] is None:\n                return 0\n            node = node.children[j]\n        # Bug: counts only terminal words at node, not all words under subtree\n        return node.words", "tests": "def test_trie_supports_mixed_chars():\n    t = Trie()\n    t.insert(\"a-1\")\n    assert t.search(\"a-1\") is True\n    assert t.search(\"a\") is False\n\ndef test_trie_prefix_subtree_count():\n    t = Trie()\n    for w in [\"ab\", \"abc\", \"abd\", \"b\"]:\n        t.insert(w)\n    assert t.count_prefix(\"a\") == 3\n    assert t.count_prefix(\"ab\") == 3\n    assert t.count_prefix(\"abc\") == 1\n    assert t.count_prefix(\"z\") == 0", "category": "bugfix", "topic": "trie", "tier": "oscillation", "starter_check": "fail", "approaches": ["dict_children_general", "array_children_with_escape_map", "nested_defaultdict"]}
{"task_id": "osc_trie_009", "prompt": "Fix this trie: remove deletes shared prefixes and can remove non-words.", "signature": "class Trie:", "starter_code": "class Trie:\n    def __init__(self):\n        self.children = {}\n        self.end = False\n        self.freq = 0\n    def insert(self, word: str) -> None:\n        node = self\n        for ch in word:\n            # Bug: uses setdefault but accidentally stores bool instead of node on existing path\n            node.children.setdefault(ch, Trie())\n            node = node.children[ch]\n        node.end = True\n        node.freq += 1\n    def remove(self, word: str) -> bool:\n        path = []\n        node = self\n        for ch in word:\n            if ch not in node.children:\n                return False\n            path.append((node, ch))\n            node = node.children[ch]\n        # Bug: removes even when not end (removing prefix)\n        node.end = False\n        node.freq = 0\n        # Bug: pruning condition wrong; may delete shared prefixes\n        for parent, ch in reversed(path):\n            child = parent.children[ch]\n            if child.children:\n                break\n            del parent.children[ch]\n        return True\n    def search(self, word: str) -> bool:\n        node = self\n        for ch in word:\n            if ch not in node.children:\n                return False\n            node = node.children[ch]\n        return node.end", "tests": "def test_trie_remove_keeps_shared_prefix():\n    t = Trie()\n    t.insert(\"car\")\n    t.insert(\"cart\")\n    assert t.search(\"car\") is True\n    assert t.search(\"cart\") is True\n    assert t.remove(\"car\") is True\n    assert t.search(\"car\") is False\n    assert t.search(\"cart\") is True  # shared path must remain\n\ndef test_trie_remove_only_exact_word():\n    t = Trie()\n    t.insert(\"app\")\n    t.insert(\"apple\")\n    assert t.remove(\"ap\") is False\n    assert t.search(\"app\") is True\n    assert t.search(\"apple\") is True\n\ndef test_trie_remove_idempotent():\n    t = Trie()\n    t.insert(\"x\")\n    assert t.remove(\"x\") is True\n    assert t.remove(\"x\") is False", "category": "bugfix", "topic": "trie", "tier": "oscillation", "starter_check": "fail", "approaches": ["dict_nodes_with_refcount", "recursive_delete", "stack_prune_safe"]}
{"task_id": "osc_heap_001", "prompt": "Fix this min-heap: initialization and pop break ordering.", "signature": "class MinHeap:", "starter_code": "import heapq\n\nclass MinHeap:\n    def __init__(self, items=None):\n        self.data = list(items or [])\n        # Bug: heapify missing; data may not be a heap\n        self.size = len(self.data)\n\n    def push(self, x):\n        heapq.heappush(self.data, x)\n        self.size += 1\n\n    def pop(self):\n        # Bug: uses list.pop which breaks heap invariant\n        if not self.data:\n            raise IndexError(\"empty\")\n        self.size -= 1\n        return self.data.pop(0)\n\n    def peek(self):\n        if not self.data:\n            return None\n        return self.data[0]", "tests": "def test_minheap_orders():\n    h = MinHeap([5, 1, 3])\n    assert h.peek() == 1\n    assert [h.pop(), h.pop(), h.pop()] == [1, 3, 5]\n\ndef test_minheap_push_pop_mix():\n    h = MinHeap()\n    for x in [4, 2, 7, 1]:\n        h.push(x)\n    assert h.pop() == 1\n    h.push(0)\n    assert h.pop() == 0\n    assert h.pop() == 2\n\ndef test_minheap_empty():\n    h = MinHeap()\n    assert h.peek() is None", "category": "bugfix", "topic": "heap", "tier": "oscillation", "starter_check": "fail", "approaches": ["heapq_proper_heapify", "manual_sift_up_down", "sorted_list_with_bisect"]}
{"task_id": "osc_heap_002", "prompt": "Fix this max-heap: comparisons are inverted and pop order is wrong.", "signature": "class MaxHeap:", "starter_code": "class MaxHeap:\n    def __init__(self):\n        self.a = []\n    def push(self, x: int) -> None:\n        self.a.append(x)\n        self._sift_up(len(self.a) - 1)\n    def _sift_up(self, i: int) -> None:\n        while i > 0:\n            p = (i - 1) // 2\n            # Bug: wrong comparison for max-heap (uses < instead of >)\n            if self.a[p] < self.a[i]:\n                break\n            self.a[p], self.a[i] = self.a[i], self.a[p]\n            i = p\n    def pop(self) -> int:\n        if not self.a:\n            raise IndexError(\"empty\")\n        top = self.a[0]\n        last = self.a.pop()\n        if self.a:\n            self.a[0] = last\n            self._sift_down(0)\n        return top\n    def _sift_down(self, i: int) -> None:\n        n = len(self.a)\n        while True:\n            l = 2 * i + 1\n            r = 2 * i + 2\n            m = i\n            # Bug: picks smaller child, not larger\n            if l < n and self.a[l] < self.a[m]:\n                m = l\n            if r < n and self.a[r] < self.a[m]:\n                m = r\n            if m == i:\n                return\n            self.a[i], self.a[m] = self.a[m], self.a[i]\n            i = m", "tests": "def test_maxheap_basic():\n    h = MaxHeap()\n    for x in [3, 1, 5, 2, 4]:\n        h.push(x)\n    assert [h.pop(), h.pop(), h.pop(), h.pop(), h.pop()] == [5, 4, 3, 2, 1]\n\ndef test_maxheap_interleaving():\n    h = MaxHeap()\n    h.push(10)\n    h.push(1)\n    assert h.pop() == 10\n    h.push(7)\n    h.push(9)\n    assert h.pop() == 9\n    assert h.pop() == 7\n    assert h.pop() == 1", "category": "bugfix", "topic": "heap", "tier": "oscillation", "starter_check": "fail", "approaches": ["invert_values_with_heapq", "manual_sift_correct", "sorted_list_desc"]}
{"task_id": "osc_heap_003", "prompt": "Fix this priority queue: it returns the wrong end and tie-breaking isn't FIFO.", "signature": "class PriorityQueue:", "starter_code": "import bisect\n\nclass PriorityQueue:\n    def __init__(self):\n        self.items = []  # list of (priority, value)\n        self._idx = 0\n\n    def push(self, priority: int, value):\n        # Bug: ties should be FIFO, but idx is decremented creating reverse order\n        self._idx -= 1\n        bisect.insort(self.items, (priority, self._idx, value))\n\n    def pop(self):\n        if not self.items:\n            raise IndexError(\"empty\")\n        # Bug: pops from end -> returns max priority instead of min\n        p, _, v = self.items.pop()\n        return p, v\n\n    def __len__(self):\n        return len(self.items)", "tests": "def test_pq_priority_order():\n    q = PriorityQueue()\n    q.push(2, \"b\")\n    q.push(1, \"a\")\n    q.push(3, \"c\")\n    assert q.pop() == (1, \"a\")\n    assert q.pop() == (2, \"b\")\n    assert q.pop() == (3, \"c\")\n\ndef test_pq_stable_ties():\n    q = PriorityQueue()\n    q.push(1, \"first\")\n    q.push(1, \"second\")\n    assert q.pop() == (1, \"first\")\n    assert q.pop() == (1, \"second\")", "category": "bugfix", "topic": "heap", "tier": "oscillation", "starter_check": "fail", "approaches": ["heapq_with_counter", "sorted_list_with_counter_fixed", "manual_heap_stable"]}
{"task_id": "osc_heap_004", "prompt": "Fix this min-heap: initialization and pop break ordering.", "signature": "class MinHeap:", "starter_code": "import heapq\n\nclass MinHeap:\n    def __init__(self, items=None):\n        self.data = list(items or [])\n        # Bug: heapify missing; data may not be a heap\n        self.size = len(self.data)\n\n    def push(self, x):\n        heapq.heappush(self.data, x)\n        self.size += 1\n\n    def pop(self):\n        # Bug: uses list.pop which breaks heap invariant\n        if not self.data:\n            raise IndexError(\"empty\")\n        self.size -= 1\n        return self.data.pop(0)\n\n    def peek(self):\n        if not self.data:\n            return None\n        return self.data[0]", "tests": "def test_minheap_orders():\n    h = MinHeap([5, 1, 3])\n    assert h.peek() == 1\n    assert [h.pop(), h.pop(), h.pop()] == [1, 3, 5]\n\ndef test_minheap_push_pop_mix():\n    h = MinHeap()\n    for x in [4, 2, 7, 1]:\n        h.push(x)\n    assert h.pop() == 1\n    h.push(0)\n    assert h.pop() == 0\n    assert h.pop() == 2\n\ndef test_minheap_empty():\n    h = MinHeap()\n    assert h.peek() is None", "category": "bugfix", "topic": "heap", "tier": "oscillation", "starter_check": "fail", "approaches": ["heapq_proper_heapify", "manual_sift_up_down", "sorted_list_with_bisect"]}
{"task_id": "osc_heap_005", "prompt": "Fix this max-heap: comparisons are inverted and pop order is wrong.", "signature": "class MaxHeap:", "starter_code": "class MaxHeap:\n    def __init__(self):\n        self.a = []\n    def push(self, x: int) -> None:\n        self.a.append(x)\n        self._sift_up(len(self.a) - 1)\n    def _sift_up(self, i: int) -> None:\n        while i > 0:\n            p = (i - 1) // 2\n            # Bug: wrong comparison for max-heap (uses < instead of >)\n            if self.a[p] < self.a[i]:\n                break\n            self.a[p], self.a[i] = self.a[i], self.a[p]\n            i = p\n    def pop(self) -> int:\n        if not self.a:\n            raise IndexError(\"empty\")\n        top = self.a[0]\n        last = self.a.pop()\n        if self.a:\n            self.a[0] = last\n            self._sift_down(0)\n        return top\n    def _sift_down(self, i: int) -> None:\n        n = len(self.a)\n        while True:\n            l = 2 * i + 1\n            r = 2 * i + 2\n            m = i\n            # Bug: picks smaller child, not larger\n            if l < n and self.a[l] < self.a[m]:\n                m = l\n            if r < n and self.a[r] < self.a[m]:\n                m = r\n            if m == i:\n                return\n            self.a[i], self.a[m] = self.a[m], self.a[i]\n            i = m", "tests": "def test_maxheap_basic():\n    h = MaxHeap()\n    for x in [3, 1, 5, 2, 4]:\n        h.push(x)\n    assert [h.pop(), h.pop(), h.pop(), h.pop(), h.pop()] == [5, 4, 3, 2, 1]\n\ndef test_maxheap_interleaving():\n    h = MaxHeap()\n    h.push(10)\n    h.push(1)\n    assert h.pop() == 10\n    h.push(7)\n    h.push(9)\n    assert h.pop() == 9\n    assert h.pop() == 7\n    assert h.pop() == 1", "category": "bugfix", "topic": "heap", "tier": "oscillation", "starter_check": "fail", "approaches": ["invert_values_with_heapq", "manual_sift_correct", "sorted_list_desc"]}
{"task_id": "osc_heap_006", "prompt": "Fix this priority queue: it returns the wrong end and tie-breaking isn't FIFO.", "signature": "class PriorityQueue:", "starter_code": "import bisect\n\nclass PriorityQueue:\n    def __init__(self):\n        self.items = []  # list of (priority, value)\n        self._idx = 0\n\n    def push(self, priority: int, value):\n        # Bug: ties should be FIFO, but idx is decremented creating reverse order\n        self._idx -= 1\n        bisect.insort(self.items, (priority, self._idx, value))\n\n    def pop(self):\n        if not self.items:\n            raise IndexError(\"empty\")\n        # Bug: pops from end -> returns max priority instead of min\n        p, _, v = self.items.pop()\n        return p, v\n\n    def __len__(self):\n        return len(self.items)", "tests": "def test_pq_priority_order():\n    q = PriorityQueue()\n    q.push(2, \"b\")\n    q.push(1, \"a\")\n    q.push(3, \"c\")\n    assert q.pop() == (1, \"a\")\n    assert q.pop() == (2, \"b\")\n    assert q.pop() == (3, \"c\")\n\ndef test_pq_stable_ties():\n    q = PriorityQueue()\n    q.push(1, \"first\")\n    q.push(1, \"second\")\n    assert q.pop() == (1, \"first\")\n    assert q.pop() == (1, \"second\")", "category": "bugfix", "topic": "heap", "tier": "oscillation", "starter_check": "fail", "approaches": ["heapq_with_counter", "sorted_list_with_counter_fixed", "manual_heap_stable"]}
{"task_id": "osc_heap_007", "prompt": "Fix this min-heap: initialization and pop break ordering.", "signature": "class MinHeap:", "starter_code": "import heapq\n\nclass MinHeap:\n    def __init__(self, items=None):\n        self.data = list(items or [])\n        # Bug: heapify missing; data may not be a heap\n        self.size = len(self.data)\n\n    def push(self, x):\n        heapq.heappush(self.data, x)\n        self.size += 1\n\n    def pop(self):\n        # Bug: uses list.pop which breaks heap invariant\n        if not self.data:\n            raise IndexError(\"empty\")\n        self.size -= 1\n        return self.data.pop(0)\n\n    def peek(self):\n        if not self.data:\n            return None\n        return self.data[0]", "tests": "def test_minheap_orders():\n    h = MinHeap([5, 1, 3])\n    assert h.peek() == 1\n    assert [h.pop(), h.pop(), h.pop()] == [1, 3, 5]\n\ndef test_minheap_push_pop_mix():\n    h = MinHeap()\n    for x in [4, 2, 7, 1]:\n        h.push(x)\n    assert h.pop() == 1\n    h.push(0)\n    assert h.pop() == 0\n    assert h.pop() == 2\n\ndef test_minheap_empty():\n    h = MinHeap()\n    assert h.peek() is None", "category": "bugfix", "topic": "heap", "tier": "oscillation", "starter_check": "fail", "approaches": ["heapq_proper_heapify", "manual_sift_up_down", "sorted_list_with_bisect"]}
{"task_id": "osc_heap_008", "prompt": "Fix this max-heap: comparisons are inverted and pop order is wrong.", "signature": "class MaxHeap:", "starter_code": "class MaxHeap:\n    def __init__(self):\n        self.a = []\n    def push(self, x: int) -> None:\n        self.a.append(x)\n        self._sift_up(len(self.a) - 1)\n    def _sift_up(self, i: int) -> None:\n        while i > 0:\n            p = (i - 1) // 2\n            # Bug: wrong comparison for max-heap (uses < instead of >)\n            if self.a[p] < self.a[i]:\n                break\n            self.a[p], self.a[i] = self.a[i], self.a[p]\n            i = p\n    def pop(self) -> int:\n        if not self.a:\n            raise IndexError(\"empty\")\n        top = self.a[0]\n        last = self.a.pop()\n        if self.a:\n            self.a[0] = last\n            self._sift_down(0)\n        return top\n    def _sift_down(self, i: int) -> None:\n        n = len(self.a)\n        while True:\n            l = 2 * i + 1\n            r = 2 * i + 2\n            m = i\n            # Bug: picks smaller child, not larger\n            if l < n and self.a[l] < self.a[m]:\n                m = l\n            if r < n and self.a[r] < self.a[m]:\n                m = r\n            if m == i:\n                return\n            self.a[i], self.a[m] = self.a[m], self.a[i]\n            i = m", "tests": "def test_maxheap_basic():\n    h = MaxHeap()\n    for x in [3, 1, 5, 2, 4]:\n        h.push(x)\n    assert [h.pop(), h.pop(), h.pop(), h.pop(), h.pop()] == [5, 4, 3, 2, 1]\n\ndef test_maxheap_interleaving():\n    h = MaxHeap()\n    h.push(10)\n    h.push(1)\n    assert h.pop() == 10\n    h.push(7)\n    h.push(9)\n    assert h.pop() == 9\n    assert h.pop() == 7\n    assert h.pop() == 1", "category": "bugfix", "topic": "heap", "tier": "oscillation", "starter_check": "fail", "approaches": ["invert_values_with_heapq", "manual_sift_correct", "sorted_list_desc"]}
{"task_id": "osc_heap_009", "prompt": "Fix this priority queue: it returns the wrong end and tie-breaking isn't FIFO.", "signature": "class PriorityQueue:", "starter_code": "import bisect\n\nclass PriorityQueue:\n    def __init__(self):\n        self.items = []  # list of (priority, value)\n        self._idx = 0\n\n    def push(self, priority: int, value):\n        # Bug: ties should be FIFO, but idx is decremented creating reverse order\n        self._idx -= 1\n        bisect.insort(self.items, (priority, self._idx, value))\n\n    def pop(self):\n        if not self.items:\n            raise IndexError(\"empty\")\n        # Bug: pops from end -> returns max priority instead of min\n        p, _, v = self.items.pop()\n        return p, v\n\n    def __len__(self):\n        return len(self.items)", "tests": "def test_pq_priority_order():\n    q = PriorityQueue()\n    q.push(2, \"b\")\n    q.push(1, \"a\")\n    q.push(3, \"c\")\n    assert q.pop() == (1, \"a\")\n    assert q.pop() == (2, \"b\")\n    assert q.pop() == (3, \"c\")\n\ndef test_pq_stable_ties():\n    q = PriorityQueue()\n    q.push(1, \"first\")\n    q.push(1, \"second\")\n    assert q.pop() == (1, \"first\")\n    assert q.pop() == (1, \"second\")", "category": "bugfix", "topic": "heap", "tier": "oscillation", "starter_check": "fail", "approaches": ["heapq_with_counter", "sorted_list_with_counter_fixed", "manual_heap_stable"]}
{"task_id": "osc_disjoint_set_001", "prompt": "Fix this union-find: find returns wrong roots and union-by-rank is backwards.", "signature": "class DisjointSet:", "starter_code": "class DisjointSet:\n    def __init__(self, n: int):\n        self.parent = list(range(n))\n        self.rank = [0] * n\n\n    def find(self, x: int) -> int:\n        # Bug: path compression half-implemented; returns parent not root\n        while self.parent[x] != x:\n            x = self.parent[x]\n        return self.parent[x]\n\n    def union(self, a: int, b: int) -> bool:\n        ra = self.find(a)\n        rb = self.find(b)\n        if ra == rb:\n            return False\n        # Bug: union by rank reversed\n        if self.rank[ra] > self.rank[rb]:\n            self.parent[ra] = rb\n        elif self.rank[ra] < self.rank[rb]:\n            self.parent[rb] = ra\n        else:\n            self.parent[rb] = ra\n            self.rank[rb] += 1\n        return True\n\n    def connected(self, a: int, b: int) -> bool:\n        return self.find(a) == self.find(b)", "tests": "def test_union_find_connectivity():\n    d = DisjointSet(6)\n    d.union(0, 1)\n    d.union(1, 2)\n    assert d.connected(0, 2) is True\n    assert d.connected(0, 3) is False\n\ndef test_union_find_idempotent():\n    d = DisjointSet(3)\n    assert d.union(0, 1) is True\n    assert d.union(0, 1) is False\n    assert d.connected(0, 1) is True\n\ndef test_union_find_chain():\n    d = DisjointSet(5)\n    for a, b in [(0,1),(1,2),(2,3),(3,4)]:\n        d.union(a,b)\n    assert d.connected(0,4) is True", "category": "bugfix", "topic": "disjoint_set", "tier": "oscillation", "starter_check": "fail", "approaches": ["path_compression_union_by_rank", "simple_union_no_rank", "compression_recursive"]}
{"task_id": "osc_disjoint_set_002", "prompt": "Fix this dynamic union-find: union/find crash on unseen items and sizes go stale.", "signature": "class DisjointSet:", "starter_code": "class DisjointSet:\n    def __init__(self):\n        self.parent = {}\n        self.size = {}\n\n    def add(self, x):\n        if x in self.parent:\n            return\n        self.parent[x] = x\n        self.size[x] = 1\n\n    def find(self, x):\n        # Bug: missing add on unseen elements leads to KeyError\n        if self.parent[x] != x:\n            self.parent[x] = self.find(self.parent[x])\n        return self.parent[x]\n\n    def union(self, a, b):\n        # Bug: unions without ensuring nodes exist\n        ra = self.find(a)\n        rb = self.find(b)\n        if ra == rb:\n            return\n        # Bug: union-by-size forgets to update size on new root\n        if self.size[ra] < self.size[rb]:\n            self.parent[ra] = rb\n        else:\n            self.parent[rb] = ra\n\n    def groups(self):\n        g = {}\n        for x in self.parent:\n            r = self.find(x)\n            g.setdefault(r, []).append(x)\n        return list(g.values())", "tests": "def test_dynamic_union_find_adds():\n    d = DisjointSet()\n    d.union(\"a\", \"b\")\n    d.union(\"b\", \"c\")\n    assert sorted([sorted(g) for g in d.groups()]) == [[\"a\",\"b\",\"c\"]]\n\ndef test_dynamic_union_find_multiple_sets():\n    d = DisjointSet()\n    d.union(1, 2)\n    d.union(3, 4)\n    d.union(2, 3)\n    groups = [set(g) for g in d.groups()]\n    assert any(g == {1,2,3,4} for g in groups)", "category": "bugfix", "topic": "disjoint_set", "tier": "oscillation", "starter_check": "fail", "approaches": ["auto_add_in_find", "explicit_add_required", "dict_parent_with_size_update"]}
{"task_id": "osc_disjoint_set_003", "prompt": "Fix this union-find: find is broken (infinite recursion) and shouldn't crash on roots.", "signature": "class DisjointSet:", "starter_code": "class DisjointSet:\n    def __init__(self, n: int):\n        self.parent = list(range(n))\n\n    def find(self, x: int) -> int:\n        # Bug: recursion base incorrect; may infinite loop when parent[x]==x\n        if self.parent[x] == x:\n            return self.find(self.parent[x])\n        return self.find(self.parent[x])\n\n    def union(self, a: int, b: int) -> None:\n        ra = self._root(a)\n        rb = self._root(b)\n        self.parent[ra] = rb\n\n    def _root(self, x: int) -> int:\n        while self.parent[x] != x:\n            x = self.parent[x]\n        return x\n\n    def connected(self, a: int, b: int) -> bool:\n        return self._root(a) == self._root(b)", "tests": "def test_find_returns_root():\n    d = DisjointSet(4)\n    d.union(0, 1)\n    d.union(1, 2)\n    assert d.connected(0, 2) is True\n    assert d.connected(0, 3) is False\n\ndef test_find_self_root():\n    d = DisjointSet(2)\n    assert d.connected(0, 0) is True", "category": "bugfix", "topic": "disjoint_set", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_recursive_find", "drop_recursive_use_iterative", "add_path_compression"]}
{"task_id": "osc_disjoint_set_004", "prompt": "Fix this union-find: find returns wrong roots and union-by-rank is backwards.", "signature": "class DisjointSet:", "starter_code": "class DisjointSet:\n    def __init__(self, n: int):\n        self.parent = list(range(n))\n        self.rank = [0] * n\n\n    def find(self, x: int) -> int:\n        # Bug: path compression half-implemented; returns parent not root\n        while self.parent[x] != x:\n            x = self.parent[x]\n        return self.parent[x]\n\n    def union(self, a: int, b: int) -> bool:\n        ra = self.find(a)\n        rb = self.find(b)\n        if ra == rb:\n            return False\n        # Bug: union by rank reversed\n        if self.rank[ra] > self.rank[rb]:\n            self.parent[ra] = rb\n        elif self.rank[ra] < self.rank[rb]:\n            self.parent[rb] = ra\n        else:\n            self.parent[rb] = ra\n            self.rank[rb] += 1\n        return True\n\n    def connected(self, a: int, b: int) -> bool:\n        return self.find(a) == self.find(b)", "tests": "def test_union_find_connectivity():\n    d = DisjointSet(6)\n    d.union(0, 1)\n    d.union(1, 2)\n    assert d.connected(0, 2) is True\n    assert d.connected(0, 3) is False\n\ndef test_union_find_idempotent():\n    d = DisjointSet(3)\n    assert d.union(0, 1) is True\n    assert d.union(0, 1) is False\n    assert d.connected(0, 1) is True\n\ndef test_union_find_chain():\n    d = DisjointSet(5)\n    for a, b in [(0,1),(1,2),(2,3),(3,4)]:\n        d.union(a,b)\n    assert d.connected(0,4) is True", "category": "bugfix", "topic": "disjoint_set", "tier": "oscillation", "starter_check": "fail", "approaches": ["path_compression_union_by_rank", "simple_union_no_rank", "compression_recursive"]}
{"task_id": "osc_disjoint_set_005", "prompt": "Fix this dynamic union-find: union/find crash on unseen items and sizes go stale.", "signature": "class DisjointSet:", "starter_code": "class DisjointSet:\n    def __init__(self):\n        self.parent = {}\n        self.size = {}\n\n    def add(self, x):\n        if x in self.parent:\n            return\n        self.parent[x] = x\n        self.size[x] = 1\n\n    def find(self, x):\n        # Bug: missing add on unseen elements leads to KeyError\n        if self.parent[x] != x:\n            self.parent[x] = self.find(self.parent[x])\n        return self.parent[x]\n\n    def union(self, a, b):\n        # Bug: unions without ensuring nodes exist\n        ra = self.find(a)\n        rb = self.find(b)\n        if ra == rb:\n            return\n        # Bug: union-by-size forgets to update size on new root\n        if self.size[ra] < self.size[rb]:\n            self.parent[ra] = rb\n        else:\n            self.parent[rb] = ra\n\n    def groups(self):\n        g = {}\n        for x in self.parent:\n            r = self.find(x)\n            g.setdefault(r, []).append(x)\n        return list(g.values())", "tests": "def test_dynamic_union_find_adds():\n    d = DisjointSet()\n    d.union(\"a\", \"b\")\n    d.union(\"b\", \"c\")\n    assert sorted([sorted(g) for g in d.groups()]) == [[\"a\",\"b\",\"c\"]]\n\ndef test_dynamic_union_find_multiple_sets():\n    d = DisjointSet()\n    d.union(1, 2)\n    d.union(3, 4)\n    d.union(2, 3)\n    groups = [set(g) for g in d.groups()]\n    assert any(g == {1,2,3,4} for g in groups)", "category": "bugfix", "topic": "disjoint_set", "tier": "oscillation", "starter_check": "fail", "approaches": ["auto_add_in_find", "explicit_add_required", "dict_parent_with_size_update"]}
{"task_id": "osc_disjoint_set_006", "prompt": "Fix this union-find: find is broken (infinite recursion) and shouldn't crash on roots.", "signature": "class DisjointSet:", "starter_code": "class DisjointSet:\n    def __init__(self, n: int):\n        self.parent = list(range(n))\n\n    def find(self, x: int) -> int:\n        # Bug: recursion base incorrect; may infinite loop when parent[x]==x\n        if self.parent[x] == x:\n            return self.find(self.parent[x])\n        return self.find(self.parent[x])\n\n    def union(self, a: int, b: int) -> None:\n        ra = self._root(a)\n        rb = self._root(b)\n        self.parent[ra] = rb\n\n    def _root(self, x: int) -> int:\n        while self.parent[x] != x:\n            x = self.parent[x]\n        return x\n\n    def connected(self, a: int, b: int) -> bool:\n        return self._root(a) == self._root(b)", "tests": "def test_find_returns_root():\n    d = DisjointSet(4)\n    d.union(0, 1)\n    d.union(1, 2)\n    assert d.connected(0, 2) is True\n    assert d.connected(0, 3) is False\n\ndef test_find_self_root():\n    d = DisjointSet(2)\n    assert d.connected(0, 0) is True", "category": "bugfix", "topic": "disjoint_set", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_recursive_find", "drop_recursive_use_iterative", "add_path_compression"]}
{"task_id": "osc_disjoint_set_007", "prompt": "Fix this union-find: find returns wrong roots and union-by-rank is backwards.", "signature": "class DisjointSet:", "starter_code": "class DisjointSet:\n    def __init__(self, n: int):\n        self.parent = list(range(n))\n        self.rank = [0] * n\n\n    def find(self, x: int) -> int:\n        # Bug: path compression half-implemented; returns parent not root\n        while self.parent[x] != x:\n            x = self.parent[x]\n        return self.parent[x]\n\n    def union(self, a: int, b: int) -> bool:\n        ra = self.find(a)\n        rb = self.find(b)\n        if ra == rb:\n            return False\n        # Bug: union by rank reversed\n        if self.rank[ra] > self.rank[rb]:\n            self.parent[ra] = rb\n        elif self.rank[ra] < self.rank[rb]:\n            self.parent[rb] = ra\n        else:\n            self.parent[rb] = ra\n            self.rank[rb] += 1\n        return True\n\n    def connected(self, a: int, b: int) -> bool:\n        return self.find(a) == self.find(b)", "tests": "def test_union_find_connectivity():\n    d = DisjointSet(6)\n    d.union(0, 1)\n    d.union(1, 2)\n    assert d.connected(0, 2) is True\n    assert d.connected(0, 3) is False\n\ndef test_union_find_idempotent():\n    d = DisjointSet(3)\n    assert d.union(0, 1) is True\n    assert d.union(0, 1) is False\n    assert d.connected(0, 1) is True\n\ndef test_union_find_chain():\n    d = DisjointSet(5)\n    for a, b in [(0,1),(1,2),(2,3),(3,4)]:\n        d.union(a,b)\n    assert d.connected(0,4) is True", "category": "bugfix", "topic": "disjoint_set", "tier": "oscillation", "starter_check": "fail", "approaches": ["path_compression_union_by_rank", "simple_union_no_rank", "compression_recursive"]}
{"task_id": "osc_disjoint_set_008", "prompt": "Fix this dynamic union-find: union/find crash on unseen items and sizes go stale.", "signature": "class DisjointSet:", "starter_code": "class DisjointSet:\n    def __init__(self):\n        self.parent = {}\n        self.size = {}\n\n    def add(self, x):\n        if x in self.parent:\n            return\n        self.parent[x] = x\n        self.size[x] = 1\n\n    def find(self, x):\n        # Bug: missing add on unseen elements leads to KeyError\n        if self.parent[x] != x:\n            self.parent[x] = self.find(self.parent[x])\n        return self.parent[x]\n\n    def union(self, a, b):\n        # Bug: unions without ensuring nodes exist\n        ra = self.find(a)\n        rb = self.find(b)\n        if ra == rb:\n            return\n        # Bug: union-by-size forgets to update size on new root\n        if self.size[ra] < self.size[rb]:\n            self.parent[ra] = rb\n        else:\n            self.parent[rb] = ra\n\n    def groups(self):\n        g = {}\n        for x in self.parent:\n            r = self.find(x)\n            g.setdefault(r, []).append(x)\n        return list(g.values())", "tests": "def test_dynamic_union_find_adds():\n    d = DisjointSet()\n    d.union(\"a\", \"b\")\n    d.union(\"b\", \"c\")\n    assert sorted([sorted(g) for g in d.groups()]) == [[\"a\",\"b\",\"c\"]]\n\ndef test_dynamic_union_find_multiple_sets():\n    d = DisjointSet()\n    d.union(1, 2)\n    d.union(3, 4)\n    d.union(2, 3)\n    groups = [set(g) for g in d.groups()]\n    assert any(g == {1,2,3,4} for g in groups)", "category": "bugfix", "topic": "disjoint_set", "tier": "oscillation", "starter_check": "fail", "approaches": ["auto_add_in_find", "explicit_add_required", "dict_parent_with_size_update"]}
{"task_id": "osc_disjoint_set_009", "prompt": "Fix this union-find: find is broken (infinite recursion) and shouldn't crash on roots.", "signature": "class DisjointSet:", "starter_code": "class DisjointSet:\n    def __init__(self, n: int):\n        self.parent = list(range(n))\n\n    def find(self, x: int) -> int:\n        # Bug: recursion base incorrect; may infinite loop when parent[x]==x\n        if self.parent[x] == x:\n            return self.find(self.parent[x])\n        return self.find(self.parent[x])\n\n    def union(self, a: int, b: int) -> None:\n        ra = self._root(a)\n        rb = self._root(b)\n        self.parent[ra] = rb\n\n    def _root(self, x: int) -> int:\n        while self.parent[x] != x:\n            x = self.parent[x]\n        return x\n\n    def connected(self, a: int, b: int) -> bool:\n        return self._root(a) == self._root(b)", "tests": "def test_find_returns_root():\n    d = DisjointSet(4)\n    d.union(0, 1)\n    d.union(1, 2)\n    assert d.connected(0, 2) is True\n    assert d.connected(0, 3) is False\n\ndef test_find_self_root():\n    d = DisjointSet(2)\n    assert d.connected(0, 0) is True", "category": "bugfix", "topic": "disjoint_set", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_recursive_find", "drop_recursive_use_iterative", "add_path_compression"]}
{"task_id": "osc_ring_buffer_001", "prompt": "Fix this ring buffer: mixed list/deque state gets out of sync and evictions are wrong.", "signature": "class RingBuffer:", "starter_code": "from collections import deque\n\nclass RingBuffer:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.buf = []            # list approach\n        self.q = deque()         # deque approach\n        self.head = 0\n\n    def push(self, x):\n        # Bug: writes to both structures but evicts from only one\n        if len(self.buf) >= self.capacity:\n            self.buf.pop(0)\n        self.buf.append(x)\n        self.q.append(x)\n        if len(self.q) > self.capacity:\n            # Bug: evicts from wrong end\n            self.q.pop()\n\n    def pop(self):\n        if not self.buf:\n            raise IndexError(\"empty\")\n        # Bug: pop from list but from left of deque -> desync\n        v = self.buf.pop(0)\n        self.q.popleft()\n        return v\n\n    def to_list(self):\n        return list(self.buf)", "tests": "def test_ringbuffer_order_and_capacity():\n    r = RingBuffer(3)\n    for x in [1,2,3,4]:\n        r.push(x)\n    assert r.to_list() == [2,3,4]\n\ndef test_ringbuffer_pop_then_push():\n    r = RingBuffer(2)\n    r.push(\"a\")\n    r.push(\"b\")\n    assert r.pop() == \"a\"\n    r.push(\"c\")\n    assert r.to_list() == [\"b\",\"c\"]", "category": "bugfix", "topic": "ring_buffer", "tier": "oscillation", "starter_check": "fail", "approaches": ["deque_only", "modulo_index_array", "list_with_head_index"]}
{"task_id": "osc_ring_buffer_002", "prompt": "Fix this ring buffer: push/pop indexing and size tracking are inconsistent.", "signature": "class RingBuffer:", "starter_code": "class RingBuffer:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.data = [None] * capacity\n        self.head = 0\n        self.size = 0\n\n    def push(self, x):\n        # Bug: head is advanced before write (off-by-one)\n        self.head = (self.head + 1) % self.capacity\n        self.data[self.head] = x\n        if self.size < self.capacity:\n            self.size += 1\n\n    def pop(self):\n        if self.size == 0:\n            raise IndexError(\"empty\")\n        tail = (self.head - self.size) % self.capacity\n        v = self.data[tail]\n        # Bug: doesn't clear slot; and size updated wrong direction\n        self.size += 1\n        return v\n\n    def to_list(self):\n        out = []\n        for i in range(self.size):\n            idx = (self.head - self.size + 1 + i) % self.capacity\n            out.append(self.data[idx])\n        return out", "tests": "def test_ringbuffer_basic():\n    r = RingBuffer(3)\n    r.push(1); r.push(2); r.push(3)\n    assert r.to_list() == [1,2,3]\n    assert r.pop() == 1\n    assert r.to_list() == [2,3]\n\ndef test_ringbuffer_wrap():\n    r = RingBuffer(2)\n    r.push(\"x\"); r.push(\"y\"); r.push(\"z\")\n    assert r.to_list() == [\"y\",\"z\"]", "category": "bugfix", "topic": "ring_buffer", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_modulo_array", "deque_based", "list_rotate"]}
{"task_id": "osc_ring_buffer_003", "prompt": "Fix this ring buffer: overwrites don't advance and pop mutates the backing list incorrectly.", "signature": "class RingBuffer:", "starter_code": "class RingBuffer:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.items = []\n        self.start = 0\n\n    def push(self, x):\n        if len(self.items) < self.capacity:\n            self.items.append(x)\n        else:\n            # Bug: overwrites but doesn't advance start (stuck pointer)\n            self.items[self.start] = x\n\n    def pop(self):\n        if not self.items:\n            raise IndexError(\"empty\")\n        v = self.items[self.start]\n        # Bug: deletes from list causing O(n) shifts and breaks ring semantics\n        self.items.pop(self.start)\n        if self.items:\n            self.start %= len(self.items)\n        return v\n\n    def to_list(self):\n        if not self.items:\n            return []\n        return self.items[self.start:] + self.items[:self.start]", "tests": "def test_ringbuffer_overwrite_oldest():\n    r = RingBuffer(3)\n    for x in [1,2,3,4]:\n        r.push(x)\n    assert r.to_list() == [2,3,4]\n\ndef test_ringbuffer_pop_sequence():\n    r = RingBuffer(2)\n    r.push(\"a\"); r.push(\"b\"); r.push(\"c\")\n    assert r.pop() == \"b\"\n    assert r.pop() == \"c\"", "category": "bugfix", "topic": "ring_buffer", "tier": "oscillation", "starter_check": "fail", "approaches": ["advance_start_on_overwrite", "use_deque_maxlen", "head_index_no_pop"]}
{"task_id": "osc_ring_buffer_004", "prompt": "Fix this ring buffer: mixed list/deque state gets out of sync and evictions are wrong.", "signature": "class RingBuffer:", "starter_code": "from collections import deque\n\nclass RingBuffer:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.buf = []            # list approach\n        self.q = deque()         # deque approach\n        self.head = 0\n\n    def push(self, x):\n        # Bug: writes to both structures but evicts from only one\n        if len(self.buf) >= self.capacity:\n            self.buf.pop(0)\n        self.buf.append(x)\n        self.q.append(x)\n        if len(self.q) > self.capacity:\n            # Bug: evicts from wrong end\n            self.q.pop()\n\n    def pop(self):\n        if not self.buf:\n            raise IndexError(\"empty\")\n        # Bug: pop from list but from left of deque -> desync\n        v = self.buf.pop(0)\n        self.q.popleft()\n        return v\n\n    def to_list(self):\n        return list(self.buf)", "tests": "def test_ringbuffer_order_and_capacity():\n    r = RingBuffer(3)\n    for x in [1,2,3,4]:\n        r.push(x)\n    assert r.to_list() == [2,3,4]\n\ndef test_ringbuffer_pop_then_push():\n    r = RingBuffer(2)\n    r.push(\"a\")\n    r.push(\"b\")\n    assert r.pop() == \"a\"\n    r.push(\"c\")\n    assert r.to_list() == [\"b\",\"c\"]", "category": "bugfix", "topic": "ring_buffer", "tier": "oscillation", "starter_check": "fail", "approaches": ["deque_only", "modulo_index_array", "list_with_head_index"]}
{"task_id": "osc_ring_buffer_005", "prompt": "Fix this ring buffer: push/pop indexing and size tracking are inconsistent.", "signature": "class RingBuffer:", "starter_code": "class RingBuffer:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.data = [None] * capacity\n        self.head = 0\n        self.size = 0\n\n    def push(self, x):\n        # Bug: head is advanced before write (off-by-one)\n        self.head = (self.head + 1) % self.capacity\n        self.data[self.head] = x\n        if self.size < self.capacity:\n            self.size += 1\n\n    def pop(self):\n        if self.size == 0:\n            raise IndexError(\"empty\")\n        tail = (self.head - self.size) % self.capacity\n        v = self.data[tail]\n        # Bug: doesn't clear slot; and size updated wrong direction\n        self.size += 1\n        return v\n\n    def to_list(self):\n        out = []\n        for i in range(self.size):\n            idx = (self.head - self.size + 1 + i) % self.capacity\n            out.append(self.data[idx])\n        return out", "tests": "def test_ringbuffer_basic():\n    r = RingBuffer(3)\n    r.push(1); r.push(2); r.push(3)\n    assert r.to_list() == [1,2,3]\n    assert r.pop() == 1\n    assert r.to_list() == [2,3]\n\ndef test_ringbuffer_wrap():\n    r = RingBuffer(2)\n    r.push(\"x\"); r.push(\"y\"); r.push(\"z\")\n    assert r.to_list() == [\"y\",\"z\"]", "category": "bugfix", "topic": "ring_buffer", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_modulo_array", "deque_based", "list_rotate"]}
{"task_id": "osc_ring_buffer_006", "prompt": "Fix this ring buffer: overwrites don't advance and pop mutates the backing list incorrectly.", "signature": "class RingBuffer:", "starter_code": "class RingBuffer:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.items = []\n        self.start = 0\n\n    def push(self, x):\n        if len(self.items) < self.capacity:\n            self.items.append(x)\n        else:\n            # Bug: overwrites but doesn't advance start (stuck pointer)\n            self.items[self.start] = x\n\n    def pop(self):\n        if not self.items:\n            raise IndexError(\"empty\")\n        v = self.items[self.start]\n        # Bug: deletes from list causing O(n) shifts and breaks ring semantics\n        self.items.pop(self.start)\n        if self.items:\n            self.start %= len(self.items)\n        return v\n\n    def to_list(self):\n        if not self.items:\n            return []\n        return self.items[self.start:] + self.items[:self.start]", "tests": "def test_ringbuffer_overwrite_oldest():\n    r = RingBuffer(3)\n    for x in [1,2,3,4]:\n        r.push(x)\n    assert r.to_list() == [2,3,4]\n\ndef test_ringbuffer_pop_sequence():\n    r = RingBuffer(2)\n    r.push(\"a\"); r.push(\"b\"); r.push(\"c\")\n    assert r.pop() == \"b\"\n    assert r.pop() == \"c\"", "category": "bugfix", "topic": "ring_buffer", "tier": "oscillation", "starter_check": "fail", "approaches": ["advance_start_on_overwrite", "use_deque_maxlen", "head_index_no_pop"]}
{"task_id": "osc_ring_buffer_007", "prompt": "Fix this ring buffer: mixed list/deque state gets out of sync and evictions are wrong.", "signature": "class RingBuffer:", "starter_code": "from collections import deque\n\nclass RingBuffer:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.buf = []            # list approach\n        self.q = deque()         # deque approach\n        self.head = 0\n\n    def push(self, x):\n        # Bug: writes to both structures but evicts from only one\n        if len(self.buf) >= self.capacity:\n            self.buf.pop(0)\n        self.buf.append(x)\n        self.q.append(x)\n        if len(self.q) > self.capacity:\n            # Bug: evicts from wrong end\n            self.q.pop()\n\n    def pop(self):\n        if not self.buf:\n            raise IndexError(\"empty\")\n        # Bug: pop from list but from left of deque -> desync\n        v = self.buf.pop(0)\n        self.q.popleft()\n        return v\n\n    def to_list(self):\n        return list(self.buf)", "tests": "def test_ringbuffer_order_and_capacity():\n    r = RingBuffer(3)\n    for x in [1,2,3,4]:\n        r.push(x)\n    assert r.to_list() == [2,3,4]\n\ndef test_ringbuffer_pop_then_push():\n    r = RingBuffer(2)\n    r.push(\"a\")\n    r.push(\"b\")\n    assert r.pop() == \"a\"\n    r.push(\"c\")\n    assert r.to_list() == [\"b\",\"c\"]", "category": "bugfix", "topic": "ring_buffer", "tier": "oscillation", "starter_check": "fail", "approaches": ["deque_only", "modulo_index_array", "list_with_head_index"]}
{"task_id": "osc_ring_buffer_008", "prompt": "Fix this ring buffer: push/pop indexing and size tracking are inconsistent.", "signature": "class RingBuffer:", "starter_code": "class RingBuffer:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.data = [None] * capacity\n        self.head = 0\n        self.size = 0\n\n    def push(self, x):\n        # Bug: head is advanced before write (off-by-one)\n        self.head = (self.head + 1) % self.capacity\n        self.data[self.head] = x\n        if self.size < self.capacity:\n            self.size += 1\n\n    def pop(self):\n        if self.size == 0:\n            raise IndexError(\"empty\")\n        tail = (self.head - self.size) % self.capacity\n        v = self.data[tail]\n        # Bug: doesn't clear slot; and size updated wrong direction\n        self.size += 1\n        return v\n\n    def to_list(self):\n        out = []\n        for i in range(self.size):\n            idx = (self.head - self.size + 1 + i) % self.capacity\n            out.append(self.data[idx])\n        return out", "tests": "def test_ringbuffer_basic():\n    r = RingBuffer(3)\n    r.push(1); r.push(2); r.push(3)\n    assert r.to_list() == [1,2,3]\n    assert r.pop() == 1\n    assert r.to_list() == [2,3]\n\ndef test_ringbuffer_wrap():\n    r = RingBuffer(2)\n    r.push(\"x\"); r.push(\"y\"); r.push(\"z\")\n    assert r.to_list() == [\"y\",\"z\"]", "category": "bugfix", "topic": "ring_buffer", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_modulo_array", "deque_based", "list_rotate"]}
{"task_id": "osc_ring_buffer_009", "prompt": "Fix this ring buffer: overwrites don't advance and pop mutates the backing list incorrectly.", "signature": "class RingBuffer:", "starter_code": "class RingBuffer:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.items = []\n        self.start = 0\n\n    def push(self, x):\n        if len(self.items) < self.capacity:\n            self.items.append(x)\n        else:\n            # Bug: overwrites but doesn't advance start (stuck pointer)\n            self.items[self.start] = x\n\n    def pop(self):\n        if not self.items:\n            raise IndexError(\"empty\")\n        v = self.items[self.start]\n        # Bug: deletes from list causing O(n) shifts and breaks ring semantics\n        self.items.pop(self.start)\n        if self.items:\n            self.start %= len(self.items)\n        return v\n\n    def to_list(self):\n        if not self.items:\n            return []\n        return self.items[self.start:] + self.items[:self.start]", "tests": "def test_ringbuffer_overwrite_oldest():\n    r = RingBuffer(3)\n    for x in [1,2,3,4]:\n        r.push(x)\n    assert r.to_list() == [2,3,4]\n\ndef test_ringbuffer_pop_sequence():\n    r = RingBuffer(2)\n    r.push(\"a\"); r.push(\"b\"); r.push(\"c\")\n    assert r.pop() == \"b\"\n    assert r.pop() == \"c\"", "category": "bugfix", "topic": "ring_buffer", "tier": "oscillation", "starter_check": "fail", "approaches": ["advance_start_on_overwrite", "use_deque_maxlen", "head_index_no_pop"]}
{"task_id": "osc_skip_list_001", "prompt": "Fix this skip list: contains checks the wrong level and level maintenance is inconsistent.", "signature": "class SkipList:", "starter_code": "class SkipList:\n    def __init__(self):\n        self.levels = [[]]  # list of sorted lists per level (top is last)\n\n    def add(self, x: int) -> None:\n        # Bug: inserts into all levels unsorted, pretending random promotion\n        for lvl in self.levels:\n            lvl.append(x)\n        # Bug: promotes every time -> unbounded levels\n        if len(self.levels[-1]) > 2:\n            self.levels.append([])\n\n    def contains(self, x: int) -> bool:\n        # Bug: searches only top level which may be empty\n        top = self.levels[-1]\n        return x in top\n\n    def to_sorted(self):\n        # bottom level is levels[0]\n        return sorted(self.levels[0])", "tests": "def test_skiplist_contains_after_add():\n    s = SkipList()\n    for x in [5, 1, 3]:\n        s.add(x)\n    assert s.contains(1) is True\n    assert s.contains(2) is False\n\ndef test_skiplist_sorted_view():\n    s = SkipList()\n    for x in [10, 7, 8]:\n        s.add(x)\n    assert s.to_sorted() == [7,8,10]", "category": "bugfix", "topic": "skip_list", "tier": "oscillation", "starter_check": "fail", "approaches": ["proper_level_search", "single_sorted_list_baseline", "binary_search_per_level"]}
{"task_id": "osc_skip_list_002", "prompt": "Fix this skip list: contains misses unsampled items and remove should be safe.", "signature": "class SkipList:", "starter_code": "import bisect\n\nclass SkipList:\n    def __init__(self):\n        self.bottom = []      # sorted\n        self.top = []         # sampled subset\n        self.step = 2\n\n    def add(self, x: int) -> None:\n        bisect.insort(self.bottom, x)\n        # Bug: sampling condition reversed; should add every k-th\n        if len(self.bottom) % self.step != 0:\n            bisect.insort(self.top, x)\n\n    def remove(self, x: int) -> bool:\n        # Bug: uses list.remove without guarding; may raise\n        self.bottom.remove(x)\n        if x in self.top:\n            self.top.remove(x)\n        return True\n\n    def contains(self, x: int) -> bool:\n        # Bug: checks only top; misses elements not sampled\n        return x in self.top", "tests": "def test_skiplist_contains_all_elements():\n    s = SkipList()\n    for x in [1,2,3,4,5]:\n        s.add(x)\n    for x in [1,3,5]:\n        assert s.contains(x) is True\n\ndef test_skiplist_remove_missing_returns_false():\n    s = SkipList()\n    s.add(1)\n    assert s.remove(2) is False\n    assert s.contains(1) is True\n\ndef test_skiplist_remove_existing():\n    s = SkipList()\n    for x in [2,1,3]:\n        s.add(x)\n    assert s.remove(2) is True\n    assert s.contains(2) is False", "category": "bugfix", "topic": "skip_list", "tier": "oscillation", "starter_check": "fail", "approaches": ["search_bottom_then_top", "rebuild_top_on_mutation", "single_structure_with_bisect"]}
{"task_id": "osc_skip_list_003", "prompt": "Fix this skip list: contains ignores the base level and add breaks ordering.", "signature": "class SkipList:", "starter_code": "class SkipList:\n    def __init__(self):\n        self.data = {0: []}  # level -> sorted list\n\n    def add(self, x: int) -> None:\n        # Bug: uses append instead of sorted insert\n        self.data[0].append(x)\n        # Bug: promotes duplicates across levels\n        if len(self.data[0]) % 3 == 0:\n            self.data.setdefault(1, []).append(x)\n\n    def contains(self, x: int) -> bool:\n        # Bug: assumes if not in level 1 then absent, skipping level 0\n        if 1 in self.data and x in self.data[1]:\n            return True\n        return False\n\n    def min(self):\n        if not self.data[0]:\n            return None\n        return min(self.data[0])", "tests": "def test_skiplist_contains_uses_base_level():\n    s = SkipList()\n    s.add(4); s.add(1); s.add(3)\n    assert s.contains(1) is True\n    assert s.contains(2) is False\n\ndef test_skiplist_min():\n    s = SkipList()\n    assert s.min() is None\n    for x in [9, 2, 5]:\n        s.add(x)\n    assert s.min() == 2", "category": "bugfix", "topic": "skip_list", "tier": "oscillation", "starter_check": "fail", "approaches": ["binary_search_base_level", "always_check_level0", "convert_to_linked_levels"]}
{"task_id": "osc_skip_list_004", "prompt": "Fix this skip list: contains checks the wrong level and level maintenance is inconsistent.", "signature": "class SkipList:", "starter_code": "class SkipList:\n    def __init__(self):\n        self.levels = [[]]  # list of sorted lists per level (top is last)\n\n    def add(self, x: int) -> None:\n        # Bug: inserts into all levels unsorted, pretending random promotion\n        for lvl in self.levels:\n            lvl.append(x)\n        # Bug: promotes every time -> unbounded levels\n        if len(self.levels[-1]) > 2:\n            self.levels.append([])\n\n    def contains(self, x: int) -> bool:\n        # Bug: searches only top level which may be empty\n        top = self.levels[-1]\n        return x in top\n\n    def to_sorted(self):\n        # bottom level is levels[0]\n        return sorted(self.levels[0])", "tests": "def test_skiplist_contains_after_add():\n    s = SkipList()\n    for x in [5, 1, 3]:\n        s.add(x)\n    assert s.contains(1) is True\n    assert s.contains(2) is False\n\ndef test_skiplist_sorted_view():\n    s = SkipList()\n    for x in [10, 7, 8]:\n        s.add(x)\n    assert s.to_sorted() == [7,8,10]", "category": "bugfix", "topic": "skip_list", "tier": "oscillation", "starter_check": "fail", "approaches": ["proper_level_search", "single_sorted_list_baseline", "binary_search_per_level"]}
{"task_id": "osc_skip_list_005", "prompt": "Fix this skip list: contains misses unsampled items and remove should be safe.", "signature": "class SkipList:", "starter_code": "import bisect\n\nclass SkipList:\n    def __init__(self):\n        self.bottom = []      # sorted\n        self.top = []         # sampled subset\n        self.step = 2\n\n    def add(self, x: int) -> None:\n        bisect.insort(self.bottom, x)\n        # Bug: sampling condition reversed; should add every k-th\n        if len(self.bottom) % self.step != 0:\n            bisect.insort(self.top, x)\n\n    def remove(self, x: int) -> bool:\n        # Bug: uses list.remove without guarding; may raise\n        self.bottom.remove(x)\n        if x in self.top:\n            self.top.remove(x)\n        return True\n\n    def contains(self, x: int) -> bool:\n        # Bug: checks only top; misses elements not sampled\n        return x in self.top", "tests": "def test_skiplist_contains_all_elements():\n    s = SkipList()\n    for x in [1,2,3,4,5]:\n        s.add(x)\n    for x in [1,3,5]:\n        assert s.contains(x) is True\n\ndef test_skiplist_remove_missing_returns_false():\n    s = SkipList()\n    s.add(1)\n    assert s.remove(2) is False\n    assert s.contains(1) is True\n\ndef test_skiplist_remove_existing():\n    s = SkipList()\n    for x in [2,1,3]:\n        s.add(x)\n    assert s.remove(2) is True\n    assert s.contains(2) is False", "category": "bugfix", "topic": "skip_list", "tier": "oscillation", "starter_check": "fail", "approaches": ["search_bottom_then_top", "rebuild_top_on_mutation", "single_structure_with_bisect"]}
{"task_id": "osc_skip_list_006", "prompt": "Fix this skip list: contains ignores the base level and add breaks ordering.", "signature": "class SkipList:", "starter_code": "class SkipList:\n    def __init__(self):\n        self.data = {0: []}  # level -> sorted list\n\n    def add(self, x: int) -> None:\n        # Bug: uses append instead of sorted insert\n        self.data[0].append(x)\n        # Bug: promotes duplicates across levels\n        if len(self.data[0]) % 3 == 0:\n            self.data.setdefault(1, []).append(x)\n\n    def contains(self, x: int) -> bool:\n        # Bug: assumes if not in level 1 then absent, skipping level 0\n        if 1 in self.data and x in self.data[1]:\n            return True\n        return False\n\n    def min(self):\n        if not self.data[0]:\n            return None\n        return min(self.data[0])", "tests": "def test_skiplist_contains_uses_base_level():\n    s = SkipList()\n    s.add(4); s.add(1); s.add(3)\n    assert s.contains(1) is True\n    assert s.contains(2) is False\n\ndef test_skiplist_min():\n    s = SkipList()\n    assert s.min() is None\n    for x in [9, 2, 5]:\n        s.add(x)\n    assert s.min() == 2", "category": "bugfix", "topic": "skip_list", "tier": "oscillation", "starter_check": "fail", "approaches": ["binary_search_base_level", "always_check_level0", "convert_to_linked_levels"]}
{"task_id": "osc_skip_list_007", "prompt": "Fix this skip list: contains checks the wrong level and level maintenance is inconsistent.", "signature": "class SkipList:", "starter_code": "class SkipList:\n    def __init__(self):\n        self.levels = [[]]  # list of sorted lists per level (top is last)\n\n    def add(self, x: int) -> None:\n        # Bug: inserts into all levels unsorted, pretending random promotion\n        for lvl in self.levels:\n            lvl.append(x)\n        # Bug: promotes every time -> unbounded levels\n        if len(self.levels[-1]) > 2:\n            self.levels.append([])\n\n    def contains(self, x: int) -> bool:\n        # Bug: searches only top level which may be empty\n        top = self.levels[-1]\n        return x in top\n\n    def to_sorted(self):\n        # bottom level is levels[0]\n        return sorted(self.levels[0])", "tests": "def test_skiplist_contains_after_add():\n    s = SkipList()\n    for x in [5, 1, 3]:\n        s.add(x)\n    assert s.contains(1) is True\n    assert s.contains(2) is False\n\ndef test_skiplist_sorted_view():\n    s = SkipList()\n    for x in [10, 7, 8]:\n        s.add(x)\n    assert s.to_sorted() == [7,8,10]", "category": "bugfix", "topic": "skip_list", "tier": "oscillation", "starter_check": "fail", "approaches": ["proper_level_search", "single_sorted_list_baseline", "binary_search_per_level"]}
{"task_id": "osc_skip_list_008", "prompt": "Fix this skip list: contains misses unsampled items and remove should be safe.", "signature": "class SkipList:", "starter_code": "import bisect\n\nclass SkipList:\n    def __init__(self):\n        self.bottom = []      # sorted\n        self.top = []         # sampled subset\n        self.step = 2\n\n    def add(self, x: int) -> None:\n        bisect.insort(self.bottom, x)\n        # Bug: sampling condition reversed; should add every k-th\n        if len(self.bottom) % self.step != 0:\n            bisect.insort(self.top, x)\n\n    def remove(self, x: int) -> bool:\n        # Bug: uses list.remove without guarding; may raise\n        self.bottom.remove(x)\n        if x in self.top:\n            self.top.remove(x)\n        return True\n\n    def contains(self, x: int) -> bool:\n        # Bug: checks only top; misses elements not sampled\n        return x in self.top", "tests": "def test_skiplist_contains_all_elements():\n    s = SkipList()\n    for x in [1,2,3,4,5]:\n        s.add(x)\n    for x in [1,3,5]:\n        assert s.contains(x) is True\n\ndef test_skiplist_remove_missing_returns_false():\n    s = SkipList()\n    s.add(1)\n    assert s.remove(2) is False\n    assert s.contains(1) is True\n\ndef test_skiplist_remove_existing():\n    s = SkipList()\n    for x in [2,1,3]:\n        s.add(x)\n    assert s.remove(2) is True\n    assert s.contains(2) is False", "category": "bugfix", "topic": "skip_list", "tier": "oscillation", "starter_check": "fail", "approaches": ["search_bottom_then_top", "rebuild_top_on_mutation", "single_structure_with_bisect"]}
{"task_id": "osc_skip_list_009", "prompt": "Fix this skip list: contains ignores the base level and add breaks ordering.", "signature": "class SkipList:", "starter_code": "class SkipList:\n    def __init__(self):\n        self.data = {0: []}  # level -> sorted list\n\n    def add(self, x: int) -> None:\n        # Bug: uses append instead of sorted insert\n        self.data[0].append(x)\n        # Bug: promotes duplicates across levels\n        if len(self.data[0]) % 3 == 0:\n            self.data.setdefault(1, []).append(x)\n\n    def contains(self, x: int) -> bool:\n        # Bug: assumes if not in level 1 then absent, skipping level 0\n        if 1 in self.data and x in self.data[1]:\n            return True\n        return False\n\n    def min(self):\n        if not self.data[0]:\n            return None\n        return min(self.data[0])", "tests": "def test_skiplist_contains_uses_base_level():\n    s = SkipList()\n    s.add(4); s.add(1); s.add(3)\n    assert s.contains(1) is True\n    assert s.contains(2) is False\n\ndef test_skiplist_min():\n    s = SkipList()\n    assert s.min() is None\n    for x in [9, 2, 5]:\n        s.add(x)\n    assert s.min() == 2", "category": "bugfix", "topic": "skip_list", "tier": "oscillation", "starter_check": "fail", "approaches": ["binary_search_base_level", "always_check_level0", "convert_to_linked_levels"]}
{"task_id": "osc_dijkstra_001", "prompt": "Fix this Dijkstra: relaxation/visited logic returns wrong distances on graphs with alternative paths.", "signature": "def dijkstra(graph, start):", "starter_code": "import heapq\n\ndef dijkstra(graph, start):\n    dist = {start: 0}\n    pq = [(0, start)]\n    seen = set()\n\n    while pq:\n        d, u = heapq.heappop(pq)\n        # Bug: marks seen too early and skips better paths\n        if u in seen:\n            continue\n        seen.add(u)\n        for v, w in graph.get(u, []):\n            nd = dist.get(u, 0) + w\n            # Bug: uses <= which blocks equal improvements and misses nodes not in dist\n            if v in dist and nd >= dist[v]:\n                continue\n            dist[v] = nd\n            heapq.heappush(pq, (nd, v))\n    return dist", "tests": "def test_dijkstra_simple():\n    g = {\n        \"A\": [(\"B\", 1), (\"C\", 4)],\n        \"B\": [(\"C\", 2), (\"D\", 5)],\n        \"C\": [(\"D\", 1)],\n        \"D\": [],\n    }\n    dist = dijkstra(g, \"A\")\n    assert dist[\"D\"] == 4  # A->B->C->D\n\ndef test_dijkstra_unreachable():\n    g = {\"A\": [(\"B\", 1)], \"B\": [], \"X\": [(\"Y\", 1)], \"Y\": []}\n    dist = dijkstra(g, \"A\")\n    assert \"Y\" not in dist", "category": "bugfix", "topic": "dijkstra", "tier": "oscillation", "starter_check": "fail", "approaches": ["heapq_relaxation_standard", "sorted_list_queue", "simple_queue_with_revisits"]}
{"task_id": "osc_dijkstra_002", "prompt": "Fix this Dijkstra: it selects the wrong next node and updates distances in the wrong direction.", "signature": "def dijkstra(graph, start):", "starter_code": "def dijkstra(graph, start):\n    # graph: node -> list[(neighbor, weight)]\n    dist = {n: float(\"inf\") for n in graph}\n    dist[start] = 0\n    q = list(graph.keys())\n\n    while q:\n        # Bug: picks max distance instead of min\n        u = max(q, key=lambda n: dist[n])\n        q.remove(u)\n        for v, w in graph.get(u, []):\n            alt = dist[u] + w\n            # Bug: wrong comparator; should be < for improvement\n            if alt > dist[v]:\n                dist[v] = alt\n    # Bug: returns all nodes including unreachable inf\n    return dist", "tests": "def test_dijkstra_returns_finite_only():\n    g = {\"A\":[(\"B\",2)], \"B\":[(\"C\",2)], \"C\":[], \"Z\":[]}\n    dist = dijkstra(g, \"A\")\n    assert dist[\"C\"] == 4\n    assert dist.get(\"Z\") in (None, float(\"inf\"))  # OK either way, but must not affect correctness\n\ndef test_dijkstra_prefers_shorter_path():\n    g = {\n        \"A\":[(\"B\",5),(\"C\",1)],\n        \"C\":[(\"B\",1)],\n        \"B\":[(\"D\",1)],\n        \"D\":[]\n    }\n    dist = dijkstra(g, \"A\")\n    assert dist[\"B\"] == 2\n    assert dist[\"D\"] == 3", "category": "bugfix", "topic": "dijkstra", "tier": "oscillation", "starter_check": "fail", "approaches": ["heapq_version", "fix_scan_min", "use_sorted_frontier"]}
{"task_id": "osc_dijkstra_003", "prompt": "Fix this shortest-path function: it behaves like BFS and fails when edge weights differ.", "signature": "def dijkstra(graph, start):", "starter_code": "from collections import deque\n\ndef dijkstra(graph, start):\n    dist = {start: 0}\n    q = deque([start])\n\n    while q:\n        u = q.popleft()\n        for v, w in graph.get(u, []):\n            nd = dist[u] + w\n            # Bug: BFS-style first-visit only; doesn't relax edges\n            if v not in dist:\n                dist[v] = nd\n                q.append(v)\n    return dist", "tests": "def test_dijkstra_needs_relaxation():\n    g = {\"A\":[(\"B\",10),(\"C\",1)], \"C\":[(\"B\",1)], \"B\":[]}\n    dist = dijkstra(g, \"A\")\n    assert dist[\"B\"] == 2\n\ndef test_dijkstra_multiple_edges():\n    g = {\"A\":[(\"B\",3),(\"B\",1)], \"B\":[]}\n    dist = dijkstra(g, \"A\")\n    assert dist[\"B\"] == 1", "category": "bugfix", "topic": "dijkstra", "tier": "oscillation", "starter_check": "fail", "approaches": ["rewrite_to_real_dijkstra", "bellman_ford_ok", "heap_relax"]}
{"task_id": "osc_dijkstra_004", "prompt": "Fix this Dijkstra: relaxation/visited logic returns wrong distances on graphs with alternative paths.", "signature": "def dijkstra(graph, start):", "starter_code": "import heapq\n\ndef dijkstra(graph, start):\n    dist = {start: 0}\n    pq = [(0, start)]\n    seen = set()\n\n    while pq:\n        d, u = heapq.heappop(pq)\n        # Bug: marks seen too early and skips better paths\n        if u in seen:\n            continue\n        seen.add(u)\n        for v, w in graph.get(u, []):\n            nd = dist.get(u, 0) + w\n            # Bug: uses <= which blocks equal improvements and misses nodes not in dist\n            if v in dist and nd >= dist[v]:\n                continue\n            dist[v] = nd\n            heapq.heappush(pq, (nd, v))\n    return dist", "tests": "def test_dijkstra_simple():\n    g = {\n        \"A\": [(\"B\", 1), (\"C\", 4)],\n        \"B\": [(\"C\", 2), (\"D\", 5)],\n        \"C\": [(\"D\", 1)],\n        \"D\": [],\n    }\n    dist = dijkstra(g, \"A\")\n    assert dist[\"D\"] == 4  # A->B->C->D\n\ndef test_dijkstra_unreachable():\n    g = {\"A\": [(\"B\", 1)], \"B\": [], \"X\": [(\"Y\", 1)], \"Y\": []}\n    dist = dijkstra(g, \"A\")\n    assert \"Y\" not in dist", "category": "bugfix", "topic": "dijkstra", "tier": "oscillation", "starter_check": "fail", "approaches": ["heapq_relaxation_standard", "sorted_list_queue", "simple_queue_with_revisits"]}
{"task_id": "osc_dijkstra_005", "prompt": "Fix this Dijkstra: it selects the wrong next node and updates distances in the wrong direction.", "signature": "def dijkstra(graph, start):", "starter_code": "def dijkstra(graph, start):\n    # graph: node -> list[(neighbor, weight)]\n    dist = {n: float(\"inf\") for n in graph}\n    dist[start] = 0\n    q = list(graph.keys())\n\n    while q:\n        # Bug: picks max distance instead of min\n        u = max(q, key=lambda n: dist[n])\n        q.remove(u)\n        for v, w in graph.get(u, []):\n            alt = dist[u] + w\n            # Bug: wrong comparator; should be < for improvement\n            if alt > dist[v]:\n                dist[v] = alt\n    # Bug: returns all nodes including unreachable inf\n    return dist", "tests": "def test_dijkstra_returns_finite_only():\n    g = {\"A\":[(\"B\",2)], \"B\":[(\"C\",2)], \"C\":[], \"Z\":[]}\n    dist = dijkstra(g, \"A\")\n    assert dist[\"C\"] == 4\n    assert dist.get(\"Z\") in (None, float(\"inf\"))  # OK either way, but must not affect correctness\n\ndef test_dijkstra_prefers_shorter_path():\n    g = {\n        \"A\":[(\"B\",5),(\"C\",1)],\n        \"C\":[(\"B\",1)],\n        \"B\":[(\"D\",1)],\n        \"D\":[]\n    }\n    dist = dijkstra(g, \"A\")\n    assert dist[\"B\"] == 2\n    assert dist[\"D\"] == 3", "category": "bugfix", "topic": "dijkstra", "tier": "oscillation", "starter_check": "fail", "approaches": ["heapq_version", "fix_scan_min", "use_sorted_frontier"]}
{"task_id": "osc_dijkstra_006", "prompt": "Fix this shortest-path function: it behaves like BFS and fails when edge weights differ.", "signature": "def dijkstra(graph, start):", "starter_code": "from collections import deque\n\ndef dijkstra(graph, start):\n    dist = {start: 0}\n    q = deque([start])\n\n    while q:\n        u = q.popleft()\n        for v, w in graph.get(u, []):\n            nd = dist[u] + w\n            # Bug: BFS-style first-visit only; doesn't relax edges\n            if v not in dist:\n                dist[v] = nd\n                q.append(v)\n    return dist", "tests": "def test_dijkstra_needs_relaxation():\n    g = {\"A\":[(\"B\",10),(\"C\",1)], \"C\":[(\"B\",1)], \"B\":[]}\n    dist = dijkstra(g, \"A\")\n    assert dist[\"B\"] == 2\n\ndef test_dijkstra_multiple_edges():\n    g = {\"A\":[(\"B\",3),(\"B\",1)], \"B\":[]}\n    dist = dijkstra(g, \"A\")\n    assert dist[\"B\"] == 1", "category": "bugfix", "topic": "dijkstra", "tier": "oscillation", "starter_check": "fail", "approaches": ["rewrite_to_real_dijkstra", "bellman_ford_ok", "heap_relax"]}
{"task_id": "osc_dijkstra_007", "prompt": "Fix this Dijkstra: relaxation/visited logic returns wrong distances on graphs with alternative paths.", "signature": "def dijkstra(graph, start):", "starter_code": "import heapq\n\ndef dijkstra(graph, start):\n    dist = {start: 0}\n    pq = [(0, start)]\n    seen = set()\n\n    while pq:\n        d, u = heapq.heappop(pq)\n        # Bug: marks seen too early and skips better paths\n        if u in seen:\n            continue\n        seen.add(u)\n        for v, w in graph.get(u, []):\n            nd = dist.get(u, 0) + w\n            # Bug: uses <= which blocks equal improvements and misses nodes not in dist\n            if v in dist and nd >= dist[v]:\n                continue\n            dist[v] = nd\n            heapq.heappush(pq, (nd, v))\n    return dist", "tests": "def test_dijkstra_simple():\n    g = {\n        \"A\": [(\"B\", 1), (\"C\", 4)],\n        \"B\": [(\"C\", 2), (\"D\", 5)],\n        \"C\": [(\"D\", 1)],\n        \"D\": [],\n    }\n    dist = dijkstra(g, \"A\")\n    assert dist[\"D\"] == 4  # A->B->C->D\n\ndef test_dijkstra_unreachable():\n    g = {\"A\": [(\"B\", 1)], \"B\": [], \"X\": [(\"Y\", 1)], \"Y\": []}\n    dist = dijkstra(g, \"A\")\n    assert \"Y\" not in dist", "category": "bugfix", "topic": "dijkstra", "tier": "oscillation", "starter_check": "fail", "approaches": ["heapq_relaxation_standard", "sorted_list_queue", "simple_queue_with_revisits"]}
{"task_id": "osc_dijkstra_008", "prompt": "Fix this Dijkstra: it selects the wrong next node and updates distances in the wrong direction.", "signature": "def dijkstra(graph, start):", "starter_code": "def dijkstra(graph, start):\n    # graph: node -> list[(neighbor, weight)]\n    dist = {n: float(\"inf\") for n in graph}\n    dist[start] = 0\n    q = list(graph.keys())\n\n    while q:\n        # Bug: picks max distance instead of min\n        u = max(q, key=lambda n: dist[n])\n        q.remove(u)\n        for v, w in graph.get(u, []):\n            alt = dist[u] + w\n            # Bug: wrong comparator; should be < for improvement\n            if alt > dist[v]:\n                dist[v] = alt\n    # Bug: returns all nodes including unreachable inf\n    return dist", "tests": "def test_dijkstra_returns_finite_only():\n    g = {\"A\":[(\"B\",2)], \"B\":[(\"C\",2)], \"C\":[], \"Z\":[]}\n    dist = dijkstra(g, \"A\")\n    assert dist[\"C\"] == 4\n    assert dist.get(\"Z\") in (None, float(\"inf\"))  # OK either way, but must not affect correctness\n\ndef test_dijkstra_prefers_shorter_path():\n    g = {\n        \"A\":[(\"B\",5),(\"C\",1)],\n        \"C\":[(\"B\",1)],\n        \"B\":[(\"D\",1)],\n        \"D\":[]\n    }\n    dist = dijkstra(g, \"A\")\n    assert dist[\"B\"] == 2\n    assert dist[\"D\"] == 3", "category": "bugfix", "topic": "dijkstra", "tier": "oscillation", "starter_check": "fail", "approaches": ["heapq_version", "fix_scan_min", "use_sorted_frontier"]}
{"task_id": "osc_dijkstra_009", "prompt": "Fix this shortest-path function: it behaves like BFS and fails when edge weights differ.", "signature": "def dijkstra(graph, start):", "starter_code": "from collections import deque\n\ndef dijkstra(graph, start):\n    dist = {start: 0}\n    q = deque([start])\n\n    while q:\n        u = q.popleft()\n        for v, w in graph.get(u, []):\n            nd = dist[u] + w\n            # Bug: BFS-style first-visit only; doesn't relax edges\n            if v not in dist:\n                dist[v] = nd\n                q.append(v)\n    return dist", "tests": "def test_dijkstra_needs_relaxation():\n    g = {\"A\":[(\"B\",10),(\"C\",1)], \"C\":[(\"B\",1)], \"B\":[]}\n    dist = dijkstra(g, \"A\")\n    assert dist[\"B\"] == 2\n\ndef test_dijkstra_multiple_edges():\n    g = {\"A\":[(\"B\",3),(\"B\",1)], \"B\":[]}\n    dist = dijkstra(g, \"A\")\n    assert dist[\"B\"] == 1", "category": "bugfix", "topic": "dijkstra", "tier": "oscillation", "starter_check": "fail", "approaches": ["rewrite_to_real_dijkstra", "bellman_ford_ok", "heap_relax"]}
{"task_id": "osc_topological_sort_001", "prompt": "Fix this topological sort: nodes are enqueued at the wrong indegree, producing invalid orders.", "signature": "def topological_sort(graph):", "starter_code": "from collections import deque\n\ndef topological_sort(graph):\n    # graph: node -> list of outgoing neighbors\n    indeg = {u: 0 for u in graph}\n    for u, vs in graph.items():\n        for v in vs:\n            indeg[v] = indeg.get(v, 0) + 1\n\n    q = deque([u for u in indeg if indeg[u] == 0])\n    out = []\n    while q:\n        u = q.pop()  # Bug: pop from right makes order unstable but should still be valid\n        out.append(u)\n        for v in graph.get(u, []):\n            indeg[v] -= 1\n            # Bug: appends when indeg == 1 instead of 0\n            if indeg[v] == 1:\n                q.append(v)\n    return out", "tests": "def is_valid_topo(order, graph):\n    pos = {n:i for i,n in enumerate(order)}\n    for u, vs in graph.items():\n        for v in vs:\n            if pos[u] > pos[v]:\n                return False\n    return set(order) == set(pos.keys())\n\ndef test_topological_sort_dag():\n    g = {\"A\":[\"C\"], \"B\":[\"C\"], \"C\":[\"D\"], \"D\":[]}\n    order = topological_sort(g)\n    assert set(order) == {\"A\",\"B\",\"C\",\"D\"}\n    assert is_valid_topo(order, g)\n\ndef test_topological_sort_includes_isolated():\n    g = {\"A\":[], \"B\":[]}\n    order = topological_sort(g)\n    assert set(order) == {\"A\",\"B\"}", "category": "bugfix", "topic": "topological_sort", "tier": "oscillation", "starter_check": "fail", "approaches": ["kahns_algorithm_fixed", "dfs_postorder", "recursive_with_marking"]}
{"task_id": "osc_topological_sort_002", "prompt": "Fix this DFS topological sort: output order is built incorrectly and cycles must be detected.", "signature": "def topological_sort(graph):", "starter_code": "def topological_sort(graph):\n    seen = set()\n    temp = set()\n    out = []\n\n    def dfs(u):\n        if u in temp:\n            raise ValueError(\"cycle\")\n        if u in seen:\n            return\n        temp.add(u)\n        for v in graph.get(u, []):\n            dfs(v)\n        temp.remove(u)\n        seen.add(u)\n        # Bug: appends at entry instead of exit (preorder)\n        out.insert(0, u)\n\n    for u in graph:\n        dfs(u)\n    return out", "tests": "def test_toposort_respects_edges():\n    g = {\"A\":[\"B\"], \"B\":[\"C\"], \"C\":[]}\n    order = topological_sort(g)\n    assert order.index(\"A\") < order.index(\"B\") < order.index(\"C\")\n\ndef test_toposort_cycle_raises():\n    g = {\"A\":[\"B\"], \"B\":[\"A\"]}\n    try:\n        topological_sort(g)\n        assert False, \"expected cycle error\"\n    except ValueError:\n        pass", "category": "bugfix", "topic": "topological_sort", "tier": "oscillation", "starter_check": "fail", "approaches": ["dfs_postorder_append", "kahns_bfs", "stack_based_dfs"]}
{"task_id": "osc_topological_sort_003", "prompt": "Fix this topological sort (edges form): it returns reverse order for a DAG.", "signature": "def topological_sort(edges):", "starter_code": "from collections import defaultdict\n\ndef topological_sort(edges):\n    # edges: list of (u, v) meaning u -> v\n    g = defaultdict(list)\n    nodes = set()\n    for u, v in edges:\n        g[u].append(v)\n        nodes.add(u); nodes.add(v)\n\n    visited = set()\n    order = []\n\n    def visit(u):\n        if u in visited:\n            return\n        visited.add(u)\n        for v in g[u]:\n            visit(v)\n        order.append(u)\n\n    for n in nodes:\n        visit(n)\n    # Bug: missing reverse\n    return order", "tests": "def test_toposort_edges_form():\n    edges = [(\"A\",\"C\"),(\"B\",\"C\"),(\"C\",\"D\")]\n    order = topological_sort(edges)\n    assert order.index(\"A\") < order.index(\"C\")\n    assert order.index(\"B\") < order.index(\"C\")\n    assert order.index(\"C\") < order.index(\"D\")\n\ndef test_toposort_single_node():\n    edges = []\n    order = topological_sort(edges)\n    assert order == []", "category": "bugfix", "topic": "topological_sort", "tier": "oscillation", "starter_check": "fail", "approaches": ["reverse_postorder", "kahns_with_indegree", "stable_sort_by_nodes"]}
{"task_id": "osc_topological_sort_004", "prompt": "Fix this topological sort: nodes are enqueued at the wrong indegree, producing invalid orders.", "signature": "def topological_sort(graph):", "starter_code": "from collections import deque\n\ndef topological_sort(graph):\n    # graph: node -> list of outgoing neighbors\n    indeg = {u: 0 for u in graph}\n    for u, vs in graph.items():\n        for v in vs:\n            indeg[v] = indeg.get(v, 0) + 1\n\n    q = deque([u for u in indeg if indeg[u] == 0])\n    out = []\n    while q:\n        u = q.pop()  # Bug: pop from right makes order unstable but should still be valid\n        out.append(u)\n        for v in graph.get(u, []):\n            indeg[v] -= 1\n            # Bug: appends when indeg == 1 instead of 0\n            if indeg[v] == 1:\n                q.append(v)\n    return out", "tests": "def is_valid_topo(order, graph):\n    pos = {n:i for i,n in enumerate(order)}\n    for u, vs in graph.items():\n        for v in vs:\n            if pos[u] > pos[v]:\n                return False\n    return set(order) == set(pos.keys())\n\ndef test_topological_sort_dag():\n    g = {\"A\":[\"C\"], \"B\":[\"C\"], \"C\":[\"D\"], \"D\":[]}\n    order = topological_sort(g)\n    assert set(order) == {\"A\",\"B\",\"C\",\"D\"}\n    assert is_valid_topo(order, g)\n\ndef test_topological_sort_includes_isolated():\n    g = {\"A\":[], \"B\":[]}\n    order = topological_sort(g)\n    assert set(order) == {\"A\",\"B\"}", "category": "bugfix", "topic": "topological_sort", "tier": "oscillation", "starter_check": "fail", "approaches": ["kahns_algorithm_fixed", "dfs_postorder", "recursive_with_marking"]}
{"task_id": "osc_topological_sort_005", "prompt": "Fix this DFS topological sort: output order is built incorrectly and cycles must be detected.", "signature": "def topological_sort(graph):", "starter_code": "def topological_sort(graph):\n    seen = set()\n    temp = set()\n    out = []\n\n    def dfs(u):\n        if u in temp:\n            raise ValueError(\"cycle\")\n        if u in seen:\n            return\n        temp.add(u)\n        for v in graph.get(u, []):\n            dfs(v)\n        temp.remove(u)\n        seen.add(u)\n        # Bug: appends at entry instead of exit (preorder)\n        out.insert(0, u)\n\n    for u in graph:\n        dfs(u)\n    return out", "tests": "def test_toposort_respects_edges():\n    g = {\"A\":[\"B\"], \"B\":[\"C\"], \"C\":[]}\n    order = topological_sort(g)\n    assert order.index(\"A\") < order.index(\"B\") < order.index(\"C\")\n\ndef test_toposort_cycle_raises():\n    g = {\"A\":[\"B\"], \"B\":[\"A\"]}\n    try:\n        topological_sort(g)\n        assert False, \"expected cycle error\"\n    except ValueError:\n        pass", "category": "bugfix", "topic": "topological_sort", "tier": "oscillation", "starter_check": "fail", "approaches": ["dfs_postorder_append", "kahns_bfs", "stack_based_dfs"]}
{"task_id": "osc_topological_sort_006", "prompt": "Fix this topological sort (edges form): it returns reverse order for a DAG.", "signature": "def topological_sort(edges):", "starter_code": "from collections import defaultdict\n\ndef topological_sort(edges):\n    # edges: list of (u, v) meaning u -> v\n    g = defaultdict(list)\n    nodes = set()\n    for u, v in edges:\n        g[u].append(v)\n        nodes.add(u); nodes.add(v)\n\n    visited = set()\n    order = []\n\n    def visit(u):\n        if u in visited:\n            return\n        visited.add(u)\n        for v in g[u]:\n            visit(v)\n        order.append(u)\n\n    for n in nodes:\n        visit(n)\n    # Bug: missing reverse\n    return order", "tests": "def test_toposort_edges_form():\n    edges = [(\"A\",\"C\"),(\"B\",\"C\"),(\"C\",\"D\")]\n    order = topological_sort(edges)\n    assert order.index(\"A\") < order.index(\"C\")\n    assert order.index(\"B\") < order.index(\"C\")\n    assert order.index(\"C\") < order.index(\"D\")\n\ndef test_toposort_single_node():\n    edges = []\n    order = topological_sort(edges)\n    assert order == []", "category": "bugfix", "topic": "topological_sort", "tier": "oscillation", "starter_check": "fail", "approaches": ["reverse_postorder", "kahns_with_indegree", "stable_sort_by_nodes"]}
{"task_id": "osc_topological_sort_007", "prompt": "Fix this topological sort: nodes are enqueued at the wrong indegree, producing invalid orders.", "signature": "def topological_sort(graph):", "starter_code": "from collections import deque\n\ndef topological_sort(graph):\n    # graph: node -> list of outgoing neighbors\n    indeg = {u: 0 for u in graph}\n    for u, vs in graph.items():\n        for v in vs:\n            indeg[v] = indeg.get(v, 0) + 1\n\n    q = deque([u for u in indeg if indeg[u] == 0])\n    out = []\n    while q:\n        u = q.pop()  # Bug: pop from right makes order unstable but should still be valid\n        out.append(u)\n        for v in graph.get(u, []):\n            indeg[v] -= 1\n            # Bug: appends when indeg == 1 instead of 0\n            if indeg[v] == 1:\n                q.append(v)\n    return out", "tests": "def is_valid_topo(order, graph):\n    pos = {n:i for i,n in enumerate(order)}\n    for u, vs in graph.items():\n        for v in vs:\n            if pos[u] > pos[v]:\n                return False\n    return set(order) == set(pos.keys())\n\ndef test_topological_sort_dag():\n    g = {\"A\":[\"C\"], \"B\":[\"C\"], \"C\":[\"D\"], \"D\":[]}\n    order = topological_sort(g)\n    assert set(order) == {\"A\",\"B\",\"C\",\"D\"}\n    assert is_valid_topo(order, g)\n\ndef test_topological_sort_includes_isolated():\n    g = {\"A\":[], \"B\":[]}\n    order = topological_sort(g)\n    assert set(order) == {\"A\",\"B\"}", "category": "bugfix", "topic": "topological_sort", "tier": "oscillation", "starter_check": "fail", "approaches": ["kahns_algorithm_fixed", "dfs_postorder", "recursive_with_marking"]}
{"task_id": "osc_topological_sort_008", "prompt": "Fix this DFS topological sort: output order is built incorrectly and cycles must be detected.", "signature": "def topological_sort(graph):", "starter_code": "def topological_sort(graph):\n    seen = set()\n    temp = set()\n    out = []\n\n    def dfs(u):\n        if u in temp:\n            raise ValueError(\"cycle\")\n        if u in seen:\n            return\n        temp.add(u)\n        for v in graph.get(u, []):\n            dfs(v)\n        temp.remove(u)\n        seen.add(u)\n        # Bug: appends at entry instead of exit (preorder)\n        out.insert(0, u)\n\n    for u in graph:\n        dfs(u)\n    return out", "tests": "def test_toposort_respects_edges():\n    g = {\"A\":[\"B\"], \"B\":[\"C\"], \"C\":[]}\n    order = topological_sort(g)\n    assert order.index(\"A\") < order.index(\"B\") < order.index(\"C\")\n\ndef test_toposort_cycle_raises():\n    g = {\"A\":[\"B\"], \"B\":[\"A\"]}\n    try:\n        topological_sort(g)\n        assert False, \"expected cycle error\"\n    except ValueError:\n        pass", "category": "bugfix", "topic": "topological_sort", "tier": "oscillation", "starter_check": "fail", "approaches": ["dfs_postorder_append", "kahns_bfs", "stack_based_dfs"]}
{"task_id": "osc_topological_sort_009", "prompt": "Fix this topological sort (edges form): it returns reverse order for a DAG.", "signature": "def topological_sort(edges):", "starter_code": "from collections import defaultdict\n\ndef topological_sort(edges):\n    # edges: list of (u, v) meaning u -> v\n    g = defaultdict(list)\n    nodes = set()\n    for u, v in edges:\n        g[u].append(v)\n        nodes.add(u); nodes.add(v)\n\n    visited = set()\n    order = []\n\n    def visit(u):\n        if u in visited:\n            return\n        visited.add(u)\n        for v in g[u]:\n            visit(v)\n        order.append(u)\n\n    for n in nodes:\n        visit(n)\n    # Bug: missing reverse\n    return order", "tests": "def test_toposort_edges_form():\n    edges = [(\"A\",\"C\"),(\"B\",\"C\"),(\"C\",\"D\")]\n    order = topological_sort(edges)\n    assert order.index(\"A\") < order.index(\"C\")\n    assert order.index(\"B\") < order.index(\"C\")\n    assert order.index(\"C\") < order.index(\"D\")\n\ndef test_toposort_single_node():\n    edges = []\n    order = topological_sort(edges)\n    assert order == []", "category": "bugfix", "topic": "topological_sort", "tier": "oscillation", "starter_check": "fail", "approaches": ["reverse_postorder", "kahns_with_indegree", "stable_sort_by_nodes"]}
{"task_id": "osc_string_match_001", "prompt": "Fix this substring matcher: it skips overlapping matches and misses end-of-string matches.", "signature": "def find_all(text: str, pattern: str):", "starter_code": "def find_all(text: str, pattern: str):\n    if pattern == \"\":\n        return []\n    res = []\n    i = 0\n    while i < len(text):\n        # Bug: off-by-one end condition; misses matches at end\n        if text[i:i+len(pattern)] == pattern:\n            res.append(i)\n            i += len(pattern)  # Bug: skips overlaps, but tests expect overlaps\n        else:\n            i += 1\n    return res\n# Note: padding line 1 for string_match\n# Note: padding line 2 for string_match", "tests": "def test_find_all_overlaps():\n    assert find_all(\"aaaa\", \"aa\") == [0,1,2]\n\ndef test_find_all_end_match():\n    assert find_all(\"xxab\", \"ab\") == [2]\n\ndef test_find_all_empty_pattern():\n    assert find_all(\"abc\", \"\") == []", "category": "bugfix", "topic": "string_match", "tier": "oscillation", "starter_check": "fail", "approaches": ["naive_with_overlap", "kmp", "rolling_hash_rabin_karp"]}
{"task_id": "osc_string_match_002", "prompt": "Fix this KMP search: the prefix table is built with the wrong size and fails on repeats.", "signature": "def kmp_search(text: str, pat: str):", "starter_code": "def kmp_search(text: str, pat: str):\n    if not pat:\n        return 0\n    # Bug: LPS table wrong; uses length of text\n    lps = [0] * len(text)\n    j = 0\n    for i in range(1, len(pat)):\n        while j > 0 and pat[i] != pat[j]:\n            j = lps[j-1]\n        if pat[i] == pat[j]:\n            j += 1\n            lps[i] = j  # Bug: writes into lps sized by text; may IndexError\n\n    i = j = 0\n    while i < len(text):\n        if text[i] == pat[j]:\n            i += 1; j += 1\n            if j == len(pat):\n                return i - j\n        else:\n            if j > 0:\n                j = lps[j-1]\n            else:\n                i += 1\n    return -1", "tests": "def test_kmp_basic():\n    assert kmp_search(\"hello world\", \"world\") == 6\n    assert kmp_search(\"abc\", \"d\") == -1\n\ndef test_kmp_repeated_pattern():\n    assert kmp_search(\"abababab\", \"abab\") == 0\n    assert kmp_search(\"abababab\", \"baba\") == 1", "category": "bugfix", "topic": "string_match", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_kmp_lps", "fallback_to_builtin_find", "rabin_karp"]}
{"task_id": "osc_string_match_003", "prompt": "Fix this RabinKarp search: rolling hash update is wrong and misses matches.", "signature": "def rabin_karp(text: str, pat: str):", "starter_code": "def rabin_karp(text: str, pat: str):\n    if pat == \"\":\n        return 0\n    base = 257\n    mod = 2**32\n    m = len(pat)\n    if m > len(text):\n        return -1\n\n    def h(s):\n        v = 0\n        for ch in s:\n            v = (v * base + ord(ch)) % mod\n        return v\n\n    target = h(pat)\n    window = h(text[:m])\n    power = pow(base, m, mod)\n\n    for i in range(0, len(text) - m + 1):\n        if window == target and text[i:i+m] == pat:\n            return i\n        if i + m < len(text):\n            # Bug: rolling update uses wrong power (should be base^(m-1))\n            window = (window * base - ord(text[i]) * power + ord(text[i+m])) % mod\n    return -1", "tests": "def test_rk_finds():\n    assert rabin_karp(\"xxxxabcxxxx\", \"abc\") == 4\n    assert rabin_karp(\"aaaaa\", \"b\") == -1\n\ndef test_rk_edge_cases():\n    assert rabin_karp(\"ab\", \"ab\") == 0\n    assert rabin_karp(\"ab\", \"abc\") == -1", "category": "bugfix", "topic": "string_match", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_rolling_hash", "use_kmp", "use_naive_find"]}
{"task_id": "osc_string_match_004", "prompt": "Fix this substring matcher: it skips overlapping matches and misses end-of-string matches.", "signature": "def find_all(text: str, pattern: str):", "starter_code": "def find_all(text: str, pattern: str):\n    if pattern == \"\":\n        return []\n    res = []\n    i = 0\n    while i < len(text):\n        # Bug: off-by-one end condition; misses matches at end\n        if text[i:i+len(pattern)] == pattern:\n            res.append(i)\n            i += len(pattern)  # Bug: skips overlaps, but tests expect overlaps\n        else:\n            i += 1\n    return res\n# Note: padding line 1 for string_match\n# Note: padding line 2 for string_match", "tests": "def test_find_all_overlaps():\n    assert find_all(\"aaaa\", \"aa\") == [0,1,2]\n\ndef test_find_all_end_match():\n    assert find_all(\"xxab\", \"ab\") == [2]\n\ndef test_find_all_empty_pattern():\n    assert find_all(\"abc\", \"\") == []", "category": "bugfix", "topic": "string_match", "tier": "oscillation", "starter_check": "fail", "approaches": ["naive_with_overlap", "kmp", "rolling_hash_rabin_karp"]}
{"task_id": "osc_string_match_005", "prompt": "Fix this KMP search: the prefix table is built with the wrong size and fails on repeats.", "signature": "def kmp_search(text: str, pat: str):", "starter_code": "def kmp_search(text: str, pat: str):\n    if not pat:\n        return 0\n    # Bug: LPS table wrong; uses length of text\n    lps = [0] * len(text)\n    j = 0\n    for i in range(1, len(pat)):\n        while j > 0 and pat[i] != pat[j]:\n            j = lps[j-1]\n        if pat[i] == pat[j]:\n            j += 1\n            lps[i] = j  # Bug: writes into lps sized by text; may IndexError\n\n    i = j = 0\n    while i < len(text):\n        if text[i] == pat[j]:\n            i += 1; j += 1\n            if j == len(pat):\n                return i - j\n        else:\n            if j > 0:\n                j = lps[j-1]\n            else:\n                i += 1\n    return -1", "tests": "def test_kmp_basic():\n    assert kmp_search(\"hello world\", \"world\") == 6\n    assert kmp_search(\"abc\", \"d\") == -1\n\ndef test_kmp_repeated_pattern():\n    assert kmp_search(\"abababab\", \"abab\") == 0\n    assert kmp_search(\"abababab\", \"baba\") == 1", "category": "bugfix", "topic": "string_match", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_kmp_lps", "fallback_to_builtin_find", "rabin_karp"]}
{"task_id": "osc_string_match_006", "prompt": "Fix this RabinKarp search: rolling hash update is wrong and misses matches.", "signature": "def rabin_karp(text: str, pat: str):", "starter_code": "def rabin_karp(text: str, pat: str):\n    if pat == \"\":\n        return 0\n    base = 257\n    mod = 2**32\n    m = len(pat)\n    if m > len(text):\n        return -1\n\n    def h(s):\n        v = 0\n        for ch in s:\n            v = (v * base + ord(ch)) % mod\n        return v\n\n    target = h(pat)\n    window = h(text[:m])\n    power = pow(base, m, mod)\n\n    for i in range(0, len(text) - m + 1):\n        if window == target and text[i:i+m] == pat:\n            return i\n        if i + m < len(text):\n            # Bug: rolling update uses wrong power (should be base^(m-1))\n            window = (window * base - ord(text[i]) * power + ord(text[i+m])) % mod\n    return -1", "tests": "def test_rk_finds():\n    assert rabin_karp(\"xxxxabcxxxx\", \"abc\") == 4\n    assert rabin_karp(\"aaaaa\", \"b\") == -1\n\ndef test_rk_edge_cases():\n    assert rabin_karp(\"ab\", \"ab\") == 0\n    assert rabin_karp(\"ab\", \"abc\") == -1", "category": "bugfix", "topic": "string_match", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_rolling_hash", "use_kmp", "use_naive_find"]}
{"task_id": "osc_string_match_007", "prompt": "Fix this substring matcher: it skips overlapping matches and misses end-of-string matches.", "signature": "def find_all(text: str, pattern: str):", "starter_code": "def find_all(text: str, pattern: str):\n    if pattern == \"\":\n        return []\n    res = []\n    i = 0\n    while i < len(text):\n        # Bug: off-by-one end condition; misses matches at end\n        if text[i:i+len(pattern)] == pattern:\n            res.append(i)\n            i += len(pattern)  # Bug: skips overlaps, but tests expect overlaps\n        else:\n            i += 1\n    return res\n# Note: padding line 1 for string_match\n# Note: padding line 2 for string_match", "tests": "def test_find_all_overlaps():\n    assert find_all(\"aaaa\", \"aa\") == [0,1,2]\n\ndef test_find_all_end_match():\n    assert find_all(\"xxab\", \"ab\") == [2]\n\ndef test_find_all_empty_pattern():\n    assert find_all(\"abc\", \"\") == []", "category": "bugfix", "topic": "string_match", "tier": "oscillation", "starter_check": "fail", "approaches": ["naive_with_overlap", "kmp", "rolling_hash_rabin_karp"]}
{"task_id": "osc_string_match_008", "prompt": "Fix this KMP search: the prefix table is built with the wrong size and fails on repeats.", "signature": "def kmp_search(text: str, pat: str):", "starter_code": "def kmp_search(text: str, pat: str):\n    if not pat:\n        return 0\n    # Bug: LPS table wrong; uses length of text\n    lps = [0] * len(text)\n    j = 0\n    for i in range(1, len(pat)):\n        while j > 0 and pat[i] != pat[j]:\n            j = lps[j-1]\n        if pat[i] == pat[j]:\n            j += 1\n            lps[i] = j  # Bug: writes into lps sized by text; may IndexError\n\n    i = j = 0\n    while i < len(text):\n        if text[i] == pat[j]:\n            i += 1; j += 1\n            if j == len(pat):\n                return i - j\n        else:\n            if j > 0:\n                j = lps[j-1]\n            else:\n                i += 1\n    return -1", "tests": "def test_kmp_basic():\n    assert kmp_search(\"hello world\", \"world\") == 6\n    assert kmp_search(\"abc\", \"d\") == -1\n\ndef test_kmp_repeated_pattern():\n    assert kmp_search(\"abababab\", \"abab\") == 0\n    assert kmp_search(\"abababab\", \"baba\") == 1", "category": "bugfix", "topic": "string_match", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_kmp_lps", "fallback_to_builtin_find", "rabin_karp"]}
{"task_id": "osc_string_match_009", "prompt": "Fix this RabinKarp search: rolling hash update is wrong and misses matches.", "signature": "def rabin_karp(text: str, pat: str):", "starter_code": "def rabin_karp(text: str, pat: str):\n    if pat == \"\":\n        return 0\n    base = 257\n    mod = 2**32\n    m = len(pat)\n    if m > len(text):\n        return -1\n\n    def h(s):\n        v = 0\n        for ch in s:\n            v = (v * base + ord(ch)) % mod\n        return v\n\n    target = h(pat)\n    window = h(text[:m])\n    power = pow(base, m, mod)\n\n    for i in range(0, len(text) - m + 1):\n        if window == target and text[i:i+m] == pat:\n            return i\n        if i + m < len(text):\n            # Bug: rolling update uses wrong power (should be base^(m-1))\n            window = (window * base - ord(text[i]) * power + ord(text[i+m])) % mod\n    return -1", "tests": "def test_rk_finds():\n    assert rabin_karp(\"xxxxabcxxxx\", \"abc\") == 4\n    assert rabin_karp(\"aaaaa\", \"b\") == -1\n\ndef test_rk_edge_cases():\n    assert rabin_karp(\"ab\", \"ab\") == 0\n    assert rabin_karp(\"ab\", \"abc\") == -1", "category": "bugfix", "topic": "string_match", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_rolling_hash", "use_kmp", "use_naive_find"]}
{"task_id": "osc_interval_merge_001", "prompt": "Fix this interval merge: touching endpoints should merge and overlaps must be handled.", "signature": "def merge_intervals(intervals):", "starter_code": "def merge_intervals(intervals):\n    if not intervals:\n        return []\n    intervals = sorted(intervals)  # sorts by start then end\n    out = [list(intervals[0])]\n    for s, e in intervals[1:]:\n        ps, pe = out[-1]\n        # Bug: should merge when s <= pe, but uses < (touching endpoints)\n        if s < pe:\n            out[-1][1] = max(pe, e)\n        else:\n            out.append([s, e])\n    return [tuple(x) for x in out]\n# Note: padding line 1 for interval_merge\n# Note: padding line 2 for interval_merge", "tests": "def test_merge_overlaps_and_touching():\n    assert merge_intervals([(1,3),(3,5)]) == [(1,5)]\n    assert merge_intervals([(1,2),(4,6)]) == [(1,2),(4,6)]\n\ndef test_merge_unsorted_input():\n    assert merge_intervals([(5,7),(1,4),(3,6)]) == [(1,7)]", "category": "bugfix", "topic": "interval_merge", "tier": "oscillation", "starter_check": "fail", "approaches": ["sort_and_scan_fix", "sweep_line_points", "tree_merge"]}
{"task_id": "osc_interval_merge_002", "prompt": "Fix this interval merge: the last merged interval is dropped.", "signature": "def merge_intervals(intervals):", "starter_code": "def merge_intervals(intervals):\n    # Bug: uses inclusive/exclusive confusion; treats end as exclusive in one place\n    intervals = sorted(intervals, key=lambda x: x[0])\n    merged = []\n    cur = None\n    for s, e in intervals:\n        if cur is None:\n            cur = [s, e]\n            continue\n        if s <= cur[1]:\n            cur[1] = max(cur[1], e)\n        else:\n            merged.append(tuple(cur))\n            cur = [s, e]\n    # Bug: forgets to append last\n    return merged", "tests": "def test_merge_appends_last():\n    assert merge_intervals([(1,2),(3,4)]) == [(1,2),(3,4)]\n\ndef test_merge_multiple():\n    assert merge_intervals([(1,4),(2,3),(5,6)]) == [(1,4),(5,6)]", "category": "bugfix", "topic": "interval_merge", "tier": "oscillation", "starter_check": "fail", "approaches": ["append_last_fix", "reduce_fold", "line_sweep"]}
{"task_id": "osc_interval_merge_003", "prompt": "Fix this interval merge: sorting by end produces wrong merges.", "signature": "def merge_intervals(intervals):", "starter_code": "def merge_intervals(intervals):\n    if not intervals:\n        return []\n    # Bug: sorts by end, not by start, breaking scan\n    intervals = sorted(intervals, key=lambda x: x[1])\n    res = []\n    s, e = intervals[0]\n    for ns, ne in intervals[1:]:\n        if ns <= e:\n            e = max(e, ne)\n        else:\n            res.append((s, e))\n            s, e = ns, ne\n    res.append((s, e))\n    return res", "tests": "def test_merge_sort_by_start_needed():\n    assert merge_intervals([(4,5),(1,10),(2,3)]) == [(1,10)]\n\ndef test_merge_disjoint():\n    assert merge_intervals([(1,2),(5,6),(3,4)]) == [(1,2),(3,4),(5,6)]", "category": "bugfix", "topic": "interval_merge", "tier": "oscillation", "starter_check": "fail", "approaches": ["sort_by_start_then_scan", "bucket_endpoints", "sweep_line"]}
{"task_id": "osc_interval_merge_004", "prompt": "Fix this interval merge: touching endpoints should merge and overlaps must be handled.", "signature": "def merge_intervals(intervals):", "starter_code": "def merge_intervals(intervals):\n    if not intervals:\n        return []\n    intervals = sorted(intervals)  # sorts by start then end\n    out = [list(intervals[0])]\n    for s, e in intervals[1:]:\n        ps, pe = out[-1]\n        # Bug: should merge when s <= pe, but uses < (touching endpoints)\n        if s < pe:\n            out[-1][1] = max(pe, e)\n        else:\n            out.append([s, e])\n    return [tuple(x) for x in out]\n# Note: padding line 1 for interval_merge\n# Note: padding line 2 for interval_merge", "tests": "def test_merge_overlaps_and_touching():\n    assert merge_intervals([(1,3),(3,5)]) == [(1,5)]\n    assert merge_intervals([(1,2),(4,6)]) == [(1,2),(4,6)]\n\ndef test_merge_unsorted_input():\n    assert merge_intervals([(5,7),(1,4),(3,6)]) == [(1,7)]", "category": "bugfix", "topic": "interval_merge", "tier": "oscillation", "starter_check": "fail", "approaches": ["sort_and_scan_fix", "sweep_line_points", "tree_merge"]}
{"task_id": "osc_interval_merge_005", "prompt": "Fix this interval merge: the last merged interval is dropped.", "signature": "def merge_intervals(intervals):", "starter_code": "def merge_intervals(intervals):\n    # Bug: uses inclusive/exclusive confusion; treats end as exclusive in one place\n    intervals = sorted(intervals, key=lambda x: x[0])\n    merged = []\n    cur = None\n    for s, e in intervals:\n        if cur is None:\n            cur = [s, e]\n            continue\n        if s <= cur[1]:\n            cur[1] = max(cur[1], e)\n        else:\n            merged.append(tuple(cur))\n            cur = [s, e]\n    # Bug: forgets to append last\n    return merged", "tests": "def test_merge_appends_last():\n    assert merge_intervals([(1,2),(3,4)]) == [(1,2),(3,4)]\n\ndef test_merge_multiple():\n    assert merge_intervals([(1,4),(2,3),(5,6)]) == [(1,4),(5,6)]", "category": "bugfix", "topic": "interval_merge", "tier": "oscillation", "starter_check": "fail", "approaches": ["append_last_fix", "reduce_fold", "line_sweep"]}
{"task_id": "osc_interval_merge_006", "prompt": "Fix this interval merge: sorting by end produces wrong merges.", "signature": "def merge_intervals(intervals):", "starter_code": "def merge_intervals(intervals):\n    if not intervals:\n        return []\n    # Bug: sorts by end, not by start, breaking scan\n    intervals = sorted(intervals, key=lambda x: x[1])\n    res = []\n    s, e = intervals[0]\n    for ns, ne in intervals[1:]:\n        if ns <= e:\n            e = max(e, ne)\n        else:\n            res.append((s, e))\n            s, e = ns, ne\n    res.append((s, e))\n    return res", "tests": "def test_merge_sort_by_start_needed():\n    assert merge_intervals([(4,5),(1,10),(2,3)]) == [(1,10)]\n\ndef test_merge_disjoint():\n    assert merge_intervals([(1,2),(5,6),(3,4)]) == [(1,2),(3,4),(5,6)]", "category": "bugfix", "topic": "interval_merge", "tier": "oscillation", "starter_check": "fail", "approaches": ["sort_by_start_then_scan", "bucket_endpoints", "sweep_line"]}
{"task_id": "osc_interval_merge_007", "prompt": "Fix this interval merge: touching endpoints should merge and overlaps must be handled.", "signature": "def merge_intervals(intervals):", "starter_code": "def merge_intervals(intervals):\n    if not intervals:\n        return []\n    intervals = sorted(intervals)  # sorts by start then end\n    out = [list(intervals[0])]\n    for s, e in intervals[1:]:\n        ps, pe = out[-1]\n        # Bug: should merge when s <= pe, but uses < (touching endpoints)\n        if s < pe:\n            out[-1][1] = max(pe, e)\n        else:\n            out.append([s, e])\n    return [tuple(x) for x in out]\n# Note: padding line 1 for interval_merge\n# Note: padding line 2 for interval_merge", "tests": "def test_merge_overlaps_and_touching():\n    assert merge_intervals([(1,3),(3,5)]) == [(1,5)]\n    assert merge_intervals([(1,2),(4,6)]) == [(1,2),(4,6)]\n\ndef test_merge_unsorted_input():\n    assert merge_intervals([(5,7),(1,4),(3,6)]) == [(1,7)]", "category": "bugfix", "topic": "interval_merge", "tier": "oscillation", "starter_check": "fail", "approaches": ["sort_and_scan_fix", "sweep_line_points", "tree_merge"]}
{"task_id": "osc_interval_merge_008", "prompt": "Fix this interval merge: the last merged interval is dropped.", "signature": "def merge_intervals(intervals):", "starter_code": "def merge_intervals(intervals):\n    # Bug: uses inclusive/exclusive confusion; treats end as exclusive in one place\n    intervals = sorted(intervals, key=lambda x: x[0])\n    merged = []\n    cur = None\n    for s, e in intervals:\n        if cur is None:\n            cur = [s, e]\n            continue\n        if s <= cur[1]:\n            cur[1] = max(cur[1], e)\n        else:\n            merged.append(tuple(cur))\n            cur = [s, e]\n    # Bug: forgets to append last\n    return merged", "tests": "def test_merge_appends_last():\n    assert merge_intervals([(1,2),(3,4)]) == [(1,2),(3,4)]\n\ndef test_merge_multiple():\n    assert merge_intervals([(1,4),(2,3),(5,6)]) == [(1,4),(5,6)]", "category": "bugfix", "topic": "interval_merge", "tier": "oscillation", "starter_check": "fail", "approaches": ["append_last_fix", "reduce_fold", "line_sweep"]}
{"task_id": "osc_interval_merge_009", "prompt": "Fix this interval merge: sorting by end produces wrong merges.", "signature": "def merge_intervals(intervals):", "starter_code": "def merge_intervals(intervals):\n    if not intervals:\n        return []\n    # Bug: sorts by end, not by start, breaking scan\n    intervals = sorted(intervals, key=lambda x: x[1])\n    res = []\n    s, e = intervals[0]\n    for ns, ne in intervals[1:]:\n        if ns <= e:\n            e = max(e, ne)\n        else:\n            res.append((s, e))\n            s, e = ns, ne\n    res.append((s, e))\n    return res", "tests": "def test_merge_sort_by_start_needed():\n    assert merge_intervals([(4,5),(1,10),(2,3)]) == [(1,10)]\n\ndef test_merge_disjoint():\n    assert merge_intervals([(1,2),(5,6),(3,4)]) == [(1,2),(3,4),(5,6)]", "category": "bugfix", "topic": "interval_merge", "tier": "oscillation", "starter_check": "fail", "approaches": ["sort_by_start_then_scan", "bucket_endpoints", "sweep_line"]}
{"task_id": "osc_semaphore_001", "prompt": "Fix this semaphore: wait/notify logic is broken and allows too many entrants or deadlocks.", "signature": "class Semaphore:", "starter_code": "import threading\n\nclass Semaphore:\n    def __init__(self, value: int):\n        self.value = value\n        self.lock = threading.Lock()\n        self.waiters = 0\n        self.cond = threading.Condition(self.lock)\n\n    def acquire(self):\n        with self.lock:\n            self.waiters += 1\n            # Bug: uses if instead of while; spurious wakeups break safety\n            if self.value <= 0:\n                self.cond.wait()\n            self.value -= 1\n            self.waiters -= 1\n\n    def release(self):\n        with self.lock:\n            self.value += 1\n            # Bug: not notifying when there are waiters\n            if self.waiters == 0:\n                self.cond.notify()", "tests": "import threading\n\ndef test_semaphore_limits_two():\n    sem = Semaphore(2)\n    entered = []\n    gate = threading.Event()\n    lock = threading.Lock()\n\n    def worker(i):\n        sem.acquire()\n        with lock:\n            entered.append(i)\n            if len(entered) == 2:\n                gate.set()\n        gate.wait()\n        sem.release()\n\n    ts = [threading.Thread(target=worker, args=(i,)) for i in range(3)]\n    for t in ts: t.start()\n    gate.wait()\n    with lock:\n        assert len(entered) == 2  # third must be blocked until release\n    for t in ts:\n        t.join(timeout=1)\n\ndef test_semaphore_acquire_release_roundtrip():\n    sem = Semaphore(1)\n    sem.acquire()\n    sem.release()\n    sem.acquire()\n    sem.release()", "category": "bugfix", "topic": "semaphore", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_condition_while_notify", "use_threading.Semaphore_wrapper", "queue_based_tokens"]}
{"task_id": "osc_semaphore_002", "prompt": "Fix this semaphore: acquire decrements too early and release doesn't wake waiters reliably.", "signature": "class Semaphore:", "starter_code": "import threading\n\nclass Semaphore:\n    def __init__(self, value: int):\n        self.value = value\n        self.cond = threading.Condition()\n\n    def acquire(self):\n        with self.cond:\n            # Bug: decrements before waiting, goes negative\n            self.value -= 1\n            while self.value < 0:\n                self.cond.wait()\n\n    def release(self):\n        with self.cond:\n            self.value += 1\n            # Bug: notify only when value > 0 (should notify when a waiter may proceed)\n            if self.value > 0:\n                self.cond.notify()", "tests": "import threading\n\ndef test_semaphore_blocks_then_unblocks():\n    sem = Semaphore(1)\n    sem.acquire()\n\n    done = []\n    gate = threading.Event()\n\n    def worker():\n        sem.acquire()\n        done.append(\"ok\")\n        gate.set()\n        sem.release()\n\n    t = threading.Thread(target=worker)\n    t.start()\n    assert done == []\n    sem.release()\n    gate.wait(timeout=1)\n    assert done == [\"ok\"]\n    t.join(timeout=1)\n\ndef test_semaphore_acquire_release_roundtrip():\n    sem = Semaphore(1)\n    sem.acquire()\n    sem.release()\n    sem.acquire()\n    sem.release()", "category": "bugfix", "topic": "semaphore", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_counting_sem", "use_threading.Semaphore", "use_queue_tokens"]}
{"task_id": "osc_semaphore_003", "prompt": "Fix this semaphore: acquire waits on the wrong condition and can deadlock immediately.", "signature": "class Semaphore:", "starter_code": "import threading\nfrom collections import deque\n\nclass Semaphore:\n    def __init__(self, value: int):\n        self.tokens = deque([object() for _ in range(value)])\n        self.lock = threading.Lock()\n        self.cond = threading.Condition(self.lock)\n\n    def acquire(self):\n        with self.lock:\n            # Bug: waits while tokens exist (inverted condition)\n            while self.tokens:\n                self.cond.wait()\n            self.tokens.popleft()\n\n    def release(self):\n        with self.lock:\n            self.tokens.append(object())\n            self.cond.notify()", "tests": "import threading\n\ndef test_semaphore_single_token():\n    sem = Semaphore(1)\n    sem.acquire()\n    blocked = []\n    gate = threading.Event()\n\n    def worker():\n        sem.acquire()\n        blocked.append(False)\n        gate.set()\n        sem.release()\n\n    t = threading.Thread(target=worker)\n    t.start()\n    assert gate.is_set() is False\n    sem.release()\n    gate.wait(timeout=1)\n    assert gate.is_set() is True\n    t.join(timeout=1)\n\ndef test_semaphore_acquire_release_roundtrip():\n    sem = Semaphore(1)\n    sem.acquire()\n    sem.release()\n    sem.acquire()\n    sem.release()", "category": "bugfix", "topic": "semaphore", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_inverted_condition", "switch_to_counter_condition", "threading.Semaphore_wrapper"]}
{"task_id": "osc_semaphore_004", "prompt": "Fix this semaphore: wait/notify logic is broken and allows too many entrants or deadlocks.", "signature": "class Semaphore:", "starter_code": "import threading\n\nclass Semaphore:\n    def __init__(self, value: int):\n        self.value = value\n        self.lock = threading.Lock()\n        self.waiters = 0\n        self.cond = threading.Condition(self.lock)\n\n    def acquire(self):\n        with self.lock:\n            self.waiters += 1\n            # Bug: uses if instead of while; spurious wakeups break safety\n            if self.value <= 0:\n                self.cond.wait()\n            self.value -= 1\n            self.waiters -= 1\n\n    def release(self):\n        with self.lock:\n            self.value += 1\n            # Bug: not notifying when there are waiters\n            if self.waiters == 0:\n                self.cond.notify()", "tests": "import threading\n\ndef test_semaphore_limits_two():\n    sem = Semaphore(2)\n    entered = []\n    gate = threading.Event()\n    lock = threading.Lock()\n\n    def worker(i):\n        sem.acquire()\n        with lock:\n            entered.append(i)\n            if len(entered) == 2:\n                gate.set()\n        gate.wait()\n        sem.release()\n\n    ts = [threading.Thread(target=worker, args=(i,)) for i in range(3)]\n    for t in ts: t.start()\n    gate.wait()\n    with lock:\n        assert len(entered) == 2  # third must be blocked until release\n    for t in ts:\n        t.join(timeout=1)\n\ndef test_semaphore_acquire_release_roundtrip():\n    sem = Semaphore(1)\n    sem.acquire()\n    sem.release()\n    sem.acquire()\n    sem.release()", "category": "bugfix", "topic": "semaphore", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_condition_while_notify", "use_threading.Semaphore_wrapper", "queue_based_tokens"]}
{"task_id": "osc_semaphore_005", "prompt": "Fix this semaphore: acquire decrements too early and release doesn't wake waiters reliably.", "signature": "class Semaphore:", "starter_code": "import threading\n\nclass Semaphore:\n    def __init__(self, value: int):\n        self.value = value\n        self.cond = threading.Condition()\n\n    def acquire(self):\n        with self.cond:\n            # Bug: decrements before waiting, goes negative\n            self.value -= 1\n            while self.value < 0:\n                self.cond.wait()\n\n    def release(self):\n        with self.cond:\n            self.value += 1\n            # Bug: notify only when value > 0 (should notify when a waiter may proceed)\n            if self.value > 0:\n                self.cond.notify()", "tests": "import threading\n\ndef test_semaphore_blocks_then_unblocks():\n    sem = Semaphore(1)\n    sem.acquire()\n\n    done = []\n    gate = threading.Event()\n\n    def worker():\n        sem.acquire()\n        done.append(\"ok\")\n        gate.set()\n        sem.release()\n\n    t = threading.Thread(target=worker)\n    t.start()\n    assert done == []\n    sem.release()\n    gate.wait(timeout=1)\n    assert done == [\"ok\"]\n    t.join(timeout=1)\n\ndef test_semaphore_acquire_release_roundtrip():\n    sem = Semaphore(1)\n    sem.acquire()\n    sem.release()\n    sem.acquire()\n    sem.release()", "category": "bugfix", "topic": "semaphore", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_counting_sem", "use_threading.Semaphore", "use_queue_tokens"]}
{"task_id": "osc_semaphore_006", "prompt": "Fix this semaphore: acquire waits on the wrong condition and can deadlock immediately.", "signature": "class Semaphore:", "starter_code": "import threading\nfrom collections import deque\n\nclass Semaphore:\n    def __init__(self, value: int):\n        self.tokens = deque([object() for _ in range(value)])\n        self.lock = threading.Lock()\n        self.cond = threading.Condition(self.lock)\n\n    def acquire(self):\n        with self.lock:\n            # Bug: waits while tokens exist (inverted condition)\n            while self.tokens:\n                self.cond.wait()\n            self.tokens.popleft()\n\n    def release(self):\n        with self.lock:\n            self.tokens.append(object())\n            self.cond.notify()", "tests": "import threading\n\ndef test_semaphore_single_token():\n    sem = Semaphore(1)\n    sem.acquire()\n    blocked = []\n    gate = threading.Event()\n\n    def worker():\n        sem.acquire()\n        blocked.append(False)\n        gate.set()\n        sem.release()\n\n    t = threading.Thread(target=worker)\n    t.start()\n    assert gate.is_set() is False\n    sem.release()\n    gate.wait(timeout=1)\n    assert gate.is_set() is True\n    t.join(timeout=1)\n\ndef test_semaphore_acquire_release_roundtrip():\n    sem = Semaphore(1)\n    sem.acquire()\n    sem.release()\n    sem.acquire()\n    sem.release()", "category": "bugfix", "topic": "semaphore", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_inverted_condition", "switch_to_counter_condition", "threading.Semaphore_wrapper"]}
{"task_id": "osc_semaphore_007", "prompt": "Fix this semaphore: wait/notify logic is broken and allows too many entrants or deadlocks.", "signature": "class Semaphore:", "starter_code": "import threading\n\nclass Semaphore:\n    def __init__(self, value: int):\n        self.value = value\n        self.lock = threading.Lock()\n        self.waiters = 0\n        self.cond = threading.Condition(self.lock)\n\n    def acquire(self):\n        with self.lock:\n            self.waiters += 1\n            # Bug: uses if instead of while; spurious wakeups break safety\n            if self.value <= 0:\n                self.cond.wait()\n            self.value -= 1\n            self.waiters -= 1\n\n    def release(self):\n        with self.lock:\n            self.value += 1\n            # Bug: not notifying when there are waiters\n            if self.waiters == 0:\n                self.cond.notify()", "tests": "import threading\n\ndef test_semaphore_limits_two():\n    sem = Semaphore(2)\n    entered = []\n    gate = threading.Event()\n    lock = threading.Lock()\n\n    def worker(i):\n        sem.acquire()\n        with lock:\n            entered.append(i)\n            if len(entered) == 2:\n                gate.set()\n        gate.wait()\n        sem.release()\n\n    ts = [threading.Thread(target=worker, args=(i,)) for i in range(3)]\n    for t in ts: t.start()\n    gate.wait()\n    with lock:\n        assert len(entered) == 2  # third must be blocked until release\n    for t in ts:\n        t.join(timeout=1)\n\ndef test_semaphore_acquire_release_roundtrip():\n    sem = Semaphore(1)\n    sem.acquire()\n    sem.release()\n    sem.acquire()\n    sem.release()", "category": "bugfix", "topic": "semaphore", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_condition_while_notify", "use_threading.Semaphore_wrapper", "queue_based_tokens"]}
{"task_id": "osc_semaphore_008", "prompt": "Fix this semaphore: acquire decrements too early and release doesn't wake waiters reliably.", "signature": "class Semaphore:", "starter_code": "import threading\n\nclass Semaphore:\n    def __init__(self, value: int):\n        self.value = value\n        self.cond = threading.Condition()\n\n    def acquire(self):\n        with self.cond:\n            # Bug: decrements before waiting, goes negative\n            self.value -= 1\n            while self.value < 0:\n                self.cond.wait()\n\n    def release(self):\n        with self.cond:\n            self.value += 1\n            # Bug: notify only when value > 0 (should notify when a waiter may proceed)\n            if self.value > 0:\n                self.cond.notify()", "tests": "import threading\n\ndef test_semaphore_blocks_then_unblocks():\n    sem = Semaphore(1)\n    sem.acquire()\n\n    done = []\n    gate = threading.Event()\n\n    def worker():\n        sem.acquire()\n        done.append(\"ok\")\n        gate.set()\n        sem.release()\n\n    t = threading.Thread(target=worker)\n    t.start()\n    assert done == []\n    sem.release()\n    gate.wait(timeout=1)\n    assert done == [\"ok\"]\n    t.join(timeout=1)\n\ndef test_semaphore_acquire_release_roundtrip():\n    sem = Semaphore(1)\n    sem.acquire()\n    sem.release()\n    sem.acquire()\n    sem.release()", "category": "bugfix", "topic": "semaphore", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_counting_sem", "use_threading.Semaphore", "use_queue_tokens"]}
{"task_id": "osc_semaphore_009", "prompt": "Fix this semaphore: acquire waits on the wrong condition and can deadlock immediately.", "signature": "class Semaphore:", "starter_code": "import threading\nfrom collections import deque\n\nclass Semaphore:\n    def __init__(self, value: int):\n        self.tokens = deque([object() for _ in range(value)])\n        self.lock = threading.Lock()\n        self.cond = threading.Condition(self.lock)\n\n    def acquire(self):\n        with self.lock:\n            # Bug: waits while tokens exist (inverted condition)\n            while self.tokens:\n                self.cond.wait()\n            self.tokens.popleft()\n\n    def release(self):\n        with self.lock:\n            self.tokens.append(object())\n            self.cond.notify()", "tests": "import threading\n\ndef test_semaphore_single_token():\n    sem = Semaphore(1)\n    sem.acquire()\n    blocked = []\n    gate = threading.Event()\n\n    def worker():\n        sem.acquire()\n        blocked.append(False)\n        gate.set()\n        sem.release()\n\n    t = threading.Thread(target=worker)\n    t.start()\n    assert gate.is_set() is False\n    sem.release()\n    gate.wait(timeout=1)\n    assert gate.is_set() is True\n    t.join(timeout=1)\n\ndef test_semaphore_acquire_release_roundtrip():\n    sem = Semaphore(1)\n    sem.acquire()\n    sem.release()\n    sem.acquire()\n    sem.release()", "category": "bugfix", "topic": "semaphore", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_inverted_condition", "switch_to_counter_condition", "threading.Semaphore_wrapper"]}
{"task_id": "osc_barrier_001", "prompt": "Fix this barrier: it only wakes one thread and breaks on reuse without generation tracking.", "signature": "class Barrier:", "starter_code": "import threading\n\nclass Barrier:\n    def __init__(self, parties: int):\n        self.parties = parties\n        self.count = 0\n        self.cond = threading.Condition()\n\n    def wait(self):\n        with self.cond:\n            self.count += 1\n            # Bug: uses notify instead of notify_all; some threads never wake\n            if self.count == self.parties:\n                self.cond.notify()\n                self.count = 0  # Bug: resets too early without generation tracking\n                return 0\n            self.cond.wait()\n            return self.count", "tests": "import threading\n\ndef test_barrier_releases_all():\n    b = Barrier(3)\n    passed = []\n    lock = threading.Lock()\n    gate = threading.Event()\n\n    def worker(i):\n        b.wait()\n        with lock:\n            passed.append(i)\n            if len(passed) == 3:\n                gate.set()\n\n    ts = [threading.Thread(target=worker, args=(i,)) for i in range(3)]\n    for t in ts: t.start()\n    gate.wait(timeout=1)\n    assert set(passed) == {0,1,2}\n    for t in ts: t.join(timeout=1)\n\ndef test_barrier_single_party():\n    b = Barrier(1)\n    assert b.wait() in (0, True, 1)", "category": "bugfix", "topic": "barrier", "tier": "oscillation", "starter_check": "fail", "approaches": ["generation_counter_barrier", "threading.Barrier_wrapper", "event_fanout"]}
{"task_id": "osc_barrier_002", "prompt": "Fix this barrier: wait predicate is wrong so threads can pass without all parties arriving.", "signature": "class Barrier:", "starter_code": "import threading\n\nclass Barrier:\n    def __init__(self, parties: int):\n        self.parties = parties\n        self.n = 0\n        self.g = 0\n        self.cond = threading.Condition()\n\n    def wait(self):\n        with self.cond:\n            gen = self.g\n            self.n += 1\n            if self.n == self.parties:\n                self.g += 1\n                self.n = 0\n                self.cond.notify_all()\n                return 0\n            # Bug: waits on wrong predicate; may proceed early\n            while self.g == gen:\n                break\n            return 1", "tests": "import threading\n\ndef test_barrier_blocks_until_all_arrive():\n    b = Barrier(2)\n    started = []\n    done = []\n    lock = threading.Lock()\n    gate = threading.Event()\n\n    def t1():\n        with lock:\n            started.append(1)\n        b.wait()\n        done.append(1)\n        gate.set()\n\n    th = threading.Thread(target=t1)\n    th.start()\n    assert started == [1]\n    assert done == []  # should still be waiting\n    b.wait()\n    gate.wait(timeout=1)\n    assert set(done) == {1}\n    th.join(timeout=1)\n\ndef test_barrier_single_party():\n    b = Barrier(1)\n    assert b.wait() in (0, True, 1)", "category": "bugfix", "topic": "barrier", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_wait_predicate", "use_threading.Barrier", "event_counter"]}
{"task_id": "osc_barrier_003", "prompt": "Fix this barrier: it is not thread-safe and isn't reusable across rounds.", "signature": "class Barrier:", "starter_code": "import threading\n\nclass Barrier:\n    def __init__(self, parties: int):\n        self.parties = parties\n        self.arrived = 0\n        self.event = threading.Event()\n\n    def wait(self):\n        self.arrived += 1  # Bug: not protected by lock\n        if self.arrived == self.parties:\n            self.event.set()\n            self.arrived = 0  # Bug: resets without clearing event\n        self.event.wait()\n        return True", "tests": "import threading\n\ndef test_barrier_reusable_two_rounds():\n    b = Barrier(2)\n    flags = []\n    lock = threading.Lock()\n\n    def worker():\n        b.wait()\n        with lock: flags.append(\"r1\")\n        b.wait()\n        with lock: flags.append(\"r2\")\n\n    t = threading.Thread(target=worker)\n    t.start()\n    b.wait()\n    b.wait()\n    t.join(timeout=1)\n    assert flags.count(\"r1\") == 1\n    assert flags.count(\"r2\") == 1\n\ndef test_barrier_single_party():\n    b = Barrier(1)\n    assert b.wait() in (0, True, 1)", "category": "bugfix", "topic": "barrier", "tier": "oscillation", "starter_check": "fail", "approaches": ["lock_and_generation", "threading.Barrier_wrapper", "condition_notify_all"]}
{"task_id": "osc_barrier_004", "prompt": "Fix this barrier: it only wakes one thread and breaks on reuse without generation tracking.", "signature": "class Barrier:", "starter_code": "import threading\n\nclass Barrier:\n    def __init__(self, parties: int):\n        self.parties = parties\n        self.count = 0\n        self.cond = threading.Condition()\n\n    def wait(self):\n        with self.cond:\n            self.count += 1\n            # Bug: uses notify instead of notify_all; some threads never wake\n            if self.count == self.parties:\n                self.cond.notify()\n                self.count = 0  # Bug: resets too early without generation tracking\n                return 0\n            self.cond.wait()\n            return self.count", "tests": "import threading\n\ndef test_barrier_releases_all():\n    b = Barrier(3)\n    passed = []\n    lock = threading.Lock()\n    gate = threading.Event()\n\n    def worker(i):\n        b.wait()\n        with lock:\n            passed.append(i)\n            if len(passed) == 3:\n                gate.set()\n\n    ts = [threading.Thread(target=worker, args=(i,)) for i in range(3)]\n    for t in ts: t.start()\n    gate.wait(timeout=1)\n    assert set(passed) == {0,1,2}\n    for t in ts: t.join(timeout=1)\n\ndef test_barrier_single_party():\n    b = Barrier(1)\n    assert b.wait() in (0, True, 1)", "category": "bugfix", "topic": "barrier", "tier": "oscillation", "starter_check": "fail", "approaches": ["generation_counter_barrier", "threading.Barrier_wrapper", "event_fanout"]}
{"task_id": "osc_barrier_005", "prompt": "Fix this barrier: wait predicate is wrong so threads can pass without all parties arriving.", "signature": "class Barrier:", "starter_code": "import threading\n\nclass Barrier:\n    def __init__(self, parties: int):\n        self.parties = parties\n        self.n = 0\n        self.g = 0\n        self.cond = threading.Condition()\n\n    def wait(self):\n        with self.cond:\n            gen = self.g\n            self.n += 1\n            if self.n == self.parties:\n                self.g += 1\n                self.n = 0\n                self.cond.notify_all()\n                return 0\n            # Bug: waits on wrong predicate; may proceed early\n            while self.g == gen:\n                break\n            return 1", "tests": "import threading\n\ndef test_barrier_blocks_until_all_arrive():\n    b = Barrier(2)\n    started = []\n    done = []\n    lock = threading.Lock()\n    gate = threading.Event()\n\n    def t1():\n        with lock:\n            started.append(1)\n        b.wait()\n        done.append(1)\n        gate.set()\n\n    th = threading.Thread(target=t1)\n    th.start()\n    assert started == [1]\n    assert done == []  # should still be waiting\n    b.wait()\n    gate.wait(timeout=1)\n    assert set(done) == {1}\n    th.join(timeout=1)\n\ndef test_barrier_single_party():\n    b = Barrier(1)\n    assert b.wait() in (0, True, 1)", "category": "bugfix", "topic": "barrier", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_wait_predicate", "use_threading.Barrier", "event_counter"]}
{"task_id": "osc_barrier_006", "prompt": "Fix this barrier: it is not thread-safe and isn't reusable across rounds.", "signature": "class Barrier:", "starter_code": "import threading\n\nclass Barrier:\n    def __init__(self, parties: int):\n        self.parties = parties\n        self.arrived = 0\n        self.event = threading.Event()\n\n    def wait(self):\n        self.arrived += 1  # Bug: not protected by lock\n        if self.arrived == self.parties:\n            self.event.set()\n            self.arrived = 0  # Bug: resets without clearing event\n        self.event.wait()\n        return True", "tests": "import threading\n\ndef test_barrier_reusable_two_rounds():\n    b = Barrier(2)\n    flags = []\n    lock = threading.Lock()\n\n    def worker():\n        b.wait()\n        with lock: flags.append(\"r1\")\n        b.wait()\n        with lock: flags.append(\"r2\")\n\n    t = threading.Thread(target=worker)\n    t.start()\n    b.wait()\n    b.wait()\n    t.join(timeout=1)\n    assert flags.count(\"r1\") == 1\n    assert flags.count(\"r2\") == 1\n\ndef test_barrier_single_party():\n    b = Barrier(1)\n    assert b.wait() in (0, True, 1)", "category": "bugfix", "topic": "barrier", "tier": "oscillation", "starter_check": "fail", "approaches": ["lock_and_generation", "threading.Barrier_wrapper", "condition_notify_all"]}
{"task_id": "osc_barrier_007", "prompt": "Fix this barrier: it only wakes one thread and breaks on reuse without generation tracking.", "signature": "class Barrier:", "starter_code": "import threading\n\nclass Barrier:\n    def __init__(self, parties: int):\n        self.parties = parties\n        self.count = 0\n        self.cond = threading.Condition()\n\n    def wait(self):\n        with self.cond:\n            self.count += 1\n            # Bug: uses notify instead of notify_all; some threads never wake\n            if self.count == self.parties:\n                self.cond.notify()\n                self.count = 0  # Bug: resets too early without generation tracking\n                return 0\n            self.cond.wait()\n            return self.count", "tests": "import threading\n\ndef test_barrier_releases_all():\n    b = Barrier(3)\n    passed = []\n    lock = threading.Lock()\n    gate = threading.Event()\n\n    def worker(i):\n        b.wait()\n        with lock:\n            passed.append(i)\n            if len(passed) == 3:\n                gate.set()\n\n    ts = [threading.Thread(target=worker, args=(i,)) for i in range(3)]\n    for t in ts: t.start()\n    gate.wait(timeout=1)\n    assert set(passed) == {0,1,2}\n    for t in ts: t.join(timeout=1)\n\ndef test_barrier_single_party():\n    b = Barrier(1)\n    assert b.wait() in (0, True, 1)", "category": "bugfix", "topic": "barrier", "tier": "oscillation", "starter_check": "fail", "approaches": ["generation_counter_barrier", "threading.Barrier_wrapper", "event_fanout"]}
{"task_id": "osc_barrier_008", "prompt": "Fix this barrier: wait predicate is wrong so threads can pass without all parties arriving.", "signature": "class Barrier:", "starter_code": "import threading\n\nclass Barrier:\n    def __init__(self, parties: int):\n        self.parties = parties\n        self.n = 0\n        self.g = 0\n        self.cond = threading.Condition()\n\n    def wait(self):\n        with self.cond:\n            gen = self.g\n            self.n += 1\n            if self.n == self.parties:\n                self.g += 1\n                self.n = 0\n                self.cond.notify_all()\n                return 0\n            # Bug: waits on wrong predicate; may proceed early\n            while self.g == gen:\n                break\n            return 1", "tests": "import threading\n\ndef test_barrier_blocks_until_all_arrive():\n    b = Barrier(2)\n    started = []\n    done = []\n    lock = threading.Lock()\n    gate = threading.Event()\n\n    def t1():\n        with lock:\n            started.append(1)\n        b.wait()\n        done.append(1)\n        gate.set()\n\n    th = threading.Thread(target=t1)\n    th.start()\n    assert started == [1]\n    assert done == []  # should still be waiting\n    b.wait()\n    gate.wait(timeout=1)\n    assert set(done) == {1}\n    th.join(timeout=1)\n\ndef test_barrier_single_party():\n    b = Barrier(1)\n    assert b.wait() in (0, True, 1)", "category": "bugfix", "topic": "barrier", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_wait_predicate", "use_threading.Barrier", "event_counter"]}
{"task_id": "osc_barrier_009", "prompt": "Fix this barrier: it is not thread-safe and isn't reusable across rounds.", "signature": "class Barrier:", "starter_code": "import threading\n\nclass Barrier:\n    def __init__(self, parties: int):\n        self.parties = parties\n        self.arrived = 0\n        self.event = threading.Event()\n\n    def wait(self):\n        self.arrived += 1  # Bug: not protected by lock\n        if self.arrived == self.parties:\n            self.event.set()\n            self.arrived = 0  # Bug: resets without clearing event\n        self.event.wait()\n        return True", "tests": "import threading\n\ndef test_barrier_reusable_two_rounds():\n    b = Barrier(2)\n    flags = []\n    lock = threading.Lock()\n\n    def worker():\n        b.wait()\n        with lock: flags.append(\"r1\")\n        b.wait()\n        with lock: flags.append(\"r2\")\n\n    t = threading.Thread(target=worker)\n    t.start()\n    b.wait()\n    b.wait()\n    t.join(timeout=1)\n    assert flags.count(\"r1\") == 1\n    assert flags.count(\"r2\") == 1\n\ndef test_barrier_single_party():\n    b = Barrier(1)\n    assert b.wait() in (0, True, 1)", "category": "bugfix", "topic": "barrier", "tier": "oscillation", "starter_check": "fail", "approaches": ["lock_and_generation", "threading.Barrier_wrapper", "condition_notify_all"]}
{"task_id": "osc_read_write_lock_001", "prompt": "Fix this read-write lock: readers don't synchronize with writers and release logic is wrong.", "signature": "class ReadWriteLock:", "starter_code": "import threading\n\nclass ReadWriteLock:\n    def __init__(self):\n        self.readers = 0\n        self.lock = threading.Lock()\n        self.writer = threading.Lock()\n\n    def acquire_read(self):\n        with self.lock:\n            self.readers += 1\n            # Bug: forgets to block writers on first reader\n            if self.readers == 0:\n                self.writer.acquire()\n\n    def release_read(self):\n        with self.lock:\n            self.readers -= 1\n            # Bug: releases writer lock too early (on readers==1)\n            if self.readers == 1:\n                self.writer.release()\n\n    def acquire_write(self):\n        self.writer.acquire()\n\n    def release_write(self):\n        self.writer.release()", "tests": "import threading\n\ndef test_rwlock_writer_excludes_readers():\n    rw = ReadWriteLock()\n    entered = []\n    gate = threading.Event()\n\n    def writer():\n        rw.acquire_write()\n        entered.append(\"w\")\n        gate.wait()\n        rw.release_write()\n\n    def reader():\n        rw.acquire_read()\n        entered.append(\"r\")\n        rw.release_read()\n\n    tw = threading.Thread(target=writer)\n    tr = threading.Thread(target=reader)\n    tw.start()\n    # ensure writer acquires first\n    while entered == []:\n        pass\n    tr.start()\n    # reader should not enter until writer releases\n    assert entered == [\"w\"]\n    gate.set()\n    tw.join(timeout=1); tr.join(timeout=1)\n    assert \"r\" in entered\n\ndef test_rwlock_read_then_write():\n    rw = ReadWriteLock()\n    rw.acquire_read()\n    rw.release_read()\n    rw.acquire_write()\n    rw.release_write()", "category": "bugfix", "topic": "read_write_lock", "tier": "oscillation", "starter_check": "fail", "approaches": ["condition_based_rwlock", "two_lock_first_reader_last_reader_fixed", "single_lock_with_counter"]}
{"task_id": "osc_read_write_lock_002", "prompt": "Fix this read-write lock: writers don't wait for active readers.", "signature": "class ReadWriteLock:", "starter_code": "import threading\n\nclass ReadWriteLock:\n    def __init__(self):\n        self._lock = threading.Lock()\n        self._cond = threading.Condition(self._lock)\n        self._readers = 0\n        self._writer = False\n\n    def acquire_read(self):\n        with self._lock:\n            # Bug: allows new readers even when writer waiting/active\n            while self._writer:\n                self._cond.wait()\n            self._readers += 1\n\n    def release_read(self):\n        with self._lock:\n            self._readers -= 1\n            if self._readers == 0:\n                self._cond.notify()\n\n    def acquire_write(self):\n        with self._lock:\n            # Bug: waits only for writer flag, not readers\n            while self._writer:\n                self._cond.wait()\n            self._writer = True\n\n    def release_write(self):\n        with self._lock:\n            self._writer = False\n            self._cond.notify_all()", "tests": "import threading\n\ndef test_rwlock_writer_waits_for_readers():\n    rw = ReadWriteLock()\n    rw.acquire_read()\n\n    acquired = []\n    gate = threading.Event()\n\n    def writer():\n        rw.acquire_write()\n        acquired.append(\"w\")\n        gate.set()\n        rw.release_write()\n\n    t = threading.Thread(target=writer)\n    t.start()\n    assert acquired == []\n    rw.release_read()\n    gate.wait(timeout=1)\n    assert acquired == [\"w\"]\n    t.join(timeout=1)\n\ndef test_rwlock_read_then_write():\n    rw = ReadWriteLock()\n    rw.acquire_read()\n    rw.release_read()\n    rw.acquire_write()\n    rw.release_write()", "category": "bugfix", "topic": "read_write_lock", "tier": "oscillation", "starter_check": "fail", "approaches": ["wait_for_readers_and_writer", "writer_preference_flag", "simple_lock_only"]}
{"task_id": "osc_read_write_lock_003", "prompt": "Fix this read-write lock: acquire_read never releases its mutex and deadlocks other readers.", "signature": "class ReadWriteLock:", "starter_code": "import threading\n\nclass ReadWriteLock:\n    def __init__(self):\n        self._read_lock = threading.Lock()\n        self._write_lock = threading.Lock()\n        self._readers = 0\n\n    def acquire_read(self):\n        self._read_lock.acquire()\n        self._readers += 1\n        if self._readers == 1:\n            self._write_lock.acquire()\n        # Bug: forgets to release read_lock\n        # self._read_lock.release()\n\n    def release_read(self):\n        self._read_lock.acquire()\n        self._readers -= 1\n        if self._readers == 0:\n            self._write_lock.release()\n        self._read_lock.release()\n\n    def acquire_write(self):\n        self._write_lock.acquire()\n\n    def release_write(self):\n        self._write_lock.release()", "tests": "import threading\n\ndef test_rwlock_multiple_readers_no_deadlock():\n    rw = ReadWriteLock()\n    ok = []\n\n    def reader():\n        rw.acquire_read()\n        ok.append(1)\n        rw.release_read()\n\n    ts = [threading.Thread(target=reader) for _ in range(3)]\n    for t in ts: t.start()\n    for t in ts: t.join(timeout=1)\n    assert len(ok) == 3\n\ndef test_rwlock_read_then_write():\n    rw = ReadWriteLock()\n    rw.acquire_read()\n    rw.release_read()\n    rw.acquire_write()\n    rw.release_write()", "category": "bugfix", "topic": "read_write_lock", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_missing_release", "use_condition_rwlock", "use_rlock_and_counter"]}
{"task_id": "osc_read_write_lock_004", "prompt": "Fix this read-write lock: readers don't synchronize with writers and release logic is wrong.", "signature": "class ReadWriteLock:", "starter_code": "import threading\n\nclass ReadWriteLock:\n    def __init__(self):\n        self.readers = 0\n        self.lock = threading.Lock()\n        self.writer = threading.Lock()\n\n    def acquire_read(self):\n        with self.lock:\n            self.readers += 1\n            # Bug: forgets to block writers on first reader\n            if self.readers == 0:\n                self.writer.acquire()\n\n    def release_read(self):\n        with self.lock:\n            self.readers -= 1\n            # Bug: releases writer lock too early (on readers==1)\n            if self.readers == 1:\n                self.writer.release()\n\n    def acquire_write(self):\n        self.writer.acquire()\n\n    def release_write(self):\n        self.writer.release()", "tests": "import threading\n\ndef test_rwlock_writer_excludes_readers():\n    rw = ReadWriteLock()\n    entered = []\n    gate = threading.Event()\n\n    def writer():\n        rw.acquire_write()\n        entered.append(\"w\")\n        gate.wait()\n        rw.release_write()\n\n    def reader():\n        rw.acquire_read()\n        entered.append(\"r\")\n        rw.release_read()\n\n    tw = threading.Thread(target=writer)\n    tr = threading.Thread(target=reader)\n    tw.start()\n    # ensure writer acquires first\n    while entered == []:\n        pass\n    tr.start()\n    # reader should not enter until writer releases\n    assert entered == [\"w\"]\n    gate.set()\n    tw.join(timeout=1); tr.join(timeout=1)\n    assert \"r\" in entered\n\ndef test_rwlock_read_then_write():\n    rw = ReadWriteLock()\n    rw.acquire_read()\n    rw.release_read()\n    rw.acquire_write()\n    rw.release_write()", "category": "bugfix", "topic": "read_write_lock", "tier": "oscillation", "starter_check": "fail", "approaches": ["condition_based_rwlock", "two_lock_first_reader_last_reader_fixed", "single_lock_with_counter"]}
{"task_id": "osc_read_write_lock_005", "prompt": "Fix this read-write lock: writers don't wait for active readers.", "signature": "class ReadWriteLock:", "starter_code": "import threading\n\nclass ReadWriteLock:\n    def __init__(self):\n        self._lock = threading.Lock()\n        self._cond = threading.Condition(self._lock)\n        self._readers = 0\n        self._writer = False\n\n    def acquire_read(self):\n        with self._lock:\n            # Bug: allows new readers even when writer waiting/active\n            while self._writer:\n                self._cond.wait()\n            self._readers += 1\n\n    def release_read(self):\n        with self._lock:\n            self._readers -= 1\n            if self._readers == 0:\n                self._cond.notify()\n\n    def acquire_write(self):\n        with self._lock:\n            # Bug: waits only for writer flag, not readers\n            while self._writer:\n                self._cond.wait()\n            self._writer = True\n\n    def release_write(self):\n        with self._lock:\n            self._writer = False\n            self._cond.notify_all()", "tests": "import threading\n\ndef test_rwlock_writer_waits_for_readers():\n    rw = ReadWriteLock()\n    rw.acquire_read()\n\n    acquired = []\n    gate = threading.Event()\n\n    def writer():\n        rw.acquire_write()\n        acquired.append(\"w\")\n        gate.set()\n        rw.release_write()\n\n    t = threading.Thread(target=writer)\n    t.start()\n    assert acquired == []\n    rw.release_read()\n    gate.wait(timeout=1)\n    assert acquired == [\"w\"]\n    t.join(timeout=1)\n\ndef test_rwlock_read_then_write():\n    rw = ReadWriteLock()\n    rw.acquire_read()\n    rw.release_read()\n    rw.acquire_write()\n    rw.release_write()", "category": "bugfix", "topic": "read_write_lock", "tier": "oscillation", "starter_check": "fail", "approaches": ["wait_for_readers_and_writer", "writer_preference_flag", "simple_lock_only"]}
{"task_id": "osc_read_write_lock_006", "prompt": "Fix this read-write lock: acquire_read never releases its mutex and deadlocks other readers.", "signature": "class ReadWriteLock:", "starter_code": "import threading\n\nclass ReadWriteLock:\n    def __init__(self):\n        self._read_lock = threading.Lock()\n        self._write_lock = threading.Lock()\n        self._readers = 0\n\n    def acquire_read(self):\n        self._read_lock.acquire()\n        self._readers += 1\n        if self._readers == 1:\n            self._write_lock.acquire()\n        # Bug: forgets to release read_lock\n        # self._read_lock.release()\n\n    def release_read(self):\n        self._read_lock.acquire()\n        self._readers -= 1\n        if self._readers == 0:\n            self._write_lock.release()\n        self._read_lock.release()\n\n    def acquire_write(self):\n        self._write_lock.acquire()\n\n    def release_write(self):\n        self._write_lock.release()", "tests": "import threading\n\ndef test_rwlock_multiple_readers_no_deadlock():\n    rw = ReadWriteLock()\n    ok = []\n\n    def reader():\n        rw.acquire_read()\n        ok.append(1)\n        rw.release_read()\n\n    ts = [threading.Thread(target=reader) for _ in range(3)]\n    for t in ts: t.start()\n    for t in ts: t.join(timeout=1)\n    assert len(ok) == 3\n\ndef test_rwlock_read_then_write():\n    rw = ReadWriteLock()\n    rw.acquire_read()\n    rw.release_read()\n    rw.acquire_write()\n    rw.release_write()", "category": "bugfix", "topic": "read_write_lock", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_missing_release", "use_condition_rwlock", "use_rlock_and_counter"]}
{"task_id": "osc_read_write_lock_007", "prompt": "Fix this read-write lock: readers don't synchronize with writers and release logic is wrong.", "signature": "class ReadWriteLock:", "starter_code": "import threading\n\nclass ReadWriteLock:\n    def __init__(self):\n        self.readers = 0\n        self.lock = threading.Lock()\n        self.writer = threading.Lock()\n\n    def acquire_read(self):\n        with self.lock:\n            self.readers += 1\n            # Bug: forgets to block writers on first reader\n            if self.readers == 0:\n                self.writer.acquire()\n\n    def release_read(self):\n        with self.lock:\n            self.readers -= 1\n            # Bug: releases writer lock too early (on readers==1)\n            if self.readers == 1:\n                self.writer.release()\n\n    def acquire_write(self):\n        self.writer.acquire()\n\n    def release_write(self):\n        self.writer.release()", "tests": "import threading\n\ndef test_rwlock_writer_excludes_readers():\n    rw = ReadWriteLock()\n    entered = []\n    gate = threading.Event()\n\n    def writer():\n        rw.acquire_write()\n        entered.append(\"w\")\n        gate.wait()\n        rw.release_write()\n\n    def reader():\n        rw.acquire_read()\n        entered.append(\"r\")\n        rw.release_read()\n\n    tw = threading.Thread(target=writer)\n    tr = threading.Thread(target=reader)\n    tw.start()\n    # ensure writer acquires first\n    while entered == []:\n        pass\n    tr.start()\n    # reader should not enter until writer releases\n    assert entered == [\"w\"]\n    gate.set()\n    tw.join(timeout=1); tr.join(timeout=1)\n    assert \"r\" in entered\n\ndef test_rwlock_read_then_write():\n    rw = ReadWriteLock()\n    rw.acquire_read()\n    rw.release_read()\n    rw.acquire_write()\n    rw.release_write()", "category": "bugfix", "topic": "read_write_lock", "tier": "oscillation", "starter_check": "fail", "approaches": ["condition_based_rwlock", "two_lock_first_reader_last_reader_fixed", "single_lock_with_counter"]}
{"task_id": "osc_read_write_lock_008", "prompt": "Fix this read-write lock: writers don't wait for active readers.", "signature": "class ReadWriteLock:", "starter_code": "import threading\n\nclass ReadWriteLock:\n    def __init__(self):\n        self._lock = threading.Lock()\n        self._cond = threading.Condition(self._lock)\n        self._readers = 0\n        self._writer = False\n\n    def acquire_read(self):\n        with self._lock:\n            # Bug: allows new readers even when writer waiting/active\n            while self._writer:\n                self._cond.wait()\n            self._readers += 1\n\n    def release_read(self):\n        with self._lock:\n            self._readers -= 1\n            if self._readers == 0:\n                self._cond.notify()\n\n    def acquire_write(self):\n        with self._lock:\n            # Bug: waits only for writer flag, not readers\n            while self._writer:\n                self._cond.wait()\n            self._writer = True\n\n    def release_write(self):\n        with self._lock:\n            self._writer = False\n            self._cond.notify_all()", "tests": "import threading\n\ndef test_rwlock_writer_waits_for_readers():\n    rw = ReadWriteLock()\n    rw.acquire_read()\n\n    acquired = []\n    gate = threading.Event()\n\n    def writer():\n        rw.acquire_write()\n        acquired.append(\"w\")\n        gate.set()\n        rw.release_write()\n\n    t = threading.Thread(target=writer)\n    t.start()\n    assert acquired == []\n    rw.release_read()\n    gate.wait(timeout=1)\n    assert acquired == [\"w\"]\n    t.join(timeout=1)\n\ndef test_rwlock_read_then_write():\n    rw = ReadWriteLock()\n    rw.acquire_read()\n    rw.release_read()\n    rw.acquire_write()\n    rw.release_write()", "category": "bugfix", "topic": "read_write_lock", "tier": "oscillation", "starter_check": "fail", "approaches": ["wait_for_readers_and_writer", "writer_preference_flag", "simple_lock_only"]}
{"task_id": "osc_read_write_lock_009", "prompt": "Fix this read-write lock: acquire_read never releases its mutex and deadlocks other readers.", "signature": "class ReadWriteLock:", "starter_code": "import threading\n\nclass ReadWriteLock:\n    def __init__(self):\n        self._read_lock = threading.Lock()\n        self._write_lock = threading.Lock()\n        self._readers = 0\n\n    def acquire_read(self):\n        self._read_lock.acquire()\n        self._readers += 1\n        if self._readers == 1:\n            self._write_lock.acquire()\n        # Bug: forgets to release read_lock\n        # self._read_lock.release()\n\n    def release_read(self):\n        self._read_lock.acquire()\n        self._readers -= 1\n        if self._readers == 0:\n            self._write_lock.release()\n        self._read_lock.release()\n\n    def acquire_write(self):\n        self._write_lock.acquire()\n\n    def release_write(self):\n        self._write_lock.release()", "tests": "import threading\n\ndef test_rwlock_multiple_readers_no_deadlock():\n    rw = ReadWriteLock()\n    ok = []\n\n    def reader():\n        rw.acquire_read()\n        ok.append(1)\n        rw.release_read()\n\n    ts = [threading.Thread(target=reader) for _ in range(3)]\n    for t in ts: t.start()\n    for t in ts: t.join(timeout=1)\n    assert len(ok) == 3\n\ndef test_rwlock_read_then_write():\n    rw = ReadWriteLock()\n    rw.acquire_read()\n    rw.release_read()\n    rw.acquire_write()\n    rw.release_write()", "category": "bugfix", "topic": "read_write_lock", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_missing_release", "use_condition_rwlock", "use_rlock_and_counter"]}
{"task_id": "osc_actor_mailbox_001", "prompt": "Fix this actor mailbox: mixed mailbox structures lose messages and recv returns LIFO.", "signature": "class Actor:", "starter_code": "from collections import deque\n\nclass Actor:\n    def __init__(self):\n        self.mailbox = []     # list approach\n        self.q = deque()      # deque approach\n\n    def send(self, msg):\n        # Bug: stores into both; drain reads only one -> lost msgs\n        self.mailbox.append(msg)\n        self.q.append(msg)\n\n    def recv(self):\n        # Bug: pops from right (LIFO) but should be FIFO\n        if self.mailbox:\n            return self.mailbox.pop()\n        if self.q:\n            return self.q.popleft()\n        return None\n\n    def drain(self):\n        out = []\n        while True:\n            m = self.recv()\n            if m is None:\n                break\n            out.append(m)\n        return out", "tests": "def test_actor_fifo_order():\n    a = Actor()\n    for m in [\"a\",\"b\",\"c\"]:\n        a.send(m)\n    assert a.drain() == [\"a\",\"b\",\"c\"]\n\ndef test_actor_recv_none_when_empty():\n    a = Actor()\n    assert a.recv() is None", "category": "bugfix", "topic": "actor_mailbox", "tier": "oscillation", "starter_check": "fail", "approaches": ["deque_only_fifo", "list_with_head_index", "queue_module_queue"]}
{"task_id": "osc_actor_mailbox_002", "prompt": "Fix this actor mailbox: recv is LIFO and locking is inconsistent.", "signature": "class Actor:", "starter_code": "import threading\nfrom collections import deque\n\nclass Actor:\n    def __init__(self):\n        self._q = deque()\n        self._lock = threading.Lock()\n\n    def send(self, msg):\n        # Bug: missing lock, data race\n        self._q.append(msg)\n\n    def recv(self):\n        with self._lock:\n            if not self._q:\n                return None\n            return self._q.pop()  # Bug: LIFO\n\n    def __len__(self):\n        with self._lock:\n            return len(self._q)", "tests": "def test_actor_len_and_fifo():\n    a = Actor()\n    a.send(1); a.send(2); a.send(3)\n    assert len(a) == 3\n    assert a.recv() == 1\n    assert a.recv() == 2\n\ndef test_actor_mailbox_smoke():\n    pass", "category": "bugfix", "topic": "actor_mailbox", "tier": "oscillation", "starter_check": "fail", "approaches": ["popleft_fifo", "queue.Queue", "lock_free_deque_with_condition"]}
{"task_id": "osc_actor_mailbox_003", "prompt": "Fix this dispatcher mailbox: it delivers messages in LIFO order instead of FIFO.", "signature": "class Dispatcher:", "starter_code": "import threading\n\nclass Dispatcher:\n    def __init__(self):\n        self.boxes = {}\n        self.lock = threading.Lock()\n\n    def send(self, actor_id, msg):\n        with self.lock:\n            self.boxes.setdefault(actor_id, []).append(msg)\n\n    def recv(self, actor_id):\n        with self.lock:\n            box = self.boxes.get(actor_id, [])\n            if not box:\n                return None\n            # Bug: removes from end => LIFO\n            return box.pop()\n\n    def drain(self, actor_id):\n        out = []\n        while True:\n            m = self.recv(actor_id)\n            if m is None:\n                return out\n            out.append(m)", "tests": "def test_dispatcher_fifo_per_actor():\n    d = Dispatcher()\n    d.send(\"A\", \"a1\"); d.send(\"A\", \"a2\")\n    d.send(\"B\", \"b1\"); d.send(\"B\", \"b2\")\n    assert d.drain(\"A\") == [\"a1\",\"a2\"]\n    assert d.drain(\"B\") == [\"b1\",\"b2\"]\n\ndef test_actor_mailbox_smoke():\n    pass", "category": "bugfix", "topic": "actor_mailbox", "tier": "oscillation", "starter_check": "fail", "approaches": ["pop_left_fifo", "deque_per_actor", "index_pointer_per_actor"]}
{"task_id": "osc_actor_mailbox_004", "prompt": "Fix this actor mailbox: mixed mailbox structures lose messages and recv returns LIFO.", "signature": "class Actor:", "starter_code": "from collections import deque\n\nclass Actor:\n    def __init__(self):\n        self.mailbox = []     # list approach\n        self.q = deque()      # deque approach\n\n    def send(self, msg):\n        # Bug: stores into both; drain reads only one -> lost msgs\n        self.mailbox.append(msg)\n        self.q.append(msg)\n\n    def recv(self):\n        # Bug: pops from right (LIFO) but should be FIFO\n        if self.mailbox:\n            return self.mailbox.pop()\n        if self.q:\n            return self.q.popleft()\n        return None\n\n    def drain(self):\n        out = []\n        while True:\n            m = self.recv()\n            if m is None:\n                break\n            out.append(m)\n        return out", "tests": "def test_actor_fifo_order():\n    a = Actor()\n    for m in [\"a\",\"b\",\"c\"]:\n        a.send(m)\n    assert a.drain() == [\"a\",\"b\",\"c\"]\n\ndef test_actor_recv_none_when_empty():\n    a = Actor()\n    assert a.recv() is None", "category": "bugfix", "topic": "actor_mailbox", "tier": "oscillation", "starter_check": "fail", "approaches": ["deque_only_fifo", "list_with_head_index", "queue_module_queue"]}
{"task_id": "osc_actor_mailbox_005", "prompt": "Fix this actor mailbox: recv is LIFO and locking is inconsistent.", "signature": "class Actor:", "starter_code": "import threading\nfrom collections import deque\n\nclass Actor:\n    def __init__(self):\n        self._q = deque()\n        self._lock = threading.Lock()\n\n    def send(self, msg):\n        # Bug: missing lock, data race\n        self._q.append(msg)\n\n    def recv(self):\n        with self._lock:\n            if not self._q:\n                return None\n            return self._q.pop()  # Bug: LIFO\n\n    def __len__(self):\n        with self._lock:\n            return len(self._q)", "tests": "def test_actor_len_and_fifo():\n    a = Actor()\n    a.send(1); a.send(2); a.send(3)\n    assert len(a) == 3\n    assert a.recv() == 1\n    assert a.recv() == 2\n\ndef test_actor_mailbox_smoke():\n    pass", "category": "bugfix", "topic": "actor_mailbox", "tier": "oscillation", "starter_check": "fail", "approaches": ["popleft_fifo", "queue.Queue", "lock_free_deque_with_condition"]}
{"task_id": "osc_actor_mailbox_006", "prompt": "Fix this dispatcher mailbox: it delivers messages in LIFO order instead of FIFO.", "signature": "class Dispatcher:", "starter_code": "import threading\n\nclass Dispatcher:\n    def __init__(self):\n        self.boxes = {}\n        self.lock = threading.Lock()\n\n    def send(self, actor_id, msg):\n        with self.lock:\n            self.boxes.setdefault(actor_id, []).append(msg)\n\n    def recv(self, actor_id):\n        with self.lock:\n            box = self.boxes.get(actor_id, [])\n            if not box:\n                return None\n            # Bug: removes from end => LIFO\n            return box.pop()\n\n    def drain(self, actor_id):\n        out = []\n        while True:\n            m = self.recv(actor_id)\n            if m is None:\n                return out\n            out.append(m)", "tests": "def test_dispatcher_fifo_per_actor():\n    d = Dispatcher()\n    d.send(\"A\", \"a1\"); d.send(\"A\", \"a2\")\n    d.send(\"B\", \"b1\"); d.send(\"B\", \"b2\")\n    assert d.drain(\"A\") == [\"a1\",\"a2\"]\n    assert d.drain(\"B\") == [\"b1\",\"b2\"]\n\ndef test_actor_mailbox_smoke():\n    pass", "category": "bugfix", "topic": "actor_mailbox", "tier": "oscillation", "starter_check": "fail", "approaches": ["pop_left_fifo", "deque_per_actor", "index_pointer_per_actor"]}
{"task_id": "osc_actor_mailbox_007", "prompt": "Fix this actor mailbox: mixed mailbox structures lose messages and recv returns LIFO.", "signature": "class Actor:", "starter_code": "from collections import deque\n\nclass Actor:\n    def __init__(self):\n        self.mailbox = []     # list approach\n        self.q = deque()      # deque approach\n\n    def send(self, msg):\n        # Bug: stores into both; drain reads only one -> lost msgs\n        self.mailbox.append(msg)\n        self.q.append(msg)\n\n    def recv(self):\n        # Bug: pops from right (LIFO) but should be FIFO\n        if self.mailbox:\n            return self.mailbox.pop()\n        if self.q:\n            return self.q.popleft()\n        return None\n\n    def drain(self):\n        out = []\n        while True:\n            m = self.recv()\n            if m is None:\n                break\n            out.append(m)\n        return out", "tests": "def test_actor_fifo_order():\n    a = Actor()\n    for m in [\"a\",\"b\",\"c\"]:\n        a.send(m)\n    assert a.drain() == [\"a\",\"b\",\"c\"]\n\ndef test_actor_recv_none_when_empty():\n    a = Actor()\n    assert a.recv() is None", "category": "bugfix", "topic": "actor_mailbox", "tier": "oscillation", "starter_check": "fail", "approaches": ["deque_only_fifo", "list_with_head_index", "queue_module_queue"]}
{"task_id": "osc_actor_mailbox_008", "prompt": "Fix this actor mailbox: recv is LIFO and locking is inconsistent.", "signature": "class Actor:", "starter_code": "import threading\nfrom collections import deque\n\nclass Actor:\n    def __init__(self):\n        self._q = deque()\n        self._lock = threading.Lock()\n\n    def send(self, msg):\n        # Bug: missing lock, data race\n        self._q.append(msg)\n\n    def recv(self):\n        with self._lock:\n            if not self._q:\n                return None\n            return self._q.pop()  # Bug: LIFO\n\n    def __len__(self):\n        with self._lock:\n            return len(self._q)", "tests": "def test_actor_len_and_fifo():\n    a = Actor()\n    a.send(1); a.send(2); a.send(3)\n    assert len(a) == 3\n    assert a.recv() == 1\n    assert a.recv() == 2\n\ndef test_actor_mailbox_smoke():\n    pass", "category": "bugfix", "topic": "actor_mailbox", "tier": "oscillation", "starter_check": "fail", "approaches": ["popleft_fifo", "queue.Queue", "lock_free_deque_with_condition"]}
{"task_id": "osc_actor_mailbox_009", "prompt": "Fix this dispatcher mailbox: it delivers messages in LIFO order instead of FIFO.", "signature": "class Dispatcher:", "starter_code": "import threading\n\nclass Dispatcher:\n    def __init__(self):\n        self.boxes = {}\n        self.lock = threading.Lock()\n\n    def send(self, actor_id, msg):\n        with self.lock:\n            self.boxes.setdefault(actor_id, []).append(msg)\n\n    def recv(self, actor_id):\n        with self.lock:\n            box = self.boxes.get(actor_id, [])\n            if not box:\n                return None\n            # Bug: removes from end => LIFO\n            return box.pop()\n\n    def drain(self, actor_id):\n        out = []\n        while True:\n            m = self.recv(actor_id)\n            if m is None:\n                return out\n            out.append(m)", "tests": "def test_dispatcher_fifo_per_actor():\n    d = Dispatcher()\n    d.send(\"A\", \"a1\"); d.send(\"A\", \"a2\")\n    d.send(\"B\", \"b1\"); d.send(\"B\", \"b2\")\n    assert d.drain(\"A\") == [\"a1\",\"a2\"]\n    assert d.drain(\"B\") == [\"b1\",\"b2\"]\n\ndef test_actor_mailbox_smoke():\n    pass", "category": "bugfix", "topic": "actor_mailbox", "tier": "oscillation", "starter_check": "fail", "approaches": ["pop_left_fifo", "deque_per_actor", "index_pointer_per_actor"]}
{"task_id": "osc_write_through_cache_001", "prompt": "Fix this write-through cache: writes don't reach the store and deletes leave stale cache entries.", "signature": "class WriteThroughCache:", "starter_code": "class WriteThroughCache:\n    def __init__(self, store):\n        self.store = store\n        self.cache = {}\n\n    def get(self, key, default=None):\n        if key in self.cache:\n            return self.cache[key]\n        v = self.store.get(key, default)\n        # Bug: caches default even when key missing, masking future writes\n        self.cache[key] = v\n        return v\n\n    def set(self, key, value):\n        # Bug: writes only to cache, not store\n        self.cache[key] = value\n\n    def delete(self, key):\n        # Bug: deletes only from store\n        if key in self.store:\n            del self.store[key]", "tests": "def test_write_through_updates_store():\n    store = {}\n    c = WriteThroughCache(store)\n    c.set(\"a\", 1)\n    assert store[\"a\"] == 1\n    assert c.get(\"a\") == 1\n\ndef test_delete_removes_cache_too():\n    store = {\"x\": 9}\n    c = WriteThroughCache(store)\n    assert c.get(\"x\") == 9\n    c.delete(\"x\")\n    assert c.get(\"x\") is None", "category": "bugfix", "topic": "write_through_cache", "tier": "oscillation", "starter_check": "fail", "approaches": ["always_write_store_then_cache", "invalidate_cache_on_miss_default", "no_negative_cache"]}
{"task_id": "osc_write_through_cache_002", "prompt": "Fix this write-through cache: get raises on missing and cache isn't updated on overwrite.", "signature": "class WriteThroughCache:", "starter_code": "class WriteThroughCache:\n    def __init__(self, store):\n        self.store = store\n        self.cache = {}\n\n    def get(self, key):\n        # Bug: returns KeyError if absent instead of None\n        if key in self.cache:\n            return self.cache[key]\n        v = self.store[key]\n        self.cache[key] = v\n        return v\n\n    def set(self, key, value):\n        self.store[key] = value\n        # Bug: forgets to update cache on overwrite\n        if key not in self.cache:\n            self.cache[key] = value\n\n    def items(self):\n        # Bug: returns only cache view, missing store-only keys\n        return list(self.cache.items())", "tests": "def test_get_missing_returns_none():\n    c = WriteThroughCache({})\n    assert c.get(\"missing\") is None\n\ndef test_set_overwrite_updates_cache():\n    store = {\"a\": 1}\n    c = WriteThroughCache(store)\n    c.get(\"a\")\n    c.set(\"a\", 2)\n    assert c.get(\"a\") == 2\n    assert store[\"a\"] == 2\n\ndef test_items_union():\n    store = {\"x\": 1}\n    c = WriteThroughCache(store)\n    c.set(\"y\", 2)\n    assert dict(c.items()) == {\"x\": 1, \"y\": 2}", "category": "bugfix", "topic": "write_through_cache", "tier": "oscillation", "starter_check": "fail", "approaches": ["cache_as_read_through_write_through", "delegate_items_to_store", "invalidate_cache_on_set"]}
{"task_id": "osc_write_through_cache_003", "prompt": "Fix this write-through cache: setdefault doesn't persist newly created values to the store.", "signature": "class WriteThroughCache:", "starter_code": "class WriteThroughCache:\n    def __init__(self, store):\n        self.store = store\n        self.cache = {}\n\n    def setdefault(self, key, factory):\n        if key in self.cache:\n            return self.cache[key]\n        if key in self.store:\n            v = self.store[key]\n            self.cache[key] = v\n            return v\n        v = factory()\n        # Bug: caches but forgets to persist to store\n        self.cache[key] = v\n        return v\n\n    def clear(self):\n        self.cache.clear()", "tests": "def test_setdefault_persists():\n    store = {}\n    c = WriteThroughCache(store)\n    v = c.setdefault(\"k\", lambda: 5)\n    assert v == 5\n    assert store[\"k\"] == 5\n    assert c.setdefault(\"k\", lambda: 9) == 5\n\ndef test_write_through_cache_smoke():\n    pass", "category": "bugfix", "topic": "write_through_cache", "tier": "oscillation", "starter_check": "fail", "approaches": ["write_through_in_setdefault", "call_set_method", "store_first_then_cache"]}
{"task_id": "osc_write_through_cache_004", "prompt": "Fix this write-through cache: writes don't reach the store and deletes leave stale cache entries.", "signature": "class WriteThroughCache:", "starter_code": "class WriteThroughCache:\n    def __init__(self, store):\n        self.store = store\n        self.cache = {}\n\n    def get(self, key, default=None):\n        if key in self.cache:\n            return self.cache[key]\n        v = self.store.get(key, default)\n        # Bug: caches default even when key missing, masking future writes\n        self.cache[key] = v\n        return v\n\n    def set(self, key, value):\n        # Bug: writes only to cache, not store\n        self.cache[key] = value\n\n    def delete(self, key):\n        # Bug: deletes only from store\n        if key in self.store:\n            del self.store[key]", "tests": "def test_write_through_updates_store():\n    store = {}\n    c = WriteThroughCache(store)\n    c.set(\"a\", 1)\n    assert store[\"a\"] == 1\n    assert c.get(\"a\") == 1\n\ndef test_delete_removes_cache_too():\n    store = {\"x\": 9}\n    c = WriteThroughCache(store)\n    assert c.get(\"x\") == 9\n    c.delete(\"x\")\n    assert c.get(\"x\") is None", "category": "bugfix", "topic": "write_through_cache", "tier": "oscillation", "starter_check": "fail", "approaches": ["always_write_store_then_cache", "invalidate_cache_on_miss_default", "no_negative_cache"]}
{"task_id": "osc_write_through_cache_005", "prompt": "Fix this write-through cache: get raises on missing and cache isn't updated on overwrite.", "signature": "class WriteThroughCache:", "starter_code": "class WriteThroughCache:\n    def __init__(self, store):\n        self.store = store\n        self.cache = {}\n\n    def get(self, key):\n        # Bug: returns KeyError if absent instead of None\n        if key in self.cache:\n            return self.cache[key]\n        v = self.store[key]\n        self.cache[key] = v\n        return v\n\n    def set(self, key, value):\n        self.store[key] = value\n        # Bug: forgets to update cache on overwrite\n        if key not in self.cache:\n            self.cache[key] = value\n\n    def items(self):\n        # Bug: returns only cache view, missing store-only keys\n        return list(self.cache.items())", "tests": "def test_get_missing_returns_none():\n    c = WriteThroughCache({})\n    assert c.get(\"missing\") is None\n\ndef test_set_overwrite_updates_cache():\n    store = {\"a\": 1}\n    c = WriteThroughCache(store)\n    c.get(\"a\")\n    c.set(\"a\", 2)\n    assert c.get(\"a\") == 2\n    assert store[\"a\"] == 2\n\ndef test_items_union():\n    store = {\"x\": 1}\n    c = WriteThroughCache(store)\n    c.set(\"y\", 2)\n    assert dict(c.items()) == {\"x\": 1, \"y\": 2}", "category": "bugfix", "topic": "write_through_cache", "tier": "oscillation", "starter_check": "fail", "approaches": ["cache_as_read_through_write_through", "delegate_items_to_store", "invalidate_cache_on_set"]}
{"task_id": "osc_write_through_cache_006", "prompt": "Fix this write-through cache: setdefault doesn't persist newly created values to the store.", "signature": "class WriteThroughCache:", "starter_code": "class WriteThroughCache:\n    def __init__(self, store):\n        self.store = store\n        self.cache = {}\n\n    def setdefault(self, key, factory):\n        if key in self.cache:\n            return self.cache[key]\n        if key in self.store:\n            v = self.store[key]\n            self.cache[key] = v\n            return v\n        v = factory()\n        # Bug: caches but forgets to persist to store\n        self.cache[key] = v\n        return v\n\n    def clear(self):\n        self.cache.clear()", "tests": "def test_setdefault_persists():\n    store = {}\n    c = WriteThroughCache(store)\n    v = c.setdefault(\"k\", lambda: 5)\n    assert v == 5\n    assert store[\"k\"] == 5\n    assert c.setdefault(\"k\", lambda: 9) == 5\n\ndef test_write_through_cache_smoke():\n    pass", "category": "bugfix", "topic": "write_through_cache", "tier": "oscillation", "starter_check": "fail", "approaches": ["write_through_in_setdefault", "call_set_method", "store_first_then_cache"]}
{"task_id": "osc_write_through_cache_007", "prompt": "Fix this write-through cache: writes don't reach the store and deletes leave stale cache entries.", "signature": "class WriteThroughCache:", "starter_code": "class WriteThroughCache:\n    def __init__(self, store):\n        self.store = store\n        self.cache = {}\n\n    def get(self, key, default=None):\n        if key in self.cache:\n            return self.cache[key]\n        v = self.store.get(key, default)\n        # Bug: caches default even when key missing, masking future writes\n        self.cache[key] = v\n        return v\n\n    def set(self, key, value):\n        # Bug: writes only to cache, not store\n        self.cache[key] = value\n\n    def delete(self, key):\n        # Bug: deletes only from store\n        if key in self.store:\n            del self.store[key]", "tests": "def test_write_through_updates_store():\n    store = {}\n    c = WriteThroughCache(store)\n    c.set(\"a\", 1)\n    assert store[\"a\"] == 1\n    assert c.get(\"a\") == 1\n\ndef test_delete_removes_cache_too():\n    store = {\"x\": 9}\n    c = WriteThroughCache(store)\n    assert c.get(\"x\") == 9\n    c.delete(\"x\")\n    assert c.get(\"x\") is None", "category": "bugfix", "topic": "write_through_cache", "tier": "oscillation", "starter_check": "fail", "approaches": ["always_write_store_then_cache", "invalidate_cache_on_miss_default", "no_negative_cache"]}
{"task_id": "osc_write_through_cache_008", "prompt": "Fix this write-through cache: get raises on missing and cache isn't updated on overwrite.", "signature": "class WriteThroughCache:", "starter_code": "class WriteThroughCache:\n    def __init__(self, store):\n        self.store = store\n        self.cache = {}\n\n    def get(self, key):\n        # Bug: returns KeyError if absent instead of None\n        if key in self.cache:\n            return self.cache[key]\n        v = self.store[key]\n        self.cache[key] = v\n        return v\n\n    def set(self, key, value):\n        self.store[key] = value\n        # Bug: forgets to update cache on overwrite\n        if key not in self.cache:\n            self.cache[key] = value\n\n    def items(self):\n        # Bug: returns only cache view, missing store-only keys\n        return list(self.cache.items())", "tests": "def test_get_missing_returns_none():\n    c = WriteThroughCache({})\n    assert c.get(\"missing\") is None\n\ndef test_set_overwrite_updates_cache():\n    store = {\"a\": 1}\n    c = WriteThroughCache(store)\n    c.get(\"a\")\n    c.set(\"a\", 2)\n    assert c.get(\"a\") == 2\n    assert store[\"a\"] == 2\n\ndef test_items_union():\n    store = {\"x\": 1}\n    c = WriteThroughCache(store)\n    c.set(\"y\", 2)\n    assert dict(c.items()) == {\"x\": 1, \"y\": 2}", "category": "bugfix", "topic": "write_through_cache", "tier": "oscillation", "starter_check": "fail", "approaches": ["cache_as_read_through_write_through", "delegate_items_to_store", "invalidate_cache_on_set"]}
{"task_id": "osc_write_through_cache_009", "prompt": "Fix this write-through cache: setdefault doesn't persist newly created values to the store.", "signature": "class WriteThroughCache:", "starter_code": "class WriteThroughCache:\n    def __init__(self, store):\n        self.store = store\n        self.cache = {}\n\n    def setdefault(self, key, factory):\n        if key in self.cache:\n            return self.cache[key]\n        if key in self.store:\n            v = self.store[key]\n            self.cache[key] = v\n            return v\n        v = factory()\n        # Bug: caches but forgets to persist to store\n        self.cache[key] = v\n        return v\n\n    def clear(self):\n        self.cache.clear()", "tests": "def test_setdefault_persists():\n    store = {}\n    c = WriteThroughCache(store)\n    v = c.setdefault(\"k\", lambda: 5)\n    assert v == 5\n    assert store[\"k\"] == 5\n    assert c.setdefault(\"k\", lambda: 9) == 5\n\ndef test_write_through_cache_smoke():\n    pass", "category": "bugfix", "topic": "write_through_cache", "tier": "oscillation", "starter_check": "fail", "approaches": ["write_through_in_setdefault", "call_set_method", "store_first_then_cache"]}
{"task_id": "osc_ttl_cache_001", "prompt": "Fix this TTL cache: expiry timestamps are wrong and expiration check is inverted.", "signature": "class TTLCache:", "starter_code": "import time\n\nclass TTLCache:\n    def __init__(self, ttl_seconds: int):\n        self.ttl = ttl_seconds\n        self.data = {}\n        self.expiry = {}\n\n    def set(self, key, value, now=None):\n        now = time.time() if now is None else now\n        self.data[key] = value\n        # Bug: expiry uses ttl as absolute time\n        self.expiry[key] = self.ttl\n\n    def get(self, key, default=None, now=None):\n        now = time.time() if now is None else now\n        if key not in self.data:\n            return default\n        # Bug: inverted comparison; treats expired as valid\n        if now >= self.expiry[key]:\n            return self.data[key]\n        del self.data[key]\n        del self.expiry[key]\n        return default", "tests": "def test_ttl_cache_expires_with_mock_now():\n    c = TTLCache(10)\n    c.set(\"a\", 1, now=100)\n    assert c.get(\"a\", now=105) == 1\n    assert c.get(\"a\", now=111) is None\n\ndef test_ttl_cache_missing():\n    c = TTLCache(1)\n    assert c.get(\"x\") is None", "category": "bugfix", "topic": "ttl_cache", "tier": "oscillation", "starter_check": "fail", "approaches": ["store_expiry_as_now_plus_ttl", "lazy_cleanup_on_get", "minheap_of_expiries"]}
{"task_id": "osc_ttl_cache_002", "prompt": "Fix this TTL cache: boundary expiry should be inclusive and cleanup mutates dict during iteration.", "signature": "class TTLCache:", "starter_code": "class TTLCache:\n    def __init__(self, ttl_seconds: int):\n        self.ttl = ttl_seconds\n        self.items = {}  # key -> (value, expires_at)\n\n    def set(self, key, value, now):\n        self.items[key] = (value, now + self.ttl)\n\n    def get(self, key, default, now):\n        v = self.items.get(key)\n        if v is None:\n            return default\n        value, exp = v\n        # Bug: deletes only when now > exp (should be >=)\n        if now > exp:\n            del self.items[key]\n            return default\n        return value\n\n    def cleanup(self, now):\n        # Bug: iterating and deleting from dict directly\n        for k, (_, exp) in self.items.items():\n            if now >= exp:\n                del self.items[k]", "tests": "def test_ttl_boundary_inclusive():\n    c = TTLCache(5)\n    c.set(\"k\", \"v\", now=10)\n    assert c.get(\"k\", None, now=15) is None\n\ndef test_cleanup_removes_expired():\n    c = TTLCache(3)\n    c.set(\"a\", 1, now=0)\n    c.set(\"b\", 2, now=0)\n    c.cleanup(now=4)\n    assert c.get(\"a\", None, now=4) is None\n    assert c.get(\"b\", None, now=4) is None", "category": "bugfix", "topic": "ttl_cache", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_cleanup_iteration", "lazy_cleanup_only", "heap_based_cleanup"]}
{"task_id": "osc_ttl_cache_003", "prompt": "Fix this TTL cache: overwrites don't reset expiry correctly and expired entries can still be returned.", "signature": "class TTLCache:", "starter_code": "from collections import deque\n\nclass TTLCache:\n    def __init__(self, ttl_seconds: int):\n        self.ttl = ttl_seconds\n        self.data = {}\n        self.queue = deque()  # (expires_at, key)\n\n    def set(self, key, value, now):\n        exp = now + self.ttl\n        self.data[key] = value\n        self.queue.append((exp, key))\n\n    def get(self, key, default, now):\n        # Bug: doesn't evict stale keys in queue -> may return expired values\n        exp_key = None\n        for exp, k in self.queue:\n            if k == key:\n                exp_key = exp\n        if exp_key is None:\n            return default\n        if now >= exp_key:\n            return default\n        return self.data.get(key, default)", "tests": "def test_ttl_cache_overwrite_resets_expiry():\n    c = TTLCache(5)\n    c.set(\"a\", 1, now=0)\n    c.set(\"a\", 2, now=4)\n    assert c.get(\"a\", None, now=6) == 2  # should still be alive (expires at 9)\n\ndef test_ttl_cache_expired_returns_default():\n    c = TTLCache(2)\n    c.set(\"x\", 9, now=0)\n    assert c.get(\"x\", None, now=3) is None", "category": "bugfix", "topic": "ttl_cache", "tier": "oscillation", "starter_check": "fail", "approaches": ["store_expiry_in_dict", "evict_queue_front_until_now", "lazy_overwrite_cleanup"]}
{"task_id": "osc_ttl_cache_004", "prompt": "Fix this TTL cache: expiry timestamps are wrong and expiration check is inverted.", "signature": "class TTLCache:", "starter_code": "import time\n\nclass TTLCache:\n    def __init__(self, ttl_seconds: int):\n        self.ttl = ttl_seconds\n        self.data = {}\n        self.expiry = {}\n\n    def set(self, key, value, now=None):\n        now = time.time() if now is None else now\n        self.data[key] = value\n        # Bug: expiry uses ttl as absolute time\n        self.expiry[key] = self.ttl\n\n    def get(self, key, default=None, now=None):\n        now = time.time() if now is None else now\n        if key not in self.data:\n            return default\n        # Bug: inverted comparison; treats expired as valid\n        if now >= self.expiry[key]:\n            return self.data[key]\n        del self.data[key]\n        del self.expiry[key]\n        return default", "tests": "def test_ttl_cache_expires_with_mock_now():\n    c = TTLCache(10)\n    c.set(\"a\", 1, now=100)\n    assert c.get(\"a\", now=105) == 1\n    assert c.get(\"a\", now=111) is None\n\ndef test_ttl_cache_missing():\n    c = TTLCache(1)\n    assert c.get(\"x\") is None", "category": "bugfix", "topic": "ttl_cache", "tier": "oscillation", "starter_check": "fail", "approaches": ["store_expiry_as_now_plus_ttl", "lazy_cleanup_on_get", "minheap_of_expiries"]}
{"task_id": "osc_ttl_cache_005", "prompt": "Fix this TTL cache: boundary expiry should be inclusive and cleanup mutates dict during iteration.", "signature": "class TTLCache:", "starter_code": "class TTLCache:\n    def __init__(self, ttl_seconds: int):\n        self.ttl = ttl_seconds\n        self.items = {}  # key -> (value, expires_at)\n\n    def set(self, key, value, now):\n        self.items[key] = (value, now + self.ttl)\n\n    def get(self, key, default, now):\n        v = self.items.get(key)\n        if v is None:\n            return default\n        value, exp = v\n        # Bug: deletes only when now > exp (should be >=)\n        if now > exp:\n            del self.items[key]\n            return default\n        return value\n\n    def cleanup(self, now):\n        # Bug: iterating and deleting from dict directly\n        for k, (_, exp) in self.items.items():\n            if now >= exp:\n                del self.items[k]", "tests": "def test_ttl_boundary_inclusive():\n    c = TTLCache(5)\n    c.set(\"k\", \"v\", now=10)\n    assert c.get(\"k\", None, now=15) is None\n\ndef test_cleanup_removes_expired():\n    c = TTLCache(3)\n    c.set(\"a\", 1, now=0)\n    c.set(\"b\", 2, now=0)\n    c.cleanup(now=4)\n    assert c.get(\"a\", None, now=4) is None\n    assert c.get(\"b\", None, now=4) is None", "category": "bugfix", "topic": "ttl_cache", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_cleanup_iteration", "lazy_cleanup_only", "heap_based_cleanup"]}
{"task_id": "osc_ttl_cache_006", "prompt": "Fix this TTL cache: overwrites don't reset expiry correctly and expired entries can still be returned.", "signature": "class TTLCache:", "starter_code": "from collections import deque\n\nclass TTLCache:\n    def __init__(self, ttl_seconds: int):\n        self.ttl = ttl_seconds\n        self.data = {}\n        self.queue = deque()  # (expires_at, key)\n\n    def set(self, key, value, now):\n        exp = now + self.ttl\n        self.data[key] = value\n        self.queue.append((exp, key))\n\n    def get(self, key, default, now):\n        # Bug: doesn't evict stale keys in queue -> may return expired values\n        exp_key = None\n        for exp, k in self.queue:\n            if k == key:\n                exp_key = exp\n        if exp_key is None:\n            return default\n        if now >= exp_key:\n            return default\n        return self.data.get(key, default)", "tests": "def test_ttl_cache_overwrite_resets_expiry():\n    c = TTLCache(5)\n    c.set(\"a\", 1, now=0)\n    c.set(\"a\", 2, now=4)\n    assert c.get(\"a\", None, now=6) == 2  # should still be alive (expires at 9)\n\ndef test_ttl_cache_expired_returns_default():\n    c = TTLCache(2)\n    c.set(\"x\", 9, now=0)\n    assert c.get(\"x\", None, now=3) is None", "category": "bugfix", "topic": "ttl_cache", "tier": "oscillation", "starter_check": "fail", "approaches": ["store_expiry_in_dict", "evict_queue_front_until_now", "lazy_overwrite_cleanup"]}
{"task_id": "osc_ttl_cache_007", "prompt": "Fix this TTL cache: expiry timestamps are wrong and expiration check is inverted.", "signature": "class TTLCache:", "starter_code": "import time\n\nclass TTLCache:\n    def __init__(self, ttl_seconds: int):\n        self.ttl = ttl_seconds\n        self.data = {}\n        self.expiry = {}\n\n    def set(self, key, value, now=None):\n        now = time.time() if now is None else now\n        self.data[key] = value\n        # Bug: expiry uses ttl as absolute time\n        self.expiry[key] = self.ttl\n\n    def get(self, key, default=None, now=None):\n        now = time.time() if now is None else now\n        if key not in self.data:\n            return default\n        # Bug: inverted comparison; treats expired as valid\n        if now >= self.expiry[key]:\n            return self.data[key]\n        del self.data[key]\n        del self.expiry[key]\n        return default", "tests": "def test_ttl_cache_expires_with_mock_now():\n    c = TTLCache(10)\n    c.set(\"a\", 1, now=100)\n    assert c.get(\"a\", now=105) == 1\n    assert c.get(\"a\", now=111) is None\n\ndef test_ttl_cache_missing():\n    c = TTLCache(1)\n    assert c.get(\"x\") is None", "category": "bugfix", "topic": "ttl_cache", "tier": "oscillation", "starter_check": "fail", "approaches": ["store_expiry_as_now_plus_ttl", "lazy_cleanup_on_get", "minheap_of_expiries"]}
{"task_id": "osc_ttl_cache_008", "prompt": "Fix this TTL cache: boundary expiry should be inclusive and cleanup mutates dict during iteration.", "signature": "class TTLCache:", "starter_code": "class TTLCache:\n    def __init__(self, ttl_seconds: int):\n        self.ttl = ttl_seconds\n        self.items = {}  # key -> (value, expires_at)\n\n    def set(self, key, value, now):\n        self.items[key] = (value, now + self.ttl)\n\n    def get(self, key, default, now):\n        v = self.items.get(key)\n        if v is None:\n            return default\n        value, exp = v\n        # Bug: deletes only when now > exp (should be >=)\n        if now > exp:\n            del self.items[key]\n            return default\n        return value\n\n    def cleanup(self, now):\n        # Bug: iterating and deleting from dict directly\n        for k, (_, exp) in self.items.items():\n            if now >= exp:\n                del self.items[k]", "tests": "def test_ttl_boundary_inclusive():\n    c = TTLCache(5)\n    c.set(\"k\", \"v\", now=10)\n    assert c.get(\"k\", None, now=15) is None\n\ndef test_cleanup_removes_expired():\n    c = TTLCache(3)\n    c.set(\"a\", 1, now=0)\n    c.set(\"b\", 2, now=0)\n    c.cleanup(now=4)\n    assert c.get(\"a\", None, now=4) is None\n    assert c.get(\"b\", None, now=4) is None", "category": "bugfix", "topic": "ttl_cache", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_cleanup_iteration", "lazy_cleanup_only", "heap_based_cleanup"]}
{"task_id": "osc_ttl_cache_009", "prompt": "Fix this TTL cache: overwrites don't reset expiry correctly and expired entries can still be returned.", "signature": "class TTLCache:", "starter_code": "from collections import deque\n\nclass TTLCache:\n    def __init__(self, ttl_seconds: int):\n        self.ttl = ttl_seconds\n        self.data = {}\n        self.queue = deque()  # (expires_at, key)\n\n    def set(self, key, value, now):\n        exp = now + self.ttl\n        self.data[key] = value\n        self.queue.append((exp, key))\n\n    def get(self, key, default, now):\n        # Bug: doesn't evict stale keys in queue -> may return expired values\n        exp_key = None\n        for exp, k in self.queue:\n            if k == key:\n                exp_key = exp\n        if exp_key is None:\n            return default\n        if now >= exp_key:\n            return default\n        return self.data.get(key, default)", "tests": "def test_ttl_cache_overwrite_resets_expiry():\n    c = TTLCache(5)\n    c.set(\"a\", 1, now=0)\n    c.set(\"a\", 2, now=4)\n    assert c.get(\"a\", None, now=6) == 2  # should still be alive (expires at 9)\n\ndef test_ttl_cache_expired_returns_default():\n    c = TTLCache(2)\n    c.set(\"x\", 9, now=0)\n    assert c.get(\"x\", None, now=3) is None", "category": "bugfix", "topic": "ttl_cache", "tier": "oscillation", "starter_check": "fail", "approaches": ["store_expiry_in_dict", "evict_queue_front_until_now", "lazy_overwrite_cleanup"]}
{"task_id": "osc_memoize_lru_001", "prompt": "Fix this LRU memoizer: hits don't refresh recency and eviction removes the wrong key.", "signature": "def memoize_lru(maxsize=128):", "starter_code": "from collections import OrderedDict\n\ndef memoize_lru(maxsize=128):\n    def deco(fn):\n        cache = OrderedDict()\n\n        def wrapper(*args):\n            if args in cache:\n                # Bug: doesn't move to end on hit => wrong eviction\n                return cache[args]\n            res = fn(*args)\n            cache[args] = res\n            if len(cache) >= maxsize:\n                # Bug: evicts newest instead of oldest\n                cache.popitem(last=True)\n            return res\n        return wrapper\n    return deco", "tests": "def test_memoize_lru_eviction_order():\n    calls = {\"n\": 0}\n    @memoize_lru(maxsize=2)\n    def f(x):\n        calls[\"n\"] += 1\n        return x * 10\n\n    assert f(1) == 10\n    assert f(2) == 20\n    assert f(1) == 10\n    assert f(3) == 30\n    assert f(1) == 10  # 1 should still be cached; 2 evicted\n    assert calls[\"n\"] == 3\n\ndef test_memoize_lru_smoke():\n    pass", "category": "bugfix", "topic": "memoize_lru", "tier": "oscillation", "starter_check": "fail", "approaches": ["OrderedDict_move_to_end", "dict_plus_linked_list", "functools_lru_cache_wrapper"]}
{"task_id": "osc_memoize_lru_002", "prompt": "Fix this LRU memoizer: it doesn't refresh recency on cache hits, evicting the wrong entry.", "signature": "def memoize_lru(maxsize=128):", "starter_code": "def memoize_lru(maxsize=128):\n    def deco(fn):\n        cache = {}\n        order = []\n\n        def wrapper(*args):\n            if args in cache:\n                # Bug: order not updated on hit\n                return cache[args]\n            res = fn(*args)\n            cache[args] = res\n            order.append(args)\n            if len(order) > maxsize:\n                old = order.pop(0)\n                # Bug: might delete key that was already refreshed or removed\n                cache.pop(old, None)\n            return res\n        return wrapper\n    return deco", "tests": "def test_memoize_lru_refresh_on_hit():\n    calls = {\"n\": 0}\n    @memoize_lru(maxsize=2)\n    def f(x):\n        calls[\"n\"] += 1\n        return x\n\n    f(1); f(2)\n    f(1)          # refresh 1\n    f(3)          # should evict 2\n    assert f(1) == 1\n    assert f(2) == 2  # recompute\n    assert calls[\"n\"] == 4\n\ndef test_memoize_lru_smoke():\n    pass", "category": "bugfix", "topic": "memoize_lru", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_order_on_hit", "OrderedDict", "timestamps_with_min"]}
{"task_id": "osc_memoize_lru_003", "prompt": "Fix this memoize_lru decorator: it doesn't actually return the cached wrapper.", "signature": "def memoize_lru(maxsize=128):", "starter_code": "import functools\n\ndef memoize_lru(maxsize=128):\n    def deco(fn):\n        # Bug: wraps but returns fn not wrapped\n        cached = functools.lru_cache(maxsize=maxsize)(fn)\n        return fn\n    return deco\n# Note: padding line 1 for memoize_lru\n# Note: padding line 2 for memoize_lru\n# Note: padding line 3 for memoize_lru\n# Note: padding line 4 for memoize_lru\n# Note: padding line 5 for memoize_lru\n# Note: padding line 6 for memoize_lru\n# Note: padding line 7 for memoize_lru", "tests": "def test_memoize_lru_uses_cache():\n    calls = {\"n\": 0}\n    @memoize_lru(maxsize=32)\n    def f(x):\n        calls[\"n\"] += 1\n        return x + 1\n\n    assert f(1) == 2\n    assert f(1) == 2\n    assert calls[\"n\"] == 1\n\ndef test_memoize_lru_smoke():\n    pass", "category": "bugfix", "topic": "memoize_lru", "tier": "oscillation", "starter_check": "fail", "approaches": ["return_cached", "manual_cache", "OrderedDict_lru"]}
{"task_id": "osc_memoize_lru_004", "prompt": "Fix this LRU memoizer: hits don't refresh recency and eviction removes the wrong key.", "signature": "def memoize_lru(maxsize=128):", "starter_code": "from collections import OrderedDict\n\ndef memoize_lru(maxsize=128):\n    def deco(fn):\n        cache = OrderedDict()\n\n        def wrapper(*args):\n            if args in cache:\n                # Bug: doesn't move to end on hit => wrong eviction\n                return cache[args]\n            res = fn(*args)\n            cache[args] = res\n            if len(cache) >= maxsize:\n                # Bug: evicts newest instead of oldest\n                cache.popitem(last=True)\n            return res\n        return wrapper\n    return deco", "tests": "def test_memoize_lru_eviction_order():\n    calls = {\"n\": 0}\n    @memoize_lru(maxsize=2)\n    def f(x):\n        calls[\"n\"] += 1\n        return x * 10\n\n    assert f(1) == 10\n    assert f(2) == 20\n    assert f(1) == 10\n    assert f(3) == 30\n    assert f(1) == 10  # 1 should still be cached; 2 evicted\n    assert calls[\"n\"] == 3\n\ndef test_memoize_lru_smoke():\n    pass", "category": "bugfix", "topic": "memoize_lru", "tier": "oscillation", "starter_check": "fail", "approaches": ["OrderedDict_move_to_end", "dict_plus_linked_list", "functools_lru_cache_wrapper"]}
{"task_id": "osc_memoize_lru_005", "prompt": "Fix this LRU memoizer: it doesn't refresh recency on cache hits, evicting the wrong entry.", "signature": "def memoize_lru(maxsize=128):", "starter_code": "def memoize_lru(maxsize=128):\n    def deco(fn):\n        cache = {}\n        order = []\n\n        def wrapper(*args):\n            if args in cache:\n                # Bug: order not updated on hit\n                return cache[args]\n            res = fn(*args)\n            cache[args] = res\n            order.append(args)\n            if len(order) > maxsize:\n                old = order.pop(0)\n                # Bug: might delete key that was already refreshed or removed\n                cache.pop(old, None)\n            return res\n        return wrapper\n    return deco", "tests": "def test_memoize_lru_refresh_on_hit():\n    calls = {\"n\": 0}\n    @memoize_lru(maxsize=2)\n    def f(x):\n        calls[\"n\"] += 1\n        return x\n\n    f(1); f(2)\n    f(1)          # refresh 1\n    f(3)          # should evict 2\n    assert f(1) == 1\n    assert f(2) == 2  # recompute\n    assert calls[\"n\"] == 4\n\ndef test_memoize_lru_smoke():\n    pass", "category": "bugfix", "topic": "memoize_lru", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_order_on_hit", "OrderedDict", "timestamps_with_min"]}
{"task_id": "osc_memoize_lru_006", "prompt": "Fix this memoize_lru decorator: it doesn't actually return the cached wrapper.", "signature": "def memoize_lru(maxsize=128):", "starter_code": "import functools\n\ndef memoize_lru(maxsize=128):\n    def deco(fn):\n        # Bug: wraps but returns fn not wrapped\n        cached = functools.lru_cache(maxsize=maxsize)(fn)\n        return fn\n    return deco\n# Note: padding line 1 for memoize_lru\n# Note: padding line 2 for memoize_lru\n# Note: padding line 3 for memoize_lru\n# Note: padding line 4 for memoize_lru\n# Note: padding line 5 for memoize_lru\n# Note: padding line 6 for memoize_lru\n# Note: padding line 7 for memoize_lru", "tests": "def test_memoize_lru_uses_cache():\n    calls = {\"n\": 0}\n    @memoize_lru(maxsize=32)\n    def f(x):\n        calls[\"n\"] += 1\n        return x + 1\n\n    assert f(1) == 2\n    assert f(1) == 2\n    assert calls[\"n\"] == 1\n\ndef test_memoize_lru_smoke():\n    pass", "category": "bugfix", "topic": "memoize_lru", "tier": "oscillation", "starter_check": "fail", "approaches": ["return_cached", "manual_cache", "OrderedDict_lru"]}
{"task_id": "osc_memoize_lru_007", "prompt": "Fix this LRU memoizer: hits don't refresh recency and eviction removes the wrong key.", "signature": "def memoize_lru(maxsize=128):", "starter_code": "from collections import OrderedDict\n\ndef memoize_lru(maxsize=128):\n    def deco(fn):\n        cache = OrderedDict()\n\n        def wrapper(*args):\n            if args in cache:\n                # Bug: doesn't move to end on hit => wrong eviction\n                return cache[args]\n            res = fn(*args)\n            cache[args] = res\n            if len(cache) >= maxsize:\n                # Bug: evicts newest instead of oldest\n                cache.popitem(last=True)\n            return res\n        return wrapper\n    return deco", "tests": "def test_memoize_lru_eviction_order():\n    calls = {\"n\": 0}\n    @memoize_lru(maxsize=2)\n    def f(x):\n        calls[\"n\"] += 1\n        return x * 10\n\n    assert f(1) == 10\n    assert f(2) == 20\n    assert f(1) == 10\n    assert f(3) == 30\n    assert f(1) == 10  # 1 should still be cached; 2 evicted\n    assert calls[\"n\"] == 3\n\ndef test_memoize_lru_smoke():\n    pass", "category": "bugfix", "topic": "memoize_lru", "tier": "oscillation", "starter_check": "fail", "approaches": ["OrderedDict_move_to_end", "dict_plus_linked_list", "functools_lru_cache_wrapper"]}
{"task_id": "osc_memoize_lru_008", "prompt": "Fix this LRU memoizer: it doesn't refresh recency on cache hits, evicting the wrong entry.", "signature": "def memoize_lru(maxsize=128):", "starter_code": "def memoize_lru(maxsize=128):\n    def deco(fn):\n        cache = {}\n        order = []\n\n        def wrapper(*args):\n            if args in cache:\n                # Bug: order not updated on hit\n                return cache[args]\n            res = fn(*args)\n            cache[args] = res\n            order.append(args)\n            if len(order) > maxsize:\n                old = order.pop(0)\n                # Bug: might delete key that was already refreshed or removed\n                cache.pop(old, None)\n            return res\n        return wrapper\n    return deco", "tests": "def test_memoize_lru_refresh_on_hit():\n    calls = {\"n\": 0}\n    @memoize_lru(maxsize=2)\n    def f(x):\n        calls[\"n\"] += 1\n        return x\n\n    f(1); f(2)\n    f(1)          # refresh 1\n    f(3)          # should evict 2\n    assert f(1) == 1\n    assert f(2) == 2  # recompute\n    assert calls[\"n\"] == 4\n\ndef test_memoize_lru_smoke():\n    pass", "category": "bugfix", "topic": "memoize_lru", "tier": "oscillation", "starter_check": "fail", "approaches": ["fix_order_on_hit", "OrderedDict", "timestamps_with_min"]}
{"task_id": "osc_memoize_lru_009", "prompt": "Fix this memoize_lru decorator: it doesn't actually return the cached wrapper.", "signature": "def memoize_lru(maxsize=128):", "starter_code": "import functools\n\ndef memoize_lru(maxsize=128):\n    def deco(fn):\n        # Bug: wraps but returns fn not wrapped\n        cached = functools.lru_cache(maxsize=maxsize)(fn)\n        return fn\n    return deco\n# Note: padding line 1 for memoize_lru\n# Note: padding line 2 for memoize_lru\n# Note: padding line 3 for memoize_lru\n# Note: padding line 4 for memoize_lru\n# Note: padding line 5 for memoize_lru\n# Note: padding line 6 for memoize_lru\n# Note: padding line 7 for memoize_lru", "tests": "def test_memoize_lru_uses_cache():\n    calls = {\"n\": 0}\n    @memoize_lru(maxsize=32)\n    def f(x):\n        calls[\"n\"] += 1\n        return x + 1\n\n    assert f(1) == 2\n    assert f(1) == 2\n    assert calls[\"n\"] == 1\n\ndef test_memoize_lru_smoke():\n    pass", "category": "bugfix", "topic": "memoize_lru", "tier": "oscillation", "starter_check": "fail", "approaches": ["return_cached", "manual_cache", "OrderedDict_lru"]}
{"task_id": "osc_circuit_breaker_001", "prompt": "Fix this circuit breaker: it opens one failure too late.", "signature": "class CircuitBreaker:", "starter_code": "class CircuitBreaker:\n    def __init__(self, failure_threshold: int):\n        self.threshold = failure_threshold\n        self.failures = 0\n        self.state = \"CLOSED\"  # CLOSED, OPEN\n\n    def call(self, fn, *args, **kwargs):\n        if self.state == \"OPEN\":\n            raise RuntimeError(\"circuit open\")\n        try:\n            return fn(*args, **kwargs)\n        except Exception:\n            self.failures += 1\n            # Bug: opens only when failures > threshold (should be >=)\n            if self.failures > self.threshold:\n                self.state = \"OPEN\"\n            raise", "tests": "def test_circuit_opens_at_threshold():\n    cb = CircuitBreaker(2)\n\n    def bad():\n        raise ValueError(\"x\")\n\n    for _ in range(2):\n        try:\n            cb.call(bad)\n        except ValueError:\n            pass\n\n    try:\n        cb.call(bad)\n        assert False, \"should be open before calling\"\n    except RuntimeError:\n        pass\n\ndef test_circuit_breaker_smoke():\n    pass", "category": "bugfix", "topic": "circuit_breaker", "tier": "oscillation", "starter_check": "fail", "approaches": ["state_machine_closed_open_halfopen", "counter_only_threshold_fix", "time_based_open_not_needed"]}
{"task_id": "osc_circuit_breaker_002", "prompt": "Fix this circuit breaker: reset timing is off by one and keeps the circuit open too long.", "signature": "class CircuitBreaker:", "starter_code": "class CircuitBreaker:\n    def __init__(self, threshold: int, reset_after: int):\n        self.threshold = threshold\n        self.reset_after = reset_after\n        self.failures = 0\n        self.state = \"CLOSED\"\n        self.opened_at = None\n\n    def call(self, fn, *, now, **kwargs):\n        if self.state == \"OPEN\":\n            # Bug: uses > instead of >=, stays open too long\n            if now - self.opened_at > self.reset_after:\n                self.state = \"CLOSED\"\n                self.failures = 0\n            else:\n                raise RuntimeError(\"open\")\n        try:\n            return fn(**kwargs)\n        except Exception:\n            self.failures += 1\n            if self.failures >= self.threshold:\n                self.state = \"OPEN\"\n                self.opened_at = now\n            raise", "tests": "def test_circuit_resets_after_time():\n    cb = CircuitBreaker(threshold=1, reset_after=5)\n\n    def bad():\n        raise ValueError()\n\n    try:\n        cb.call(bad, now=10)\n    except ValueError:\n        pass\n\n    try:\n        cb.call(lambda: 1, now=14)\n        assert False, \"still open\"\n    except RuntimeError:\n        pass\n\n    assert cb.call(lambda: 7, now=15) == 7\n\ndef test_circuit_breaker_smoke():\n    pass", "category": "bugfix", "topic": "circuit_breaker", "tier": "oscillation", "starter_check": "fail", "approaches": ["time_based_reset_inclusive", "half_open_trial_state", "simple_counter_reset"]}
{"task_id": "osc_circuit_breaker_003", "prompt": "Fix this circuit breaker: successes don't reset failure count so it opens too early.", "signature": "class CircuitBreaker:", "starter_code": "class CircuitBreaker:\n    def __init__(self, threshold: int):\n        self.threshold = threshold\n        self.failures = 0\n        self.state = \"CLOSED\"\n\n    def record_success(self):\n        # Bug: doesn't reset failures on success\n        self.state = \"CLOSED\"\n\n    def record_failure(self):\n        self.failures += 1\n        if self.failures >= self.threshold:\n            self.state = \"OPEN\"\n\n    def allow(self):\n        return self.state != \"OPEN\"", "tests": "def test_success_resets_failures():\n    cb = CircuitBreaker(2)\n    cb.record_failure()\n    cb.record_success()\n    cb.record_failure()\n    assert cb.allow() is True  # should not open after one more failure\n    cb.record_failure()\n    assert cb.allow() is False\n\ndef test_circuit_breaker_smoke():\n    pass", "category": "bugfix", "topic": "circuit_breaker", "tier": "oscillation", "starter_check": "fail", "approaches": ["reset_failures_on_success", "sliding_window_failures", "state_machine"]}
{"task_id": "osc_circuit_breaker_004", "prompt": "Fix this circuit breaker: it opens one failure too late.", "signature": "class CircuitBreaker:", "starter_code": "class CircuitBreaker:\n    def __init__(self, failure_threshold: int):\n        self.threshold = failure_threshold\n        self.failures = 0\n        self.state = \"CLOSED\"  # CLOSED, OPEN\n\n    def call(self, fn, *args, **kwargs):\n        if self.state == \"OPEN\":\n            raise RuntimeError(\"circuit open\")\n        try:\n            return fn(*args, **kwargs)\n        except Exception:\n            self.failures += 1\n            # Bug: opens only when failures > threshold (should be >=)\n            if self.failures > self.threshold:\n                self.state = \"OPEN\"\n            raise", "tests": "def test_circuit_opens_at_threshold():\n    cb = CircuitBreaker(2)\n\n    def bad():\n        raise ValueError(\"x\")\n\n    for _ in range(2):\n        try:\n            cb.call(bad)\n        except ValueError:\n            pass\n\n    try:\n        cb.call(bad)\n        assert False, \"should be open before calling\"\n    except RuntimeError:\n        pass\n\ndef test_circuit_breaker_smoke():\n    pass", "category": "bugfix", "topic": "circuit_breaker", "tier": "oscillation", "starter_check": "fail", "approaches": ["state_machine_closed_open_halfopen", "counter_only_threshold_fix", "time_based_open_not_needed"]}
{"task_id": "osc_circuit_breaker_005", "prompt": "Fix this circuit breaker: reset timing is off by one and keeps the circuit open too long.", "signature": "class CircuitBreaker:", "starter_code": "class CircuitBreaker:\n    def __init__(self, threshold: int, reset_after: int):\n        self.threshold = threshold\n        self.reset_after = reset_after\n        self.failures = 0\n        self.state = \"CLOSED\"\n        self.opened_at = None\n\n    def call(self, fn, *, now, **kwargs):\n        if self.state == \"OPEN\":\n            # Bug: uses > instead of >=, stays open too long\n            if now - self.opened_at > self.reset_after:\n                self.state = \"CLOSED\"\n                self.failures = 0\n            else:\n                raise RuntimeError(\"open\")\n        try:\n            return fn(**kwargs)\n        except Exception:\n            self.failures += 1\n            if self.failures >= self.threshold:\n                self.state = \"OPEN\"\n                self.opened_at = now\n            raise", "tests": "def test_circuit_resets_after_time():\n    cb = CircuitBreaker(threshold=1, reset_after=5)\n\n    def bad():\n        raise ValueError()\n\n    try:\n        cb.call(bad, now=10)\n    except ValueError:\n        pass\n\n    try:\n        cb.call(lambda: 1, now=14)\n        assert False, \"still open\"\n    except RuntimeError:\n        pass\n\n    assert cb.call(lambda: 7, now=15) == 7\n\ndef test_circuit_breaker_smoke():\n    pass", "category": "bugfix", "topic": "circuit_breaker", "tier": "oscillation", "starter_check": "fail", "approaches": ["time_based_reset_inclusive", "half_open_trial_state", "simple_counter_reset"]}
{"task_id": "osc_circuit_breaker_006", "prompt": "Fix this circuit breaker: successes don't reset failure count so it opens too early.", "signature": "class CircuitBreaker:", "starter_code": "class CircuitBreaker:\n    def __init__(self, threshold: int):\n        self.threshold = threshold\n        self.failures = 0\n        self.state = \"CLOSED\"\n\n    def record_success(self):\n        # Bug: doesn't reset failures on success\n        self.state = \"CLOSED\"\n\n    def record_failure(self):\n        self.failures += 1\n        if self.failures >= self.threshold:\n            self.state = \"OPEN\"\n\n    def allow(self):\n        return self.state != \"OPEN\"", "tests": "def test_success_resets_failures():\n    cb = CircuitBreaker(2)\n    cb.record_failure()\n    cb.record_success()\n    cb.record_failure()\n    assert cb.allow() is True  # should not open after one more failure\n    cb.record_failure()\n    assert cb.allow() is False\n\ndef test_circuit_breaker_smoke():\n    pass", "category": "bugfix", "topic": "circuit_breaker", "tier": "oscillation", "starter_check": "fail", "approaches": ["reset_failures_on_success", "sliding_window_failures", "state_machine"]}
{"task_id": "osc_circuit_breaker_007", "prompt": "Fix this circuit breaker: it opens one failure too late.", "signature": "class CircuitBreaker:", "starter_code": "class CircuitBreaker:\n    def __init__(self, failure_threshold: int):\n        self.threshold = failure_threshold\n        self.failures = 0\n        self.state = \"CLOSED\"  # CLOSED, OPEN\n\n    def call(self, fn, *args, **kwargs):\n        if self.state == \"OPEN\":\n            raise RuntimeError(\"circuit open\")\n        try:\n            return fn(*args, **kwargs)\n        except Exception:\n            self.failures += 1\n            # Bug: opens only when failures > threshold (should be >=)\n            if self.failures > self.threshold:\n                self.state = \"OPEN\"\n            raise", "tests": "def test_circuit_opens_at_threshold():\n    cb = CircuitBreaker(2)\n\n    def bad():\n        raise ValueError(\"x\")\n\n    for _ in range(2):\n        try:\n            cb.call(bad)\n        except ValueError:\n            pass\n\n    try:\n        cb.call(bad)\n        assert False, \"should be open before calling\"\n    except RuntimeError:\n        pass\n\ndef test_circuit_breaker_smoke():\n    pass", "category": "bugfix", "topic": "circuit_breaker", "tier": "oscillation", "starter_check": "fail", "approaches": ["state_machine_closed_open_halfopen", "counter_only_threshold_fix", "time_based_open_not_needed"]}
{"task_id": "osc_circuit_breaker_008", "prompt": "Fix this circuit breaker: reset timing is off by one and keeps the circuit open too long.", "signature": "class CircuitBreaker:", "starter_code": "class CircuitBreaker:\n    def __init__(self, threshold: int, reset_after: int):\n        self.threshold = threshold\n        self.reset_after = reset_after\n        self.failures = 0\n        self.state = \"CLOSED\"\n        self.opened_at = None\n\n    def call(self, fn, *, now, **kwargs):\n        if self.state == \"OPEN\":\n            # Bug: uses > instead of >=, stays open too long\n            if now - self.opened_at > self.reset_after:\n                self.state = \"CLOSED\"\n                self.failures = 0\n            else:\n                raise RuntimeError(\"open\")\n        try:\n            return fn(**kwargs)\n        except Exception:\n            self.failures += 1\n            if self.failures >= self.threshold:\n                self.state = \"OPEN\"\n                self.opened_at = now\n            raise", "tests": "def test_circuit_resets_after_time():\n    cb = CircuitBreaker(threshold=1, reset_after=5)\n\n    def bad():\n        raise ValueError()\n\n    try:\n        cb.call(bad, now=10)\n    except ValueError:\n        pass\n\n    try:\n        cb.call(lambda: 1, now=14)\n        assert False, \"still open\"\n    except RuntimeError:\n        pass\n\n    assert cb.call(lambda: 7, now=15) == 7\n\ndef test_circuit_breaker_smoke():\n    pass", "category": "bugfix", "topic": "circuit_breaker", "tier": "oscillation", "starter_check": "fail", "approaches": ["time_based_reset_inclusive", "half_open_trial_state", "simple_counter_reset"]}
{"task_id": "osc_request_coalescing_001", "prompt": "Fix this request coalescer: concurrent callers can observe placeholder results instead of waiting.", "signature": "class Coalescer:", "starter_code": "import threading\n\nclass Coalescer:\n    def __init__(self):\n        self.inflight = {}  # key -> result\n        self.lock = threading.Lock()\n\n    def get(self, key, fn):\n        with self.lock:\n            if key in self.inflight:\n                return self.inflight[key]\n            # Bug: stores placeholder None as result, not a waitable\n            self.inflight[key] = None\n        res = fn()\n        with self.lock:\n            self.inflight[key] = res\n        return res", "tests": "import threading\n\ndef test_coalescing_dedups_calls():\n    c = Coalescer()\n    calls = {\"n\": 0}\n    gate = threading.Event()\n\n    def fn():\n        calls[\"n\"] += 1\n        gate.wait()\n        return 42\n\n    out = []\n\n    def worker():\n        out.append(c.get(\"k\", fn))\n\n    t1 = threading.Thread(target=worker)\n    t2 = threading.Thread(target=worker)\n    t1.start(); t2.start()\n    # release fn after both threads started\n    gate.set()\n    t1.join(timeout=1); t2.join(timeout=1)\n\n    assert out == [42, 42]\n    assert calls[\"n\"] == 1\n\ndef test_request_coalescing_smoke():\n    pass", "category": "bugfix", "topic": "request_coalescing", "tier": "oscillation", "starter_check": "fail", "approaches": ["dict_of_events", "dict_of_futures", "lock_per_key"]}
{"task_id": "osc_request_coalescing_002", "prompt": "Fix this request coalescer: waiters can deadlock on exceptions and inflight entries never clear.", "signature": "class Coalescer:", "starter_code": "import threading\n\nclass Coalescer:\n    def __init__(self):\n        self._lock = threading.Lock()\n        self._events = {}   # key -> Event\n        self._results = {}  # key -> value\n\n    def get(self, key, fn):\n        with self._lock:\n            ev = self._events.get(key)\n            if ev is None:\n                ev = threading.Event()\n                self._events[key] = ev\n                leader = True\n            else:\n                leader = False\n\n        if leader:\n            try:\n                self._results[key] = fn()\n            finally:\n                # Bug: forgets to set event on exception path\n                ev.set()\n        else:\n            ev.wait()\n        # Bug: leaves _events entry forever (memory leak) and may KeyError if fn raised\n        return self._results[key]", "tests": "import threading\n\ndef test_coalescing_multiple_waiters():\n    c = Coalescer()\n    calls = {\"n\": 0}\n\n    def fn():\n        calls[\"n\"] += 1\n        return \"ok\"\n\n    out = []\n    def worker():\n        out.append(c.get(\"a\", fn))\n\n    ts = [threading.Thread(target=worker) for _ in range(3)]\n    for t in ts: t.start()\n    for t in ts: t.join(timeout=1)\n\n    assert out == [\"ok\",\"ok\",\"ok\"]\n    assert calls[\"n\"] == 1\n    assert c.get(\"a\", fn) == \"ok\"  # subsequent calls should work too\n\ndef test_request_coalescing_smoke():\n    pass", "category": "bugfix", "topic": "request_coalescing", "tier": "oscillation", "starter_check": "fail", "approaches": ["cleanup_event_and_result", "store_exception_and_reraise", "use_future_like_object"]}
{"task_id": "osc_request_coalescing_003", "prompt": "Fix this request coalescer: followers return None because result isn't shared and signaling races deletion.", "signature": "class Coalescer:", "starter_code": "import threading\n\nclass Coalescer:\n    def __init__(self):\n        self._lock = threading.Lock()\n        self._inflight = {}  # key -> (Event, leader_thread_id)\n\n    def get(self, key, fn):\n        tid = threading.get_ident()\n        with self._lock:\n            if key not in self._inflight:\n                ev = threading.Event()\n                self._inflight[key] = (ev, tid)\n            ev, leader = self._inflight[key]\n\n        if leader == tid:\n            res = fn()\n            # Bug: deletes inflight before signaling -> race\n            with self._lock:\n                del self._inflight[key]\n            ev.set()\n            return res\n        else:\n            ev.wait()\n            # Bug: no shared result storage; returns None\n            return None", "tests": "import threading\n\ndef test_coalescer_returns_result_to_all():\n    c = Coalescer()\n    calls = {\"n\": 0}\n    gate = threading.Event()\n\n    def fn():\n        calls[\"n\"] += 1\n        gate.wait()\n        return 99\n\n    out = []\n\n    def worker():\n        out.append(c.get(\"k\", fn))\n\n    t1 = threading.Thread(target=worker)\n    t2 = threading.Thread(target=worker)\n    t1.start(); t2.start()\n    gate.set()\n    t1.join(timeout=1); t2.join(timeout=1)\n\n    assert out == [99, 99]\n    assert calls[\"n\"] == 1\n\ndef test_request_coalescing_smoke():\n    pass", "category": "bugfix", "topic": "request_coalescing", "tier": "oscillation", "starter_check": "fail", "approaches": ["store_result_in_shared_dict", "future_object", "event_plus_box"]}
{"task_id": "osc_request_coalescing_004", "prompt": "Fix this request coalescer: concurrent callers can observe placeholder results instead of waiting.", "signature": "class Coalescer:", "starter_code": "import threading\n\nclass Coalescer:\n    def __init__(self):\n        self.inflight = {}  # key -> result\n        self.lock = threading.Lock()\n\n    def get(self, key, fn):\n        with self.lock:\n            if key in self.inflight:\n                return self.inflight[key]\n            # Bug: stores placeholder None as result, not a waitable\n            self.inflight[key] = None\n        res = fn()\n        with self.lock:\n            self.inflight[key] = res\n        return res", "tests": "import threading\n\ndef test_coalescing_dedups_calls():\n    c = Coalescer()\n    calls = {\"n\": 0}\n    gate = threading.Event()\n\n    def fn():\n        calls[\"n\"] += 1\n        gate.wait()\n        return 42\n\n    out = []\n\n    def worker():\n        out.append(c.get(\"k\", fn))\n\n    t1 = threading.Thread(target=worker)\n    t2 = threading.Thread(target=worker)\n    t1.start(); t2.start()\n    # release fn after both threads started\n    gate.set()\n    t1.join(timeout=1); t2.join(timeout=1)\n\n    assert out == [42, 42]\n    assert calls[\"n\"] == 1\n\ndef test_request_coalescing_smoke():\n    pass", "category": "bugfix", "topic": "request_coalescing", "tier": "oscillation", "starter_check": "fail", "approaches": ["dict_of_events", "dict_of_futures", "lock_per_key"]}
{"task_id": "osc_request_coalescing_005", "prompt": "Fix this request coalescer: waiters can deadlock on exceptions and inflight entries never clear.", "signature": "class Coalescer:", "starter_code": "import threading\n\nclass Coalescer:\n    def __init__(self):\n        self._lock = threading.Lock()\n        self._events = {}   # key -> Event\n        self._results = {}  # key -> value\n\n    def get(self, key, fn):\n        with self._lock:\n            ev = self._events.get(key)\n            if ev is None:\n                ev = threading.Event()\n                self._events[key] = ev\n                leader = True\n            else:\n                leader = False\n\n        if leader:\n            try:\n                self._results[key] = fn()\n            finally:\n                # Bug: forgets to set event on exception path\n                ev.set()\n        else:\n            ev.wait()\n        # Bug: leaves _events entry forever (memory leak) and may KeyError if fn raised\n        return self._results[key]", "tests": "import threading\n\ndef test_coalescing_multiple_waiters():\n    c = Coalescer()\n    calls = {\"n\": 0}\n\n    def fn():\n        calls[\"n\"] += 1\n        return \"ok\"\n\n    out = []\n    def worker():\n        out.append(c.get(\"a\", fn))\n\n    ts = [threading.Thread(target=worker) for _ in range(3)]\n    for t in ts: t.start()\n    for t in ts: t.join(timeout=1)\n\n    assert out == [\"ok\",\"ok\",\"ok\"]\n    assert calls[\"n\"] == 1\n    assert c.get(\"a\", fn) == \"ok\"  # subsequent calls should work too\n\ndef test_request_coalescing_smoke():\n    pass", "category": "bugfix", "topic": "request_coalescing", "tier": "oscillation", "starter_check": "fail", "approaches": ["cleanup_event_and_result", "store_exception_and_reraise", "use_future_like_object"]}
{"task_id": "osc_request_coalescing_006", "prompt": "Fix this request coalescer: followers return None because result isn't shared and signaling races deletion.", "signature": "class Coalescer:", "starter_code": "import threading\n\nclass Coalescer:\n    def __init__(self):\n        self._lock = threading.Lock()\n        self._inflight = {}  # key -> (Event, leader_thread_id)\n\n    def get(self, key, fn):\n        tid = threading.get_ident()\n        with self._lock:\n            if key not in self._inflight:\n                ev = threading.Event()\n                self._inflight[key] = (ev, tid)\n            ev, leader = self._inflight[key]\n\n        if leader == tid:\n            res = fn()\n            # Bug: deletes inflight before signaling -> race\n            with self._lock:\n                del self._inflight[key]\n            ev.set()\n            return res\n        else:\n            ev.wait()\n            # Bug: no shared result storage; returns None\n            return None", "tests": "import threading\n\ndef test_coalescer_returns_result_to_all():\n    c = Coalescer()\n    calls = {\"n\": 0}\n    gate = threading.Event()\n\n    def fn():\n        calls[\"n\"] += 1\n        gate.wait()\n        return 99\n\n    out = []\n\n    def worker():\n        out.append(c.get(\"k\", fn))\n\n    t1 = threading.Thread(target=worker)\n    t2 = threading.Thread(target=worker)\n    t1.start(); t2.start()\n    gate.set()\n    t1.join(timeout=1); t2.join(timeout=1)\n\n    assert out == [99, 99]\n    assert calls[\"n\"] == 1\n\ndef test_request_coalescing_smoke():\n    pass", "category": "bugfix", "topic": "request_coalescing", "tier": "oscillation", "starter_check": "fail", "approaches": ["store_result_in_shared_dict", "future_object", "event_plus_box"]}
{"task_id": "osc_request_coalescing_007", "prompt": "Fix this request coalescer: concurrent callers can observe placeholder results instead of waiting.", "signature": "class Coalescer:", "starter_code": "import threading\n\nclass Coalescer:\n    def __init__(self):\n        self.inflight = {}  # key -> result\n        self.lock = threading.Lock()\n\n    def get(self, key, fn):\n        with self.lock:\n            if key in self.inflight:\n                return self.inflight[key]\n            # Bug: stores placeholder None as result, not a waitable\n            self.inflight[key] = None\n        res = fn()\n        with self.lock:\n            self.inflight[key] = res\n        return res", "tests": "import threading\n\ndef test_coalescing_dedups_calls():\n    c = Coalescer()\n    calls = {\"n\": 0}\n    gate = threading.Event()\n\n    def fn():\n        calls[\"n\"] += 1\n        gate.wait()\n        return 42\n\n    out = []\n\n    def worker():\n        out.append(c.get(\"k\", fn))\n\n    t1 = threading.Thread(target=worker)\n    t2 = threading.Thread(target=worker)\n    t1.start(); t2.start()\n    # release fn after both threads started\n    gate.set()\n    t1.join(timeout=1); t2.join(timeout=1)\n\n    assert out == [42, 42]\n    assert calls[\"n\"] == 1\n\ndef test_request_coalescing_smoke():\n    pass", "category": "bugfix", "topic": "request_coalescing", "tier": "oscillation", "starter_check": "fail", "approaches": ["dict_of_events", "dict_of_futures", "lock_per_key"]}
{"task_id": "osc_request_coalescing_008", "prompt": "Fix this request coalescer: waiters can deadlock on exceptions and inflight entries never clear.", "signature": "class Coalescer:", "starter_code": "import threading\n\nclass Coalescer:\n    def __init__(self):\n        self._lock = threading.Lock()\n        self._events = {}   # key -> Event\n        self._results = {}  # key -> value\n\n    def get(self, key, fn):\n        with self._lock:\n            ev = self._events.get(key)\n            if ev is None:\n                ev = threading.Event()\n                self._events[key] = ev\n                leader = True\n            else:\n                leader = False\n\n        if leader:\n            try:\n                self._results[key] = fn()\n            finally:\n                # Bug: forgets to set event on exception path\n                ev.set()\n        else:\n            ev.wait()\n        # Bug: leaves _events entry forever (memory leak) and may KeyError if fn raised\n        return self._results[key]", "tests": "import threading\n\ndef test_coalescing_multiple_waiters():\n    c = Coalescer()\n    calls = {\"n\": 0}\n\n    def fn():\n        calls[\"n\"] += 1\n        return \"ok\"\n\n    out = []\n    def worker():\n        out.append(c.get(\"a\", fn))\n\n    ts = [threading.Thread(target=worker) for _ in range(3)]\n    for t in ts: t.start()\n    for t in ts: t.join(timeout=1)\n\n    assert out == [\"ok\",\"ok\",\"ok\"]\n    assert calls[\"n\"] == 1\n    assert c.get(\"a\", fn) == \"ok\"  # subsequent calls should work too\n\ndef test_request_coalescing_smoke():\n    pass", "category": "bugfix", "topic": "request_coalescing", "tier": "oscillation", "starter_check": "fail", "approaches": ["cleanup_event_and_result", "store_exception_and_reraise", "use_future_like_object"]}
{"task_id": "osc_backpressure_001", "prompt": "Fix this backpressure token bucket: allow() refills every time so it never blocks.", "signature": "class TokenBucket:", "starter_code": "class TokenBucket:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.tokens = capacity\n\n    def allow(self, n: int = 1) -> bool:\n        # Bug: refills on allow call even without time; should be pure counter in this simplified version\n        self.tokens = self.capacity\n        if self.tokens - n < 0:\n            return False\n        self.tokens -= n\n        return True\n# Note: padding line 1 for backpressure\n# Note: padding line 2 for backpressure\n# Note: padding line 3 for backpressure", "tests": "def test_token_bucket_decrements():\n    b = TokenBucket(3)\n    assert b.allow() is True\n    assert b.allow() is True\n    assert b.allow() is True\n    assert b.allow() is False\n\ndef test_token_bucket_bulk():\n    b = TokenBucket(5)\n    assert b.allow(3) is True\n    assert b.allow(3) is False", "category": "bugfix", "topic": "backpressure", "tier": "oscillation", "starter_check": "fail", "approaches": ["simple_counter_bucket", "sliding_window_counter", "queue_of_tokens"]}
{"task_id": "osc_backpressure_002", "prompt": "Fix this backpressure limiter: redundant state (deque + counter) gets out of sync and never unblocks.", "signature": "class SlidingWindowLimiter:", "starter_code": "from collections import deque\n\nclass SlidingWindowLimiter:\n    def __init__(self, max_inflight: int):\n        self.max = max_inflight\n        self.q = deque()\n        self.inflight = 0\n\n    def acquire(self):\n        # Bug: tracks both q and inflight but updates only one\n        if self.inflight >= self.max:\n            return False\n        self.q.append(1)\n        return True\n\n    def release(self):\n        if self.q:\n            self.q.popleft()\n        # Bug: never decrements inflight", "tests": "def test_limiter_blocks_when_full():\n    l = SlidingWindowLimiter(2)\n    assert l.acquire() is True\n    assert l.acquire() is True\n    assert l.acquire() is False\n    l.release()\n    assert l.acquire() is True\n\ndef test_backpressure_smoke():\n    pass", "category": "bugfix", "topic": "backpressure", "tier": "oscillation", "starter_check": "fail", "approaches": ["single_counter_only", "deque_only_len", "semaphore_wrapper"]}
{"task_id": "osc_backpressure_003", "prompt": "Fix this backpressure queue: capacity uses the wrong length when head advances.", "signature": "class BackpressureQueue:", "starter_code": "class BackpressureQueue:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.items = []\n        self.head = 0\n\n    def put(self, x) -> bool:\n        # Bug: uses len(items) rather than live size (len - head)\n        if len(self.items) >= self.capacity:\n            return False\n        self.items.append(x)\n        return True\n\n    def get(self):\n        if self.head >= len(self.items):\n            return None\n        x = self.items[self.head]\n        self.head += 1\n        # Bug: never compacts, capacity check stays wrong forever\n        return x\n\n    def size(self):\n        return len(self.items) - self.head", "tests": "def test_backpressure_queue_capacity_tracks_live_items():\n    q = BackpressureQueue(2)\n    assert q.put(1) is True\n    assert q.put(2) is True\n    assert q.put(3) is False\n    assert q.get() == 1\n    assert q.put(3) is True  # should allow after get\n    assert q.size() == 2\n\ndef test_backpressure_smoke():\n    pass", "category": "bugfix", "topic": "backpressure", "tier": "oscillation", "starter_check": "fail", "approaches": ["use_deque", "list_with_compaction", "circular_buffer"]}
{"task_id": "osc_backpressure_004", "prompt": "Fix this backpressure token bucket: allow() refills every time so it never blocks.", "signature": "class TokenBucket:", "starter_code": "class TokenBucket:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.tokens = capacity\n\n    def allow(self, n: int = 1) -> bool:\n        # Bug: refills on allow call even without time; should be pure counter in this simplified version\n        self.tokens = self.capacity\n        if self.tokens - n < 0:\n            return False\n        self.tokens -= n\n        return True\n# Note: padding line 1 for backpressure\n# Note: padding line 2 for backpressure\n# Note: padding line 3 for backpressure", "tests": "def test_token_bucket_decrements():\n    b = TokenBucket(3)\n    assert b.allow() is True\n    assert b.allow() is True\n    assert b.allow() is True\n    assert b.allow() is False\n\ndef test_token_bucket_bulk():\n    b = TokenBucket(5)\n    assert b.allow(3) is True\n    assert b.allow(3) is False", "category": "bugfix", "topic": "backpressure", "tier": "oscillation", "starter_check": "fail", "approaches": ["simple_counter_bucket", "sliding_window_counter", "queue_of_tokens"]}
{"task_id": "osc_backpressure_005", "prompt": "Fix this backpressure limiter: redundant state (deque + counter) gets out of sync and never unblocks.", "signature": "class SlidingWindowLimiter:", "starter_code": "from collections import deque\n\nclass SlidingWindowLimiter:\n    def __init__(self, max_inflight: int):\n        self.max = max_inflight\n        self.q = deque()\n        self.inflight = 0\n\n    def acquire(self):\n        # Bug: tracks both q and inflight but updates only one\n        if self.inflight >= self.max:\n            return False\n        self.q.append(1)\n        return True\n\n    def release(self):\n        if self.q:\n            self.q.popleft()\n        # Bug: never decrements inflight", "tests": "def test_limiter_blocks_when_full():\n    l = SlidingWindowLimiter(2)\n    assert l.acquire() is True\n    assert l.acquire() is True\n    assert l.acquire() is False\n    l.release()\n    assert l.acquire() is True\n\ndef test_backpressure_smoke():\n    pass", "category": "bugfix", "topic": "backpressure", "tier": "oscillation", "starter_check": "fail", "approaches": ["single_counter_only", "deque_only_len", "semaphore_wrapper"]}
{"task_id": "osc_backpressure_006", "prompt": "Fix this backpressure queue: capacity uses the wrong length when head advances.", "signature": "class BackpressureQueue:", "starter_code": "class BackpressureQueue:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.items = []\n        self.head = 0\n\n    def put(self, x) -> bool:\n        # Bug: uses len(items) rather than live size (len - head)\n        if len(self.items) >= self.capacity:\n            return False\n        self.items.append(x)\n        return True\n\n    def get(self):\n        if self.head >= len(self.items):\n            return None\n        x = self.items[self.head]\n        self.head += 1\n        # Bug: never compacts, capacity check stays wrong forever\n        return x\n\n    def size(self):\n        return len(self.items) - self.head", "tests": "def test_backpressure_queue_capacity_tracks_live_items():\n    q = BackpressureQueue(2)\n    assert q.put(1) is True\n    assert q.put(2) is True\n    assert q.put(3) is False\n    assert q.get() == 1\n    assert q.put(3) is True  # should allow after get\n    assert q.size() == 2\n\ndef test_backpressure_smoke():\n    pass", "category": "bugfix", "topic": "backpressure", "tier": "oscillation", "starter_check": "fail", "approaches": ["use_deque", "list_with_compaction", "circular_buffer"]}
{"task_id": "osc_backpressure_007", "prompt": "Fix this backpressure token bucket: allow() refills every time so it never blocks.", "signature": "class TokenBucket:", "starter_code": "class TokenBucket:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.tokens = capacity\n\n    def allow(self, n: int = 1) -> bool:\n        # Bug: refills on allow call even without time; should be pure counter in this simplified version\n        self.tokens = self.capacity\n        if self.tokens - n < 0:\n            return False\n        self.tokens -= n\n        return True\n# Note: padding line 1 for backpressure\n# Note: padding line 2 for backpressure\n# Note: padding line 3 for backpressure", "tests": "def test_token_bucket_decrements():\n    b = TokenBucket(3)\n    assert b.allow() is True\n    assert b.allow() is True\n    assert b.allow() is True\n    assert b.allow() is False\n\ndef test_token_bucket_bulk():\n    b = TokenBucket(5)\n    assert b.allow(3) is True\n    assert b.allow(3) is False", "category": "bugfix", "topic": "backpressure", "tier": "oscillation", "starter_check": "fail", "approaches": ["simple_counter_bucket", "sliding_window_counter", "queue_of_tokens"]}
{"task_id": "osc_backpressure_008", "prompt": "Fix this backpressure limiter: redundant state (deque + counter) gets out of sync and never unblocks.", "signature": "class SlidingWindowLimiter:", "starter_code": "from collections import deque\n\nclass SlidingWindowLimiter:\n    def __init__(self, max_inflight: int):\n        self.max = max_inflight\n        self.q = deque()\n        self.inflight = 0\n\n    def acquire(self):\n        # Bug: tracks both q and inflight but updates only one\n        if self.inflight >= self.max:\n            return False\n        self.q.append(1)\n        return True\n\n    def release(self):\n        if self.q:\n            self.q.popleft()\n        # Bug: never decrements inflight", "tests": "def test_limiter_blocks_when_full():\n    l = SlidingWindowLimiter(2)\n    assert l.acquire() is True\n    assert l.acquire() is True\n    assert l.acquire() is False\n    l.release()\n    assert l.acquire() is True\n\ndef test_backpressure_smoke():\n    pass", "category": "bugfix", "topic": "backpressure", "tier": "oscillation", "starter_check": "fail", "approaches": ["single_counter_only", "deque_only_len", "semaphore_wrapper"]}
